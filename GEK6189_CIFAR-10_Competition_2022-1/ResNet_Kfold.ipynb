{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet34_Kfold.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Yq2t0nduROER",
        "zP5k6WvrgnTB",
        "GjyF1Tveg0A1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f14c1120ce64dafb4c11e4ff988b9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a798cbe385d84c6f891bc9b6b41f23b1",
              "IPY_MODEL_77aad690d0a54b04bef076cc741c3c2e",
              "IPY_MODEL_bbe4b6077b21461babee656384cc747b"
            ],
            "layout": "IPY_MODEL_391cf85cd33c40048f78b7f6ab0988bd"
          }
        },
        "a798cbe385d84c6f891bc9b6b41f23b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9e54588bcc4435ba867ba7d34b3744f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8ccd90396a42b088bf62538f3d2894",
            "value": ""
          }
        },
        "77aad690d0a54b04bef076cc741c3c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ae58310f2341f88dce8052ff4bc2d1",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aacba7c58be3462a93fb3ffdbb731ea8",
            "value": 170498071
          }
        },
        "bbe4b6077b21461babee656384cc747b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6cd48289dc400e8a4d10eac240e02f",
            "placeholder": "​",
            "style": "IPY_MODEL_aabcd1977159467aa93611df4f0af538",
            "value": " 170499072/? [00:13&lt;00:00, 13254691.14it/s]"
          }
        },
        "391cf85cd33c40048f78b7f6ab0988bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e54588bcc4435ba867ba7d34b3744f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8ccd90396a42b088bf62538f3d2894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00ae58310f2341f88dce8052ff4bc2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aacba7c58be3462a93fb3ffdbb731ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e6cd48289dc400e8a4d10eac240e02f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aabcd1977159467aa93611df4f0af538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSVZKuMHOkNd",
        "outputId": "a8cc7b1a-87a2-4a84-e7a2-f5636ee7949b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import package\n",
        "\n",
        "# model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "\n",
        "# dataset and transformation\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Scheduler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# display images\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# utils\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# submission\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ],
      "metadata": {
        "id": "eFOjM_GoPIQi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define ResNet model**"
      ],
      "metadata": {
        "id": "Yq2t0nduROER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1   # output 채널을 늘리고싶다면 1보다 큰 값으로\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
        "        )\n",
        "\n",
        "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # projection mapping using 1x1conv, input과 output의 feature map size가 다를 경우 사용\n",
        "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.residual_function(x) + self.shortcut(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
        "        )\n",
        "\n",
        "        # identity mapping\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # projection mapping\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
        "            )\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.residual_function(x) + self.shortcut(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Qve0Qom9RSxo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_block, num_classes=100, init_weights=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels=64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        # weights inittialization\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        x = self.conv3_x(output)\n",
        "        x = self.conv4_x(x)\n",
        "        x = self.conv5_x(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    # define weight initialization function\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def resnet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "# 34 = 1(7x7 conv) + 2 * (3 + 4 + 6 + 3) + 1(fc 1000)\n",
        "def resnet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n",
        "\n",
        "# 50 = 1(7x7 conv) + 3 * (3 + 4 + 6 + 3) + 1(fc 1000)\n",
        "def resnet50():\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=num_classes)\n",
        "\n",
        "def resnet101():\n",
        "    return ResNet(BottleNeck, [3, 4, 23, 3], num_classes=num_classes)\n",
        "\n",
        "def resnet152():\n",
        "    return ResNet(BottleNeck, [3, 8, 36, 3], num_classes=num_classes)"
      ],
      "metadata": {
        "id": "hvqBbM3DRTUE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Utils**"
      ],
      "metadata": {
        "id": "zP5k6WvrgnTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    r\"\"\"Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        # _, pred = output.topk(maxk, 1, True, True)\n",
        "        # pred = pred.t()\n",
        "        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n",
        "        _, idx = output.sort(descending=True)\n",
        "        pred = idx[:,:maxk]\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "metadata": {
        "id": "1Xa4ViILgpKQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cutout: Main Code for Applying Cutout data augmentation**"
      ],
      "metadata": {
        "id": "GjyF1Tveg0A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cutout(object):\n",
        "    \"\"\"Randomly mask out one or more patches from an image.\n",
        "\n",
        "    Args:\n",
        "        n_holes (int): Number of patches to cut out of each image.\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "\n",
        "        for n in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "\n",
        "        return img"
      ],
      "metadata": {
        "id": "n8eGTZuwgzUF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parameter Setting**"
      ],
      "metadata": {
        "id": "lXJGSMQSRWuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'cifar10' # cifar10 or cifar100\n",
        "model = 'ResNet50' # resnet18, resnet50, resnet101, GoogLeNetV1\n",
        "batch_size = 64  # Input batch size for training (default: 128)\n",
        "epochs = 8 # Number of epochs to train (default: 200)\n",
        "learning_rate = 0.001 # Learning rate\n",
        "data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n",
        "fold_num = 10 # k-fold validation\n",
        "path2submission = f'/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/submission/{model}.csv'    # route for submission .csv file\n",
        "path2weights = f'/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/models/{model}'\n",
        "\n",
        "cutout = True # Apply Cutout?\n",
        "if cutout:\n",
        "    n_holes = 1 # Number of holes to cut out from image\n",
        "    length = 16 # Length of the holes\n",
        "\n",
        "seed = 0 # Random seed (default: 0)\n",
        "print_freq = 100\n",
        "cuda = torch.cuda.is_available()\n",
        "cudnn.benchmark = True  # Should make training should go faster for large models\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "test_id = dataset + '_' + model"
      ],
      "metadata": {
        "id": "ma17ymk8QGUN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Preprocessing\n",
        "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "# train\n",
        "train_transform = transforms.Compose([])\n",
        "\n",
        "train_transform.transforms.append(transforms.Resize((64, 64)))\n",
        "if data_augmentation:\n",
        "    #train_transform.transforms.append(transforms.RandomCrop(299, 299))\n",
        "    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "train_transform.transforms.append(transforms.ToTensor())\n",
        "train_transform.transforms.append(normalize)\n",
        "\n",
        "if cutout:\n",
        "    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n",
        "\n",
        "# test\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize])\n",
        "\n",
        "\n",
        "# load dataset\n",
        "if dataset == 'cifar10':\n",
        "    num_classes = 10\n",
        "    train_dataset = datasets.CIFAR10(root='data/',\n",
        "                                     train=True,\n",
        "                                     transform=train_transform,\n",
        "                                     download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root='data/',\n",
        "                                    train=False,\n",
        "                                    transform=test_transform,\n",
        "                                    download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "9f14c1120ce64dafb4c11e4ff988b9f1",
            "a798cbe385d84c6f891bc9b6b41f23b1",
            "77aad690d0a54b04bef076cc741c3c2e",
            "bbe4b6077b21461babee656384cc747b",
            "391cf85cd33c40048f78b7f6ab0988bd",
            "a9e54588bcc4435ba867ba7d34b3744f",
            "1f8ccd90396a42b088bf62538f3d2894",
            "00ae58310f2341f88dce8052ff4bc2d1",
            "aacba7c58be3462a93fb3ffdbb731ea8",
            "9e6cd48289dc400e8a4d10eac240e02f",
            "aabcd1977159467aa93611df4f0af538"
          ]
        },
        "id": "AVTMRhb5PcH0",
        "outputId": "e04e1c54-f824-4a7f-8d98-0d4f05b2636c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f14c1120ce64dafb4c11e4ff988b9f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main Training**"
      ],
      "metadata": {
        "id": "fO4sCjR0i6f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, epoch, model, optimizer, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, losses,\n",
        "                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "        #input = input.to(torch.device(\"cpu\"))\n",
        "        #target = target.to(torch.device(\"cpu\"))\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss, accuracy \n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "def valid(val_loader, model):\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    model.eval()\n",
        "    for i,(input,target) in enumerate(val_loader):\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "        #input = input.to(torch.device(\"cpu\"))\n",
        "        #target = target.to(torch.device(\"cpu\"))\n",
        "\n",
        "        output = model(input)\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "    print('==> Valid Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "def test(test_loader, model):  \n",
        "    output = None\n",
        "    model.eval()\n",
        "    for i, (input, target) in enumerate(tqdm(test_loader), 0):\n",
        "        input = input.cuda()\n",
        "        #target은 쓰지 않음.\n",
        "        #target = target.cuda()\n",
        "        if output is not None:\n",
        "            output = torch.cat((output, model(input)), dim=0)\n",
        "        else:\n",
        "            output = model(input)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Ky64JtDki8dd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=fold_num, shuffle=True)"
      ],
      "metadata": {
        "id": "C-i8yJnaX60r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation using K-fold cross-validation\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(train_dataset)):\n",
        "\n",
        "    # Print\n",
        "    print(f'\\nFOLD {fold+1}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # Ramdom sample elements from a given list of ids, not replacement.\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "    valid_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "    train_loader = DataLoader(dataset = train_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         sampler = train_subsampler,\n",
        "                         pin_memory=True,\n",
        "                         num_workers=2)\n",
        "    \n",
        "    valid_loader = DataLoader(dataset = train_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         sampler = valid_subsampler,\n",
        "                         pin_memory=True,\n",
        "                         num_workers=2)\n",
        "    \n",
        "    # Setting\n",
        "    if model == 'ResNet34':\n",
        "        model = resnet34().cuda()\n",
        "    elif model == \"ResNet50\":\n",
        "        model = resnet50().cuda()\n",
        "    elif model == \"ResNet101\":\n",
        "        model = resnet101().cuda()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "    criterion = torch.nn.CrossEntropyLoss(reduction='sum').cuda()\n",
        "\n",
        "    # Training\n",
        "    best_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        # Train for one epoch\n",
        "        train(train_loader, epoch, model, optimizer, criterion)\n",
        "\n",
        "        # Validation\n",
        "        with torch.no_grad():\n",
        "            val_acc = valid(valid_loader, model)\n",
        "\n",
        "        # learning rate scheduling\n",
        "        scheduler.step()\n",
        "    \n",
        "        # Save model for best accuracy\n",
        "        if best_acc < val_acc:\n",
        "            path2weights_fold = f'{path2weights}_fold{fold+1}.pth'  # route for model saving\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), path2weights_fold)\n",
        "\n",
        "    print(f\"Best Top-1 Accuracy for fold{fold+1}: {best_acc}\")"
      ],
      "metadata": {
        "id": "2ZIdY89oYH7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d06c3f-8180-4962-bd3c-7197fbf417a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  1.832 ( 1.832)\tLoss 1.5313e+02 (1.5313e+02)\tAcc@1  14.06 ( 14.06)\tAcc@5  46.88 ( 46.88)\n",
            "Epoch: [0][100/704]\tTime  0.072 ( 0.090)\tLoss 1.1410e+02 (1.3952e+02)\tAcc@1  31.25 ( 26.27)\tAcc@5  90.62 ( 76.13)\n",
            "Epoch: [0][200/704]\tTime  0.072 ( 0.081)\tLoss 1.0747e+02 (1.2845e+02)\tAcc@1  39.06 ( 30.42)\tAcc@5  85.94 ( 80.95)\n",
            "Epoch: [0][300/704]\tTime  0.073 ( 0.078)\tLoss 1.1277e+02 (1.2351e+02)\tAcc@1  42.19 ( 31.92)\tAcc@5  85.94 ( 82.75)\n",
            "Epoch: [0][400/704]\tTime  0.073 ( 0.077)\tLoss 1.0463e+02 (1.1868e+02)\tAcc@1  42.19 ( 34.33)\tAcc@5  89.06 ( 84.46)\n",
            "Epoch: [0][500/704]\tTime  0.077 ( 0.076)\tLoss 1.0435e+02 (1.1467e+02)\tAcc@1  37.50 ( 36.23)\tAcc@5  89.06 ( 85.72)\n",
            "Epoch: [0][600/704]\tTime  0.073 ( 0.076)\tLoss 9.0597e+01 (1.1137e+02)\tAcc@1  50.00 ( 37.93)\tAcc@5  95.31 ( 86.68)\n",
            "Epoch: [0][700/704]\tTime  0.070 ( 0.075)\tLoss 8.4168e+01 (1.0804e+02)\tAcc@1  50.00 ( 39.68)\tAcc@5  95.31 ( 87.60)\n",
            "==> Train Accuracy: Acc@1 39.698 || Acc@5 87.596\n",
            "==> Valid Accuracy:  Acc@1 51.120 || Acc@5 93.660\n",
            "Epoch: [1][  0/704]\tTime  0.436 ( 0.436)\tLoss 8.1680e+01 (8.1680e+01)\tAcc@1  50.00 ( 50.00)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [1][100/704]\tTime  0.073 ( 0.078)\tLoss 1.2220e+02 (8.3117e+01)\tAcc@1  32.81 ( 53.30)\tAcc@5  89.06 ( 93.67)\n",
            "Epoch: [1][200/704]\tTime  0.074 ( 0.077)\tLoss 8.6024e+01 (8.1600e+01)\tAcc@1  56.25 ( 54.07)\tAcc@5  93.75 ( 94.08)\n",
            "Epoch: [1][300/704]\tTime  0.071 ( 0.076)\tLoss 9.7120e+01 (8.1294e+01)\tAcc@1  42.19 ( 54.26)\tAcc@5  92.19 ( 94.24)\n",
            "Epoch: [1][400/704]\tTime  0.074 ( 0.076)\tLoss 6.9513e+01 (8.0394e+01)\tAcc@1  62.50 ( 55.08)\tAcc@5  90.62 ( 94.33)\n",
            "Epoch: [1][500/704]\tTime  0.074 ( 0.075)\tLoss 7.8798e+01 (7.9531e+01)\tAcc@1  48.44 ( 55.79)\tAcc@5  95.31 ( 94.49)\n",
            "Epoch: [1][600/704]\tTime  0.074 ( 0.075)\tLoss 8.5816e+01 (7.8867e+01)\tAcc@1  53.12 ( 56.27)\tAcc@5  90.62 ( 94.60)\n",
            "Epoch: [1][700/704]\tTime  0.073 ( 0.076)\tLoss 8.0694e+01 (7.8058e+01)\tAcc@1  50.00 ( 56.66)\tAcc@5  95.31 ( 94.81)\n",
            "==> Train Accuracy: Acc@1 56.680 || Acc@5 94.820\n",
            "==> Valid Accuracy:  Acc@1 56.700 || Acc@5 94.560\n",
            "Epoch: [2][  0/704]\tTime  0.320 ( 0.320)\tLoss 7.8468e+01 (7.8468e+01)\tAcc@1  53.12 ( 53.12)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [2][100/704]\tTime  0.076 ( 0.078)\tLoss 5.7877e+01 (6.9761e+01)\tAcc@1  64.06 ( 60.92)\tAcc@5  95.31 ( 96.29)\n",
            "Epoch: [2][200/704]\tTime  0.074 ( 0.077)\tLoss 6.3106e+01 (6.9237e+01)\tAcc@1  60.94 ( 61.40)\tAcc@5  98.44 ( 96.27)\n",
            "Epoch: [2][300/704]\tTime  0.074 ( 0.076)\tLoss 7.6620e+01 (6.8773e+01)\tAcc@1  57.81 ( 61.75)\tAcc@5  98.44 ( 96.34)\n",
            "Epoch: [2][400/704]\tTime  0.073 ( 0.076)\tLoss 4.3946e+01 (6.7448e+01)\tAcc@1  71.88 ( 62.58)\tAcc@5 100.00 ( 96.42)\n",
            "Epoch: [2][500/704]\tTime  0.071 ( 0.076)\tLoss 6.7382e+01 (6.7164e+01)\tAcc@1  59.38 ( 62.75)\tAcc@5  98.44 ( 96.44)\n",
            "Epoch: [2][600/704]\tTime  0.075 ( 0.075)\tLoss 5.4212e+01 (6.6376e+01)\tAcc@1  71.88 ( 63.23)\tAcc@5  98.44 ( 96.53)\n",
            "Epoch: [2][700/704]\tTime  0.073 ( 0.075)\tLoss 5.5578e+01 (6.5236e+01)\tAcc@1  68.75 ( 63.92)\tAcc@5 100.00 ( 96.66)\n",
            "==> Train Accuracy: Acc@1 63.920 || Acc@5 96.658\n",
            "==> Valid Accuracy:  Acc@1 63.980 || Acc@5 96.820\n",
            "Epoch: [3][  0/704]\tTime  0.429 ( 0.429)\tLoss 6.1556e+01 (6.1556e+01)\tAcc@1  68.75 ( 68.75)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [3][100/704]\tTime  0.075 ( 0.078)\tLoss 6.7327e+01 (5.8098e+01)\tAcc@1  64.06 ( 68.16)\tAcc@5  95.31 ( 97.42)\n",
            "Epoch: [3][200/704]\tTime  0.075 ( 0.077)\tLoss 5.9823e+01 (5.8299e+01)\tAcc@1  60.94 ( 68.00)\tAcc@5  98.44 ( 97.43)\n",
            "Epoch: [3][300/704]\tTime  0.074 ( 0.076)\tLoss 6.4228e+01 (5.8179e+01)\tAcc@1  65.62 ( 68.15)\tAcc@5  95.31 ( 97.40)\n",
            "Epoch: [3][400/704]\tTime  0.076 ( 0.076)\tLoss 4.8176e+01 (5.7213e+01)\tAcc@1  76.56 ( 68.88)\tAcc@5 100.00 ( 97.49)\n",
            "Epoch: [3][500/704]\tTime  0.075 ( 0.076)\tLoss 3.9121e+01 (5.6273e+01)\tAcc@1  79.69 ( 69.39)\tAcc@5  98.44 ( 97.52)\n",
            "Epoch: [3][600/704]\tTime  0.074 ( 0.076)\tLoss 4.5358e+01 (5.5942e+01)\tAcc@1  68.75 ( 69.47)\tAcc@5  98.44 ( 97.56)\n",
            "Epoch: [3][700/704]\tTime  0.073 ( 0.076)\tLoss 5.5526e+01 (5.5626e+01)\tAcc@1  64.06 ( 69.62)\tAcc@5 100.00 ( 97.59)\n",
            "==> Train Accuracy: Acc@1 69.631 || Acc@5 97.593\n",
            "==> Valid Accuracy:  Acc@1 70.440 || Acc@5 97.180\n",
            "Epoch: [4][  0/704]\tTime  0.349 ( 0.349)\tLoss 3.2019e+01 (3.2019e+01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.074 ( 0.079)\tLoss 4.4773e+01 (4.8768e+01)\tAcc@1  71.88 ( 73.95)\tAcc@5  98.44 ( 98.17)\n",
            "Epoch: [4][200/704]\tTime  0.075 ( 0.077)\tLoss 5.6271e+01 (4.9569e+01)\tAcc@1  76.56 ( 73.37)\tAcc@5 100.00 ( 98.10)\n",
            "Epoch: [4][300/704]\tTime  0.073 ( 0.077)\tLoss 4.5921e+01 (4.9069e+01)\tAcc@1  73.44 ( 73.32)\tAcc@5  98.44 ( 98.13)\n",
            "Epoch: [4][400/704]\tTime  0.076 ( 0.076)\tLoss 4.5104e+01 (4.8963e+01)\tAcc@1  75.00 ( 73.45)\tAcc@5  98.44 ( 98.11)\n",
            "Epoch: [4][500/704]\tTime  0.077 ( 0.076)\tLoss 4.1484e+01 (4.9054e+01)\tAcc@1  73.44 ( 73.39)\tAcc@5  98.44 ( 98.10)\n",
            "Epoch: [4][600/704]\tTime  0.075 ( 0.076)\tLoss 3.9404e+01 (4.8705e+01)\tAcc@1  79.69 ( 73.60)\tAcc@5 100.00 ( 98.15)\n",
            "Epoch: [4][700/704]\tTime  0.071 ( 0.076)\tLoss 5.0855e+01 (4.8490e+01)\tAcc@1  73.44 ( 73.77)\tAcc@5  98.44 ( 98.15)\n",
            "==> Train Accuracy: Acc@1 73.771 || Acc@5 98.151\n",
            "==> Valid Accuracy:  Acc@1 72.720 || Acc@5 98.000\n",
            "Epoch: [5][  0/704]\tTime  0.412 ( 0.412)\tLoss 3.8386e+01 (3.8386e+01)\tAcc@1  79.69 ( 79.69)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [5][100/704]\tTime  0.074 ( 0.079)\tLoss 3.2289e+01 (3.9081e+01)\tAcc@1  82.81 ( 79.12)\tAcc@5  98.44 ( 98.70)\n",
            "Epoch: [5][200/704]\tTime  0.074 ( 0.077)\tLoss 3.8980e+01 (3.7560e+01)\tAcc@1  81.25 ( 79.84)\tAcc@5  96.88 ( 98.83)\n",
            "Epoch: [5][300/704]\tTime  0.074 ( 0.077)\tLoss 3.9448e+01 (3.6775e+01)\tAcc@1  76.56 ( 80.17)\tAcc@5  98.44 ( 98.87)\n",
            "Epoch: [5][400/704]\tTime  0.075 ( 0.076)\tLoss 2.5947e+01 (3.5686e+01)\tAcc@1  87.50 ( 80.70)\tAcc@5  98.44 ( 99.00)\n",
            "Epoch: [5][500/704]\tTime  0.075 ( 0.076)\tLoss 3.0784e+01 (3.5026e+01)\tAcc@1  82.81 ( 80.96)\tAcc@5 100.00 ( 99.03)\n",
            "Epoch: [5][600/704]\tTime  0.075 ( 0.076)\tLoss 2.5627e+01 (3.4825e+01)\tAcc@1  85.94 ( 81.15)\tAcc@5 100.00 ( 99.05)\n",
            "Epoch: [5][700/704]\tTime  0.071 ( 0.076)\tLoss 2.7077e+01 (3.4445e+01)\tAcc@1  79.69 ( 81.41)\tAcc@5 100.00 ( 99.07)\n",
            "==> Train Accuracy: Acc@1 81.420 || Acc@5 99.067\n",
            "==> Valid Accuracy:  Acc@1 79.400 || Acc@5 98.920\n",
            "Epoch: [6][  0/704]\tTime  0.339 ( 0.339)\tLoss 3.5943e+01 (3.5943e+01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.073 ( 0.078)\tLoss 2.4778e+01 (3.0678e+01)\tAcc@1  84.38 ( 83.14)\tAcc@5 100.00 ( 99.16)\n",
            "Epoch: [6][200/704]\tTime  0.076 ( 0.077)\tLoss 3.1939e+01 (3.0318e+01)\tAcc@1  85.94 ( 83.40)\tAcc@5  95.31 ( 99.32)\n",
            "Epoch: [6][300/704]\tTime  0.074 ( 0.077)\tLoss 3.1877e+01 (3.0131e+01)\tAcc@1  82.81 ( 83.56)\tAcc@5 100.00 ( 99.33)\n",
            "Epoch: [6][400/704]\tTime  0.075 ( 0.076)\tLoss 2.9960e+01 (2.9880e+01)\tAcc@1  76.56 ( 83.76)\tAcc@5 100.00 ( 99.31)\n",
            "Epoch: [6][500/704]\tTime  0.075 ( 0.076)\tLoss 2.6896e+01 (2.9800e+01)\tAcc@1  90.62 ( 83.80)\tAcc@5 100.00 ( 99.32)\n",
            "Epoch: [6][600/704]\tTime  0.075 ( 0.076)\tLoss 2.7008e+01 (2.9741e+01)\tAcc@1  89.06 ( 83.77)\tAcc@5  98.44 ( 99.32)\n",
            "Epoch: [6][700/704]\tTime  0.071 ( 0.076)\tLoss 2.7104e+01 (2.9487e+01)\tAcc@1  82.81 ( 83.92)\tAcc@5  98.44 ( 99.32)\n",
            "==> Train Accuracy: Acc@1 83.929 || Acc@5 99.320\n",
            "==> Valid Accuracy:  Acc@1 80.460 || Acc@5 98.940\n",
            "Epoch: [7][  0/704]\tTime  0.427 ( 0.427)\tLoss 2.2188e+01 (2.2188e+01)\tAcc@1  85.94 ( 85.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.074 ( 0.079)\tLoss 2.3311e+01 (2.6076e+01)\tAcc@1  89.06 ( 86.01)\tAcc@5 100.00 ( 99.44)\n",
            "Epoch: [7][200/704]\tTime  0.074 ( 0.077)\tLoss 2.6795e+01 (2.7019e+01)\tAcc@1  85.94 ( 85.51)\tAcc@5  98.44 ( 99.32)\n",
            "Epoch: [7][300/704]\tTime  0.074 ( 0.077)\tLoss 2.2089e+01 (2.7470e+01)\tAcc@1  87.50 ( 85.20)\tAcc@5 100.00 ( 99.33)\n",
            "Epoch: [7][400/704]\tTime  0.075 ( 0.076)\tLoss 3.3466e+01 (2.7498e+01)\tAcc@1  82.81 ( 85.15)\tAcc@5  98.44 ( 99.37)\n",
            "Epoch: [7][500/704]\tTime  0.074 ( 0.076)\tLoss 2.0620e+01 (2.7319e+01)\tAcc@1  87.50 ( 85.28)\tAcc@5 100.00 ( 99.39)\n",
            "Epoch: [7][600/704]\tTime  0.074 ( 0.076)\tLoss 2.5774e+01 (2.7245e+01)\tAcc@1  84.38 ( 85.26)\tAcc@5 100.00 ( 99.41)\n",
            "Epoch: [7][700/704]\tTime  0.072 ( 0.076)\tLoss 1.8115e+01 (2.7138e+01)\tAcc@1  89.06 ( 85.28)\tAcc@5 100.00 ( 99.42)\n",
            "==> Train Accuracy: Acc@1 85.282 || Acc@5 99.418\n",
            "==> Valid Accuracy:  Acc@1 81.000 || Acc@5 99.060\n",
            "Best Top-1 Accuracy for fold1: 81.0\n",
            "\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.345 ( 0.345)\tLoss 3.2718e+01 (3.2718e+01)\tAcc@1  82.81 ( 82.81)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [0][100/704]\tTime  0.076 ( 0.078)\tLoss 3.9658e+01 (4.4963e+01)\tAcc@1  78.12 ( 75.87)\tAcc@5  96.88 ( 98.45)\n",
            "Epoch: [0][200/704]\tTime  0.074 ( 0.078)\tLoss 4.5029e+01 (4.4183e+01)\tAcc@1  79.69 ( 76.20)\tAcc@5 100.00 ( 98.45)\n",
            "Epoch: [0][300/704]\tTime  0.075 ( 0.077)\tLoss 4.9165e+01 (4.5902e+01)\tAcc@1  76.56 ( 75.24)\tAcc@5  98.44 ( 98.30)\n",
            "Epoch: [0][400/704]\tTime  0.075 ( 0.076)\tLoss 4.6709e+01 (4.6538e+01)\tAcc@1  76.56 ( 74.92)\tAcc@5  98.44 ( 98.24)\n",
            "Epoch: [0][500/704]\tTime  0.074 ( 0.076)\tLoss 4.3199e+01 (4.7020e+01)\tAcc@1  76.56 ( 74.68)\tAcc@5  98.44 ( 98.24)\n",
            "Epoch: [0][600/704]\tTime  0.079 ( 0.076)\tLoss 5.1581e+01 (4.6375e+01)\tAcc@1  71.88 ( 75.02)\tAcc@5  98.44 ( 98.25)\n",
            "Epoch: [0][700/704]\tTime  0.072 ( 0.076)\tLoss 3.4265e+01 (4.5694e+01)\tAcc@1  84.38 ( 75.40)\tAcc@5  98.44 ( 98.29)\n",
            "==> Train Accuracy: Acc@1 75.393 || Acc@5 98.296\n",
            "==> Valid Accuracy:  Acc@1 73.940 || Acc@5 98.420\n",
            "Epoch: [1][  0/704]\tTime  0.389 ( 0.389)\tLoss 4.9496e+01 (4.9496e+01)\tAcc@1  70.31 ( 70.31)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [1][100/704]\tTime  0.075 ( 0.078)\tLoss 3.4461e+01 (4.1446e+01)\tAcc@1  84.38 ( 77.82)\tAcc@5 100.00 ( 98.75)\n",
            "Epoch: [1][200/704]\tTime  0.076 ( 0.078)\tLoss 3.9840e+01 (4.0579e+01)\tAcc@1  79.69 ( 78.26)\tAcc@5  95.31 ( 98.75)\n",
            "Epoch: [1][300/704]\tTime  0.074 ( 0.077)\tLoss 6.0260e+01 (4.0381e+01)\tAcc@1  70.31 ( 78.47)\tAcc@5  98.44 ( 98.72)\n",
            "Epoch: [1][400/704]\tTime  0.075 ( 0.076)\tLoss 6.9449e+01 (4.3421e+01)\tAcc@1  71.88 ( 77.06)\tAcc@5  95.31 ( 98.50)\n",
            "Epoch: [1][500/704]\tTime  0.073 ( 0.076)\tLoss 3.8689e+01 (4.4019e+01)\tAcc@1  71.88 ( 76.62)\tAcc@5 100.00 ( 98.49)\n",
            "Epoch: [1][600/704]\tTime  0.074 ( 0.076)\tLoss 3.6536e+01 (4.3038e+01)\tAcc@1  81.25 ( 77.12)\tAcc@5 100.00 ( 98.60)\n",
            "Epoch: [1][700/704]\tTime  0.071 ( 0.076)\tLoss 3.5833e+01 (4.2290e+01)\tAcc@1  85.94 ( 77.52)\tAcc@5  98.44 ( 98.66)\n",
            "==> Train Accuracy: Acc@1 77.507 || Acc@5 98.662\n",
            "==> Valid Accuracy:  Acc@1 80.080 || Acc@5 99.040\n",
            "Epoch: [2][  0/704]\tTime  0.418 ( 0.418)\tLoss 3.2300e+01 (3.2300e+01)\tAcc@1  78.12 ( 78.12)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [2][100/704]\tTime  0.090 ( 0.079)\tLoss 4.2453e+01 (3.3432e+01)\tAcc@1  79.69 ( 82.29)\tAcc@5  96.88 ( 99.13)\n",
            "Epoch: [2][200/704]\tTime  0.076 ( 0.078)\tLoss 3.4904e+01 (3.3591e+01)\tAcc@1  81.25 ( 82.15)\tAcc@5 100.00 ( 99.09)\n",
            "Epoch: [2][300/704]\tTime  0.074 ( 0.077)\tLoss 3.9291e+01 (3.3872e+01)\tAcc@1  79.69 ( 82.04)\tAcc@5 100.00 ( 99.13)\n",
            "Epoch: [2][400/704]\tTime  0.076 ( 0.077)\tLoss 3.6785e+01 (3.4594e+01)\tAcc@1  81.25 ( 81.67)\tAcc@5 100.00 ( 99.10)\n",
            "Epoch: [2][500/704]\tTime  0.075 ( 0.076)\tLoss 3.1960e+01 (3.5106e+01)\tAcc@1  82.81 ( 81.30)\tAcc@5  98.44 ( 99.10)\n",
            "Epoch: [2][600/704]\tTime  0.074 ( 0.076)\tLoss 3.8826e+01 (3.5722e+01)\tAcc@1  73.44 ( 80.93)\tAcc@5 100.00 ( 99.06)\n",
            "Epoch: [2][700/704]\tTime  0.070 ( 0.078)\tLoss 5.0150e+01 (3.6806e+01)\tAcc@1  75.00 ( 80.34)\tAcc@5  96.88 ( 99.00)\n",
            "==> Train Accuracy: Acc@1 80.324 || Acc@5 99.004\n",
            "==> Valid Accuracy:  Acc@1 72.040 || Acc@5 97.680\n",
            "Epoch: [3][  0/704]\tTime  0.303 ( 0.303)\tLoss 4.4889e+01 (4.4889e+01)\tAcc@1  79.69 ( 79.69)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [3][100/704]\tTime  0.075 ( 0.078)\tLoss 5.9248e+01 (4.8479e+01)\tAcc@1  68.75 ( 74.54)\tAcc@5  98.44 ( 98.16)\n",
            "Epoch: [3][200/704]\tTime  0.075 ( 0.076)\tLoss 3.1644e+01 (4.1908e+01)\tAcc@1  82.81 ( 77.57)\tAcc@5 100.00 ( 98.65)\n",
            "Epoch: [3][300/704]\tTime  0.074 ( 0.076)\tLoss 3.8768e+01 (3.8932e+01)\tAcc@1  78.12 ( 79.10)\tAcc@5 100.00 ( 98.79)\n",
            "Epoch: [3][400/704]\tTime  0.075 ( 0.076)\tLoss 3.2701e+01 (3.8329e+01)\tAcc@1  81.25 ( 79.29)\tAcc@5 100.00 ( 98.83)\n",
            "Epoch: [3][500/704]\tTime  0.075 ( 0.076)\tLoss 2.8854e+01 (3.8082e+01)\tAcc@1  87.50 ( 79.44)\tAcc@5  98.44 ( 98.87)\n",
            "Epoch: [3][600/704]\tTime  0.075 ( 0.076)\tLoss 4.7468e+01 (3.9212e+01)\tAcc@1  76.56 ( 78.79)\tAcc@5  96.88 ( 98.80)\n",
            "Epoch: [3][700/704]\tTime  0.072 ( 0.076)\tLoss 3.0510e+01 (3.8797e+01)\tAcc@1  84.38 ( 79.00)\tAcc@5 100.00 ( 98.82)\n",
            "==> Train Accuracy: Acc@1 78.989 || Acc@5 98.818\n",
            "==> Valid Accuracy:  Acc@1 79.660 || Acc@5 98.840\n",
            "Epoch: [4][  0/704]\tTime  0.397 ( 0.397)\tLoss 3.6091e+01 (3.6091e+01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.075 ( 0.080)\tLoss 3.0551e+01 (2.9571e+01)\tAcc@1  85.94 ( 83.68)\tAcc@5 100.00 ( 99.33)\n",
            "Epoch: [4][200/704]\tTime  0.075 ( 0.078)\tLoss 3.0266e+01 (3.0117e+01)\tAcc@1  79.69 ( 83.83)\tAcc@5 100.00 ( 99.33)\n",
            "Epoch: [4][300/704]\tTime  0.074 ( 0.077)\tLoss 2.5014e+01 (2.9472e+01)\tAcc@1  84.38 ( 84.28)\tAcc@5 100.00 ( 99.35)\n",
            "Epoch: [4][400/704]\tTime  0.075 ( 0.077)\tLoss 3.4043e+01 (2.9290e+01)\tAcc@1  79.69 ( 84.30)\tAcc@5  98.44 ( 99.33)\n",
            "Epoch: [4][500/704]\tTime  0.076 ( 0.077)\tLoss 2.5071e+01 (2.9387e+01)\tAcc@1  87.50 ( 84.25)\tAcc@5 100.00 ( 99.35)\n",
            "Epoch: [4][600/704]\tTime  0.074 ( 0.077)\tLoss 2.7141e+01 (2.9632e+01)\tAcc@1  87.50 ( 84.08)\tAcc@5 100.00 ( 99.35)\n",
            "Epoch: [4][700/704]\tTime  0.070 ( 0.076)\tLoss 2.3948e+01 (2.9792e+01)\tAcc@1  87.50 ( 83.98)\tAcc@5 100.00 ( 99.33)\n",
            "==> Train Accuracy: Acc@1 83.976 || Acc@5 99.333\n",
            "==> Valid Accuracy:  Acc@1 80.860 || Acc@5 99.080\n",
            "Epoch: [5][  0/704]\tTime  0.321 ( 0.321)\tLoss 1.8383e+01 (1.8383e+01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.078 ( 0.078)\tLoss 2.1308e+01 (2.3121e+01)\tAcc@1  89.06 ( 87.53)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [5][200/704]\tTime  0.074 ( 0.077)\tLoss 3.2048e+01 (2.2225e+01)\tAcc@1  84.38 ( 88.24)\tAcc@5  98.44 ( 99.64)\n",
            "Epoch: [5][300/704]\tTime  0.074 ( 0.077)\tLoss 1.0144e+01 (2.1616e+01)\tAcc@1  96.88 ( 88.29)\tAcc@5 100.00 ( 99.63)\n",
            "Epoch: [5][400/704]\tTime  0.076 ( 0.076)\tLoss 1.7062e+01 (2.1009e+01)\tAcc@1  93.75 ( 88.66)\tAcc@5 100.00 ( 99.64)\n",
            "Epoch: [5][500/704]\tTime  0.074 ( 0.076)\tLoss 1.8497e+01 (2.0343e+01)\tAcc@1  89.06 ( 89.01)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [5][600/704]\tTime  0.076 ( 0.076)\tLoss 1.7048e+01 (2.0022e+01)\tAcc@1  93.75 ( 89.20)\tAcc@5 100.00 ( 99.68)\n",
            "Epoch: [5][700/704]\tTime  0.071 ( 0.076)\tLoss 2.6449e+01 (1.9743e+01)\tAcc@1  85.94 ( 89.32)\tAcc@5  98.44 ( 99.70)\n",
            "==> Train Accuracy: Acc@1 89.320 || Acc@5 99.702\n",
            "==> Valid Accuracy:  Acc@1 85.120 || Acc@5 99.380\n",
            "Epoch: [6][  0/704]\tTime  0.438 ( 0.438)\tLoss 2.1881e+01 (2.1881e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.075 ( 0.078)\tLoss 2.0904e+01 (1.7263e+01)\tAcc@1  90.62 ( 90.70)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [6][200/704]\tTime  0.076 ( 0.077)\tLoss 8.9798e+00 (1.6857e+01)\tAcc@1  96.88 ( 90.83)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [6][300/704]\tTime  0.076 ( 0.077)\tLoss 1.1572e+01 (1.6591e+01)\tAcc@1  95.31 ( 91.02)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [6][400/704]\tTime  0.076 ( 0.076)\tLoss 1.5142e+01 (1.6299e+01)\tAcc@1  93.75 ( 91.21)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [6][500/704]\tTime  0.073 ( 0.076)\tLoss 1.1108e+01 (1.6195e+01)\tAcc@1  92.19 ( 91.25)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [6][600/704]\tTime  0.074 ( 0.076)\tLoss 1.3698e+01 (1.6156e+01)\tAcc@1  92.19 ( 91.20)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [6][700/704]\tTime  0.073 ( 0.076)\tLoss 1.6203e+01 (1.6217e+01)\tAcc@1  92.19 ( 91.19)\tAcc@5 100.00 ( 99.81)\n",
            "==> Train Accuracy: Acc@1 91.187 || Acc@5 99.813\n",
            "==> Valid Accuracy:  Acc@1 85.700 || Acc@5 99.460\n",
            "Epoch: [7][  0/704]\tTime  0.345 ( 0.345)\tLoss 2.7083e+01 (2.7083e+01)\tAcc@1  85.94 ( 85.94)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [7][100/704]\tTime  0.073 ( 0.078)\tLoss 9.2770e+00 (1.4990e+01)\tAcc@1  93.75 ( 92.02)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [7][200/704]\tTime  0.074 ( 0.077)\tLoss 2.6594e+01 (1.5492e+01)\tAcc@1  85.94 ( 91.50)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [7][300/704]\tTime  0.078 ( 0.076)\tLoss 1.6859e+01 (1.5212e+01)\tAcc@1  92.19 ( 91.68)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [7][400/704]\tTime  0.077 ( 0.076)\tLoss 1.2435e+01 (1.4933e+01)\tAcc@1  95.31 ( 91.82)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [7][500/704]\tTime  0.074 ( 0.076)\tLoss 1.1952e+01 (1.4656e+01)\tAcc@1  98.44 ( 92.01)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [7][600/704]\tTime  0.078 ( 0.075)\tLoss 1.1345e+01 (1.4734e+01)\tAcc@1  92.19 ( 91.98)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [7][700/704]\tTime  0.071 ( 0.075)\tLoss 1.5841e+01 (1.4622e+01)\tAcc@1  96.88 ( 92.03)\tAcc@5 100.00 ( 99.82)\n",
            "==> Train Accuracy: Acc@1 92.024 || Acc@5 99.822\n",
            "==> Valid Accuracy:  Acc@1 84.720 || Acc@5 99.360\n",
            "Best Top-1 Accuracy for fold2: 85.7\n",
            "\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.395 ( 0.395)\tLoss 1.4583e+01 (1.4583e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [0][100/704]\tTime  0.074 ( 0.078)\tLoss 1.8057e+01 (2.5644e+01)\tAcc@1  89.06 ( 86.36)\tAcc@5 100.00 ( 99.40)\n",
            "Epoch: [0][200/704]\tTime  0.074 ( 0.077)\tLoss 3.3153e+01 (2.5962e+01)\tAcc@1  79.69 ( 86.26)\tAcc@5  98.44 ( 99.52)\n",
            "Epoch: [0][300/704]\tTime  0.074 ( 0.076)\tLoss 3.0220e+01 (2.6414e+01)\tAcc@1  82.81 ( 85.84)\tAcc@5 100.00 ( 99.45)\n",
            "Epoch: [0][400/704]\tTime  0.077 ( 0.076)\tLoss 3.1835e+01 (2.7157e+01)\tAcc@1  84.38 ( 85.34)\tAcc@5 100.00 ( 99.42)\n",
            "Epoch: [0][500/704]\tTime  0.075 ( 0.076)\tLoss 3.2121e+01 (2.7857e+01)\tAcc@1  87.50 ( 85.02)\tAcc@5 100.00 ( 99.42)\n",
            "Epoch: [0][600/704]\tTime  0.074 ( 0.076)\tLoss 2.1828e+01 (2.8267e+01)\tAcc@1  90.62 ( 84.81)\tAcc@5 100.00 ( 99.40)\n",
            "Epoch: [0][700/704]\tTime  0.071 ( 0.076)\tLoss 2.5349e+01 (2.8400e+01)\tAcc@1  84.38 ( 84.72)\tAcc@5 100.00 ( 99.40)\n",
            "==> Train Accuracy: Acc@1 84.704 || Acc@5 99.393\n",
            "==> Valid Accuracy:  Acc@1 85.380 || Acc@5 99.460\n",
            "Epoch: [1][  0/704]\tTime  0.337 ( 0.337)\tLoss 1.3589e+01 (1.3589e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.075 ( 0.078)\tLoss 3.2235e+01 (2.4449e+01)\tAcc@1  84.38 ( 86.80)\tAcc@5 100.00 ( 99.60)\n",
            "Epoch: [1][200/704]\tTime  0.075 ( 0.078)\tLoss 2.5246e+01 (2.4673e+01)\tAcc@1  84.38 ( 86.66)\tAcc@5  98.44 ( 99.60)\n",
            "Epoch: [1][300/704]\tTime  0.076 ( 0.077)\tLoss 2.9646e+01 (2.5905e+01)\tAcc@1  87.50 ( 85.93)\tAcc@5 100.00 ( 99.53)\n",
            "Epoch: [1][400/704]\tTime  0.075 ( 0.076)\tLoss 1.9301e+01 (2.6242e+01)\tAcc@1  90.62 ( 85.76)\tAcc@5 100.00 ( 99.53)\n",
            "Epoch: [1][500/704]\tTime  0.074 ( 0.076)\tLoss 2.5440e+01 (2.6006e+01)\tAcc@1  87.50 ( 85.89)\tAcc@5 100.00 ( 99.55)\n",
            "Epoch: [1][600/704]\tTime  0.079 ( 0.076)\tLoss 3.1951e+01 (2.6029e+01)\tAcc@1  84.38 ( 85.86)\tAcc@5  98.44 ( 99.53)\n",
            "Epoch: [1][700/704]\tTime  0.079 ( 0.076)\tLoss 2.0916e+01 (2.5911e+01)\tAcc@1  90.62 ( 85.88)\tAcc@5 100.00 ( 99.54)\n",
            "==> Train Accuracy: Acc@1 85.876 || Acc@5 99.538\n",
            "==> Valid Accuracy:  Acc@1 84.260 || Acc@5 99.320\n",
            "Epoch: [2][  0/704]\tTime  0.313 ( 0.313)\tLoss 1.3189e+01 (1.3189e+01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.073 ( 0.077)\tLoss 1.8713e+01 (2.1733e+01)\tAcc@1  89.06 ( 88.03)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [2][200/704]\tTime  0.073 ( 0.076)\tLoss 2.9104e+01 (2.3575e+01)\tAcc@1  84.38 ( 87.17)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [2][300/704]\tTime  0.073 ( 0.075)\tLoss 1.8825e+01 (2.3353e+01)\tAcc@1  89.06 ( 87.31)\tAcc@5 100.00 ( 99.66)\n",
            "Epoch: [2][400/704]\tTime  0.072 ( 0.075)\tLoss 2.5851e+01 (2.4559e+01)\tAcc@1  84.38 ( 86.78)\tAcc@5 100.00 ( 99.59)\n",
            "Epoch: [2][500/704]\tTime  0.074 ( 0.075)\tLoss 3.4141e+01 (2.6162e+01)\tAcc@1  85.94 ( 86.07)\tAcc@5 100.00 ( 99.55)\n",
            "Epoch: [2][600/704]\tTime  0.074 ( 0.075)\tLoss 3.6432e+01 (2.8788e+01)\tAcc@1  76.56 ( 84.82)\tAcc@5 100.00 ( 99.41)\n",
            "Epoch: [2][700/704]\tTime  0.070 ( 0.075)\tLoss 2.4797e+01 (2.8852e+01)\tAcc@1  85.94 ( 84.74)\tAcc@5 100.00 ( 99.38)\n",
            "==> Train Accuracy: Acc@1 84.758 || Acc@5 99.387\n",
            "==> Valid Accuracy:  Acc@1 83.720 || Acc@5 99.100\n",
            "Epoch: [3][  0/704]\tTime  0.390 ( 0.390)\tLoss 1.9349e+01 (1.9349e+01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.076 ( 0.078)\tLoss 2.7061e+01 (2.4943e+01)\tAcc@1  89.06 ( 87.05)\tAcc@5 100.00 ( 99.57)\n",
            "Epoch: [3][200/704]\tTime  0.074 ( 0.076)\tLoss 2.5529e+01 (2.4130e+01)\tAcc@1  84.38 ( 87.26)\tAcc@5 100.00 ( 99.61)\n",
            "Epoch: [3][300/704]\tTime  0.077 ( 0.076)\tLoss 3.6083e+01 (2.5476e+01)\tAcc@1  82.81 ( 86.47)\tAcc@5  96.88 ( 99.53)\n",
            "Epoch: [3][400/704]\tTime  0.077 ( 0.076)\tLoss 2.0323e+01 (2.8096e+01)\tAcc@1  89.06 ( 85.39)\tAcc@5 100.00 ( 99.40)\n",
            "Epoch: [3][500/704]\tTime  0.074 ( 0.075)\tLoss 2.2851e+01 (2.7372e+01)\tAcc@1  90.62 ( 85.63)\tAcc@5 100.00 ( 99.45)\n",
            "Epoch: [3][600/704]\tTime  0.074 ( 0.075)\tLoss 2.6435e+01 (2.6621e+01)\tAcc@1  84.38 ( 85.92)\tAcc@5 100.00 ( 99.49)\n",
            "Epoch: [3][700/704]\tTime  0.074 ( 0.075)\tLoss 1.8454e+01 (2.5922e+01)\tAcc@1  89.06 ( 86.30)\tAcc@5 100.00 ( 99.51)\n",
            "==> Train Accuracy: Acc@1 86.284 || Acc@5 99.507\n",
            "==> Valid Accuracy:  Acc@1 85.260 || Acc@5 99.520\n",
            "Epoch: [4][  0/704]\tTime  0.312 ( 0.312)\tLoss 1.4356e+01 (1.4356e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.076 ( 0.077)\tLoss 1.9938e+01 (1.6719e+01)\tAcc@1  89.06 ( 90.86)\tAcc@5  98.44 ( 99.86)\n",
            "Epoch: [4][200/704]\tTime  0.076 ( 0.076)\tLoss 2.3078e+01 (1.7138e+01)\tAcc@1  87.50 ( 90.74)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [4][300/704]\tTime  0.074 ( 0.076)\tLoss 2.8119e+01 (1.8015e+01)\tAcc@1  85.94 ( 90.21)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [4][400/704]\tTime  0.081 ( 0.076)\tLoss 1.7882e+01 (1.8272e+01)\tAcc@1  90.62 ( 90.10)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [4][500/704]\tTime  0.075 ( 0.075)\tLoss 2.1152e+01 (1.8319e+01)\tAcc@1  89.06 ( 90.06)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [4][600/704]\tTime  0.075 ( 0.075)\tLoss 1.9683e+01 (1.8605e+01)\tAcc@1  89.06 ( 89.87)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [4][700/704]\tTime  0.070 ( 0.075)\tLoss 1.9466e+01 (1.8720e+01)\tAcc@1  89.06 ( 89.75)\tAcc@5 100.00 ( 99.75)\n",
            "==> Train Accuracy: Acc@1 89.747 || Acc@5 99.753\n",
            "==> Valid Accuracy:  Acc@1 85.680 || Acc@5 99.400\n",
            "Epoch: [5][  0/704]\tTime  0.452 ( 0.452)\tLoss 1.0356e+01 (1.0356e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.072 ( 0.079)\tLoss 2.0389e+01 (1.3288e+01)\tAcc@1  93.75 ( 92.96)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [5][200/704]\tTime  0.074 ( 0.078)\tLoss 1.0744e+01 (1.2819e+01)\tAcc@1  96.88 ( 93.35)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [5][300/704]\tTime  0.078 ( 0.077)\tLoss 8.7605e+00 (1.2186e+01)\tAcc@1  93.75 ( 93.62)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [5][400/704]\tTime  0.076 ( 0.077)\tLoss 5.7531e+00 (1.1733e+01)\tAcc@1  98.44 ( 93.87)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [5][500/704]\tTime  0.075 ( 0.077)\tLoss 1.0726e+01 (1.1525e+01)\tAcc@1  93.75 ( 93.97)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [5][600/704]\tTime  0.076 ( 0.076)\tLoss 8.7020e+00 (1.1301e+01)\tAcc@1  96.88 ( 94.07)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [5][700/704]\tTime  0.071 ( 0.076)\tLoss 6.0935e+00 (1.1126e+01)\tAcc@1  96.88 ( 94.18)\tAcc@5 100.00 ( 99.92)\n",
            "==> Train Accuracy: Acc@1 94.178 || Acc@5 99.924\n",
            "==> Valid Accuracy:  Acc@1 88.680 || Acc@5 99.600\n",
            "Epoch: [6][  0/704]\tTime  0.332 ( 0.332)\tLoss 1.1189e+01 (1.1189e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.075 ( 0.077)\tLoss 1.2892e+01 (9.5513e+00)\tAcc@1  93.75 ( 94.77)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [6][200/704]\tTime  0.074 ( 0.077)\tLoss 7.7125e+00 (9.3775e+00)\tAcc@1  95.31 ( 94.92)\tAcc@5  98.44 ( 99.95)\n",
            "Epoch: [6][300/704]\tTime  0.074 ( 0.076)\tLoss 6.9914e+00 (9.2017e+00)\tAcc@1  95.31 ( 95.06)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [6][400/704]\tTime  0.076 ( 0.076)\tLoss 5.9517e+00 (9.1499e+00)\tAcc@1  96.88 ( 95.05)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [6][500/704]\tTime  0.075 ( 0.076)\tLoss 3.3577e+00 (9.0065e+00)\tAcc@1  98.44 ( 95.09)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [6][600/704]\tTime  0.074 ( 0.076)\tLoss 7.2119e+00 (8.9240e+00)\tAcc@1  95.31 ( 95.11)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [6][700/704]\tTime  0.072 ( 0.075)\tLoss 4.6368e+00 (8.7728e+00)\tAcc@1  96.88 ( 95.21)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 95.211 || Acc@5 99.956\n",
            "==> Valid Accuracy:  Acc@1 89.280 || Acc@5 99.680\n",
            "Epoch: [7][  0/704]\tTime  0.485 ( 0.485)\tLoss 3.1484e+00 (3.1484e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.074 ( 0.079)\tLoss 1.0430e+01 (7.5058e+00)\tAcc@1  95.31 ( 96.01)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [7][200/704]\tTime  0.075 ( 0.077)\tLoss 1.1469e+01 (7.5760e+00)\tAcc@1  95.31 ( 96.01)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [7][300/704]\tTime  0.074 ( 0.077)\tLoss 1.4348e+01 (7.6838e+00)\tAcc@1  90.62 ( 95.96)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [7][400/704]\tTime  0.074 ( 0.076)\tLoss 7.8058e+00 (7.6159e+00)\tAcc@1  93.75 ( 95.97)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [7][500/704]\tTime  0.074 ( 0.076)\tLoss 9.7244e+00 (7.5701e+00)\tAcc@1  98.44 ( 95.97)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [7][600/704]\tTime  0.075 ( 0.076)\tLoss 6.6431e+00 (7.3636e+00)\tAcc@1  95.31 ( 96.07)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [7][700/704]\tTime  0.071 ( 0.076)\tLoss 1.2020e+01 (7.3527e+00)\tAcc@1  90.62 ( 96.03)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 96.020 || Acc@5 99.964\n",
            "==> Valid Accuracy:  Acc@1 89.420 || Acc@5 99.680\n",
            "Best Top-1 Accuracy for fold3: 89.42\n",
            "\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.361 ( 0.361)\tLoss 1.6760e+01 (1.6760e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][100/704]\tTime  0.075 ( 0.079)\tLoss 1.0140e+01 (1.6274e+01)\tAcc@1  93.75 ( 90.92)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [0][200/704]\tTime  0.074 ( 0.077)\tLoss 2.1916e+01 (1.9017e+01)\tAcc@1  89.06 ( 90.00)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [0][300/704]\tTime  0.074 ( 0.076)\tLoss 1.2128e+01 (1.9072e+01)\tAcc@1  96.88 ( 89.92)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [0][400/704]\tTime  0.073 ( 0.076)\tLoss 1.9462e+01 (1.8896e+01)\tAcc@1  87.50 ( 89.95)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [0][500/704]\tTime  0.076 ( 0.076)\tLoss 1.8023e+01 (1.8738e+01)\tAcc@1  90.62 ( 89.95)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [0][600/704]\tTime  0.073 ( 0.076)\tLoss 1.7070e+01 (1.8332e+01)\tAcc@1  89.06 ( 90.16)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [0][700/704]\tTime  0.070 ( 0.075)\tLoss 2.2771e+01 (1.8286e+01)\tAcc@1  89.06 ( 90.15)\tAcc@5 100.00 ( 99.78)\n",
            "==> Train Accuracy: Acc@1 90.149 || Acc@5 99.780\n",
            "==> Valid Accuracy:  Acc@1 89.340 || Acc@5 99.680\n",
            "Epoch: [1][  0/704]\tTime  0.467 ( 0.467)\tLoss 1.7663e+01 (1.7663e+01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.085 ( 0.080)\tLoss 9.5821e+00 (1.3560e+01)\tAcc@1  95.31 ( 92.91)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [1][200/704]\tTime  0.077 ( 0.078)\tLoss 1.1729e+01 (1.4418e+01)\tAcc@1  90.62 ( 92.36)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [1][300/704]\tTime  0.075 ( 0.077)\tLoss 1.8805e+01 (1.5072e+01)\tAcc@1  87.50 ( 91.94)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [1][400/704]\tTime  0.075 ( 0.076)\tLoss 2.2974e+01 (1.5447e+01)\tAcc@1  84.38 ( 91.62)\tAcc@5  98.44 ( 99.86)\n",
            "Epoch: [1][500/704]\tTime  0.073 ( 0.076)\tLoss 8.7064e+00 (1.5413e+01)\tAcc@1  93.75 ( 91.64)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [1][600/704]\tTime  0.074 ( 0.076)\tLoss 2.2253e+01 (1.5869e+01)\tAcc@1  84.38 ( 91.39)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [1][700/704]\tTime  0.071 ( 0.076)\tLoss 1.5850e+01 (1.7235e+01)\tAcc@1  89.06 ( 90.64)\tAcc@5 100.00 ( 99.81)\n",
            "==> Train Accuracy: Acc@1 90.633 || Acc@5 99.811\n",
            "==> Valid Accuracy:  Acc@1 87.460 || Acc@5 99.540\n",
            "Epoch: [2][  0/704]\tTime  0.307 ( 0.307)\tLoss 1.0446e+01 (1.0446e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.073 ( 0.077)\tLoss 1.0309e+01 (1.5868e+01)\tAcc@1  92.19 ( 91.54)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [2][200/704]\tTime  0.073 ( 0.076)\tLoss 1.2724e+01 (1.5711e+01)\tAcc@1  92.19 ( 91.65)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [2][300/704]\tTime  0.073 ( 0.076)\tLoss 2.1070e+01 (1.5448e+01)\tAcc@1  90.62 ( 91.72)\tAcc@5  98.44 ( 99.89)\n",
            "Epoch: [2][400/704]\tTime  0.074 ( 0.075)\tLoss 1.7962e+01 (1.6427e+01)\tAcc@1  87.50 ( 91.15)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [2][500/704]\tTime  0.076 ( 0.075)\tLoss 1.7883e+01 (1.6363e+01)\tAcc@1  90.62 ( 91.14)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [2][600/704]\tTime  0.076 ( 0.075)\tLoss 1.8404e+01 (1.6624e+01)\tAcc@1  89.06 ( 91.01)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [2][700/704]\tTime  0.069 ( 0.075)\tLoss 1.2082e+01 (1.6686e+01)\tAcc@1  92.19 ( 90.93)\tAcc@5  98.44 ( 99.86)\n",
            "==> Train Accuracy: Acc@1 90.924 || Acc@5 99.856\n",
            "==> Valid Accuracy:  Acc@1 89.680 || Acc@5 99.680\n",
            "Epoch: [3][  0/704]\tTime  0.345 ( 0.345)\tLoss 8.1007e+00 (8.1007e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.074 ( 0.078)\tLoss 1.4277e+01 (1.2087e+01)\tAcc@1  92.19 ( 93.60)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [3][200/704]\tTime  0.073 ( 0.077)\tLoss 1.2029e+01 (1.2176e+01)\tAcc@1  93.75 ( 93.57)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [3][300/704]\tTime  0.074 ( 0.076)\tLoss 1.8841e+01 (1.2800e+01)\tAcc@1  90.62 ( 93.27)\tAcc@5  96.88 ( 99.86)\n",
            "Epoch: [3][400/704]\tTime  0.073 ( 0.076)\tLoss 8.5294e+00 (1.3392e+01)\tAcc@1  98.44 ( 92.91)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [3][500/704]\tTime  0.075 ( 0.076)\tLoss 1.6008e+01 (1.3568e+01)\tAcc@1  89.06 ( 92.82)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [3][600/704]\tTime  0.073 ( 0.075)\tLoss 1.5629e+01 (1.3737e+01)\tAcc@1  89.06 ( 92.62)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [3][700/704]\tTime  0.070 ( 0.075)\tLoss 1.4773e+01 (1.4259e+01)\tAcc@1  90.62 ( 92.38)\tAcc@5  98.44 ( 99.88)\n",
            "==> Train Accuracy: Acc@1 92.378 || Acc@5 99.884\n",
            "==> Valid Accuracy:  Acc@1 87.720 || Acc@5 99.520\n",
            "Epoch: [4][  0/704]\tTime  0.441 ( 0.441)\tLoss 1.6487e+01 (1.6487e+01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.073 ( 0.079)\tLoss 1.2863e+01 (1.2734e+01)\tAcc@1  93.75 ( 93.21)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [4][200/704]\tTime  0.075 ( 0.077)\tLoss 1.0815e+01 (1.2621e+01)\tAcc@1  93.75 ( 93.24)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [4][300/704]\tTime  0.073 ( 0.076)\tLoss 9.2582e+00 (1.2637e+01)\tAcc@1  95.31 ( 93.08)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [4][400/704]\tTime  0.074 ( 0.076)\tLoss 1.2360e+01 (1.2441e+01)\tAcc@1  92.19 ( 93.17)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [4][500/704]\tTime  0.074 ( 0.076)\tLoss 7.6407e+00 (1.2654e+01)\tAcc@1  98.44 ( 93.08)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [4][600/704]\tTime  0.074 ( 0.076)\tLoss 2.0473e+01 (1.2837e+01)\tAcc@1  90.62 ( 92.90)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [4][700/704]\tTime  0.070 ( 0.075)\tLoss 8.0341e+00 (1.2796e+01)\tAcc@1  96.88 ( 92.96)\tAcc@5 100.00 ( 99.94)\n",
            "==> Train Accuracy: Acc@1 92.964 || Acc@5 99.936\n",
            "==> Valid Accuracy:  Acc@1 89.180 || Acc@5 99.740\n",
            "Epoch: [5][  0/704]\tTime  0.298 ( 0.298)\tLoss 4.3892e+00 (4.3892e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.074 ( 0.077)\tLoss 3.8964e+00 (9.2522e+00)\tAcc@1  98.44 ( 94.80)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [5][200/704]\tTime  0.074 ( 0.076)\tLoss 7.5833e+00 (8.3672e+00)\tAcc@1  93.75 ( 95.55)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [5][300/704]\tTime  0.075 ( 0.076)\tLoss 3.9032e+00 (7.9794e+00)\tAcc@1  98.44 ( 95.78)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [5][400/704]\tTime  0.074 ( 0.075)\tLoss 4.9426e+00 (7.7760e+00)\tAcc@1  93.75 ( 95.94)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [5][500/704]\tTime  0.073 ( 0.075)\tLoss 4.8858e+00 (7.3500e+00)\tAcc@1  98.44 ( 96.15)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [5][600/704]\tTime  0.076 ( 0.075)\tLoss 6.6186e+00 (7.2495e+00)\tAcc@1  96.88 ( 96.23)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [5][700/704]\tTime  0.072 ( 0.075)\tLoss 7.4697e+00 (7.0894e+00)\tAcc@1  93.75 ( 96.29)\tAcc@5 100.00 ( 99.97)\n",
            "==> Train Accuracy: Acc@1 96.291 || Acc@5 99.971\n",
            "==> Valid Accuracy:  Acc@1 92.580 || Acc@5 99.820\n",
            "Epoch: [6][  0/704]\tTime  0.436 ( 0.436)\tLoss 3.8285e+00 (3.8285e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.074 ( 0.078)\tLoss 1.9607e+00 (4.6039e+00)\tAcc@1 100.00 ( 97.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][200/704]\tTime  0.074 ( 0.077)\tLoss 3.0488e+00 (4.9087e+00)\tAcc@1  98.44 ( 97.29)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [6][300/704]\tTime  0.075 ( 0.076)\tLoss 1.9765e+00 (4.8827e+00)\tAcc@1 100.00 ( 97.37)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [6][400/704]\tTime  0.075 ( 0.076)\tLoss 3.2566e+00 (4.8321e+00)\tAcc@1  98.44 ( 97.45)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [6][500/704]\tTime  0.075 ( 0.076)\tLoss 1.1381e+00 (4.8206e+00)\tAcc@1 100.00 ( 97.46)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [6][600/704]\tTime  0.073 ( 0.076)\tLoss 2.7346e+00 (4.8764e+00)\tAcc@1  98.44 ( 97.43)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [6][700/704]\tTime  0.071 ( 0.075)\tLoss 4.4204e+00 (4.9768e+00)\tAcc@1  95.31 ( 97.40)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 97.404 || Acc@5 99.980\n",
            "==> Valid Accuracy:  Acc@1 93.160 || Acc@5 99.800\n",
            "Epoch: [7][  0/704]\tTime  0.318 ( 0.318)\tLoss 4.3144e+00 (4.3144e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.074 ( 0.077)\tLoss 3.8291e+00 (4.1749e+00)\tAcc@1  96.88 ( 97.91)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [7][200/704]\tTime  0.075 ( 0.077)\tLoss 6.3366e+00 (4.1007e+00)\tAcc@1  96.88 ( 97.93)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [7][300/704]\tTime  0.074 ( 0.076)\tLoss 1.9968e+00 (4.3392e+00)\tAcc@1 100.00 ( 97.75)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [7][400/704]\tTime  0.074 ( 0.076)\tLoss 1.0047e+01 (4.3371e+00)\tAcc@1  95.31 ( 97.76)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [7][500/704]\tTime  0.077 ( 0.076)\tLoss 1.6329e+00 (4.2538e+00)\tAcc@1 100.00 ( 97.77)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [7][600/704]\tTime  0.074 ( 0.076)\tLoss 4.4360e+00 (4.2059e+00)\tAcc@1  96.88 ( 97.78)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [7][700/704]\tTime  0.072 ( 0.075)\tLoss 4.4521e+00 (4.1800e+00)\tAcc@1  96.88 ( 97.82)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 97.813 || Acc@5 99.982\n",
            "==> Valid Accuracy:  Acc@1 93.140 || Acc@5 99.820\n",
            "Best Top-1 Accuracy for fold4: 93.16\n",
            "\n",
            "FOLD 5\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.402 ( 0.402)\tLoss 6.0679e+00 (6.0679e+00)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][100/704]\tTime  0.074 ( 0.078)\tLoss 3.9056e+00 (1.0445e+01)\tAcc@1  98.44 ( 94.23)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [0][200/704]\tTime  0.075 ( 0.076)\tLoss 1.1278e+01 (1.0503e+01)\tAcc@1  95.31 ( 94.30)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [0][300/704]\tTime  0.074 ( 0.076)\tLoss 1.1287e+01 (1.1348e+01)\tAcc@1  96.88 ( 93.81)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [0][400/704]\tTime  0.075 ( 0.075)\tLoss 5.7136e+00 (1.1397e+01)\tAcc@1  96.88 ( 93.74)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [0][500/704]\tTime  0.074 ( 0.075)\tLoss 1.6735e+01 (1.1869e+01)\tAcc@1  90.62 ( 93.44)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [0][600/704]\tTime  0.075 ( 0.075)\tLoss 1.1082e+01 (1.2186e+01)\tAcc@1  90.62 ( 93.27)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [0][700/704]\tTime  0.072 ( 0.075)\tLoss 1.7552e+01 (1.2227e+01)\tAcc@1  90.62 ( 93.26)\tAcc@5  98.44 ( 99.89)\n",
            "==> Train Accuracy: Acc@1 93.264 || Acc@5 99.889\n",
            "==> Valid Accuracy:  Acc@1 93.780 || Acc@5 99.920\n",
            "Epoch: [1][  0/704]\tTime  0.344 ( 0.344)\tLoss 1.3503e+01 (1.3503e+01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.073 ( 0.077)\tLoss 5.2326e+00 (9.9404e+00)\tAcc@1  98.44 ( 94.48)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [1][200/704]\tTime  0.073 ( 0.077)\tLoss 6.9934e+00 (1.0396e+01)\tAcc@1  96.88 ( 94.23)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [1][300/704]\tTime  0.073 ( 0.076)\tLoss 9.8385e+00 (1.0778e+01)\tAcc@1  93.75 ( 93.98)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [1][400/704]\tTime  0.075 ( 0.076)\tLoss 1.4344e+01 (1.0948e+01)\tAcc@1  90.62 ( 93.93)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [1][500/704]\tTime  0.073 ( 0.076)\tLoss 1.0983e+01 (1.1061e+01)\tAcc@1  95.31 ( 93.89)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [1][600/704]\tTime  0.073 ( 0.075)\tLoss 6.2449e+01 (1.1875e+01)\tAcc@1  71.88 ( 93.65)\tAcc@5  95.31 ( 99.90)\n",
            "Epoch: [1][700/704]\tTime  0.072 ( 0.075)\tLoss 2.0748e+01 (1.4462e+01)\tAcc@1  85.94 ( 92.43)\tAcc@5 100.00 ( 99.83)\n",
            "==> Train Accuracy: Acc@1 92.422 || Acc@5 99.824\n",
            "==> Valid Accuracy:  Acc@1 88.780 || Acc@5 99.840\n",
            "Epoch: [2][  0/704]\tTime  0.401 ( 0.401)\tLoss 1.1104e+01 (1.1104e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.074 ( 0.078)\tLoss 2.0308e+00 (1.3240e+01)\tAcc@1 100.00 ( 92.71)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [2][200/704]\tTime  0.082 ( 0.076)\tLoss 7.0282e+00 (1.2312e+01)\tAcc@1  98.44 ( 93.28)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [2][300/704]\tTime  0.074 ( 0.076)\tLoss 5.7355e+00 (1.1920e+01)\tAcc@1  96.88 ( 93.55)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [2][400/704]\tTime  0.073 ( 0.076)\tLoss 9.0177e+00 (1.1359e+01)\tAcc@1  93.75 ( 93.89)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [2][500/704]\tTime  0.077 ( 0.075)\tLoss 1.0178e+01 (1.1300e+01)\tAcc@1  95.31 ( 93.90)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [2][600/704]\tTime  0.074 ( 0.075)\tLoss 9.7103e+00 (1.1139e+01)\tAcc@1  95.31 ( 94.00)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [2][700/704]\tTime  0.070 ( 0.075)\tLoss 5.7630e+00 (1.1077e+01)\tAcc@1  96.88 ( 94.09)\tAcc@5 100.00 ( 99.94)\n",
            "==> Train Accuracy: Acc@1 94.084 || Acc@5 99.942\n",
            "==> Valid Accuracy:  Acc@1 93.080 || Acc@5 99.960\n",
            "Epoch: [3][  0/704]\tTime  0.322 ( 0.322)\tLoss 7.3610e+00 (7.3610e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.074 ( 0.077)\tLoss 6.0958e+00 (7.9905e+00)\tAcc@1  98.44 ( 95.81)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [3][200/704]\tTime  0.075 ( 0.076)\tLoss 5.9276e+00 (8.6518e+00)\tAcc@1  95.31 ( 95.40)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [3][300/704]\tTime  0.073 ( 0.076)\tLoss 2.0232e+01 (8.8919e+00)\tAcc@1  93.75 ( 95.23)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [3][400/704]\tTime  0.075 ( 0.076)\tLoss 1.0893e+01 (9.2506e+00)\tAcc@1  96.88 ( 95.12)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [3][500/704]\tTime  0.074 ( 0.076)\tLoss 1.0304e+01 (9.2924e+00)\tAcc@1  92.19 ( 95.06)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [3][600/704]\tTime  0.074 ( 0.075)\tLoss 1.0680e+01 (9.2927e+00)\tAcc@1  90.62 ( 95.06)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [3][700/704]\tTime  0.073 ( 0.075)\tLoss 4.8152e+00 (9.3456e+00)\tAcc@1  96.88 ( 95.01)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 94.998 || Acc@5 99.964\n",
            "==> Valid Accuracy:  Acc@1 93.120 || Acc@5 99.860\n",
            "Epoch: [4][  0/704]\tTime  0.307 ( 0.307)\tLoss 2.5659e+00 (2.5659e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.074 ( 0.077)\tLoss 1.3325e+01 (8.0888e+00)\tAcc@1  93.75 ( 95.78)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][200/704]\tTime  0.073 ( 0.076)\tLoss 1.5369e+01 (8.2892e+00)\tAcc@1  90.62 ( 95.56)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][300/704]\tTime  0.075 ( 0.076)\tLoss 6.3587e+00 (8.3056e+00)\tAcc@1  93.75 ( 95.57)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][400/704]\tTime  0.073 ( 0.076)\tLoss 3.5906e+00 (8.3290e+00)\tAcc@1  98.44 ( 95.53)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][500/704]\tTime  0.074 ( 0.076)\tLoss 3.6284e+00 (8.3289e+00)\tAcc@1  98.44 ( 95.56)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][600/704]\tTime  0.074 ( 0.075)\tLoss 5.2172e+00 (8.5002e+00)\tAcc@1  98.44 ( 95.46)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][700/704]\tTime  0.071 ( 0.075)\tLoss 1.1699e+01 (8.5523e+00)\tAcc@1  93.75 ( 95.40)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 95.398 || Acc@5 99.976\n",
            "==> Valid Accuracy:  Acc@1 90.780 || Acc@5 99.940\n",
            "Epoch: [5][  0/704]\tTime  0.399 ( 0.399)\tLoss 2.4984e+01 (2.4984e+01)\tAcc@1  85.94 ( 85.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.074 ( 0.078)\tLoss 8.7710e+00 (6.4295e+00)\tAcc@1  93.75 ( 96.47)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][200/704]\tTime  0.074 ( 0.076)\tLoss 1.7083e+00 (5.7870e+00)\tAcc@1  98.44 ( 96.88)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [5][300/704]\tTime  0.074 ( 0.076)\tLoss 6.1972e+00 (5.4354e+00)\tAcc@1  95.31 ( 97.09)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][400/704]\tTime  0.075 ( 0.075)\tLoss 7.5442e+00 (5.2654e+00)\tAcc@1  95.31 ( 97.17)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][500/704]\tTime  0.074 ( 0.075)\tLoss 3.4245e+00 (5.0238e+00)\tAcc@1  98.44 ( 97.35)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][600/704]\tTime  0.084 ( 0.075)\tLoss 1.1006e+00 (4.7854e+00)\tAcc@1 100.00 ( 97.47)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][700/704]\tTime  0.072 ( 0.075)\tLoss 3.7346e+00 (4.6249e+00)\tAcc@1  98.44 ( 97.58)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 97.576 || Acc@5 99.982\n",
            "==> Valid Accuracy:  Acc@1 94.920 || Acc@5 99.880\n",
            "Epoch: [6][  0/704]\tTime  0.328 ( 0.328)\tLoss 1.3087e+00 (1.3087e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.074 ( 0.077)\tLoss 2.5618e+00 (2.8274e+00)\tAcc@1  98.44 ( 98.56)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][200/704]\tTime  0.073 ( 0.077)\tLoss 4.3744e+00 (2.9691e+00)\tAcc@1  96.88 ( 98.51)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][300/704]\tTime  0.073 ( 0.076)\tLoss 5.5495e+00 (3.0093e+00)\tAcc@1  96.88 ( 98.48)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [6][400/704]\tTime  0.073 ( 0.076)\tLoss 2.6880e+00 (2.9723e+00)\tAcc@1  96.88 ( 98.50)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][500/704]\tTime  0.073 ( 0.075)\tLoss 5.1675e+00 (2.9502e+00)\tAcc@1  98.44 ( 98.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][600/704]\tTime  0.074 ( 0.075)\tLoss 1.7541e+00 (2.9073e+00)\tAcc@1  98.44 ( 98.53)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [6][700/704]\tTime  0.072 ( 0.075)\tLoss 5.7014e-01 (2.8985e+00)\tAcc@1 100.00 ( 98.55)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 98.556 || Acc@5 99.996\n",
            "==> Valid Accuracy:  Acc@1 95.360 || Acc@5 99.960\n",
            "Epoch: [7][  0/704]\tTime  0.428 ( 0.428)\tLoss 4.5016e-01 (4.5016e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.076 ( 0.078)\tLoss 1.3797e+00 (2.5938e+00)\tAcc@1 100.00 ( 98.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][200/704]\tTime  0.074 ( 0.077)\tLoss 1.0528e+00 (2.4498e+00)\tAcc@1 100.00 ( 98.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][300/704]\tTime  0.073 ( 0.076)\tLoss 6.9122e+00 (2.5699e+00)\tAcc@1  96.88 ( 98.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][400/704]\tTime  0.078 ( 0.076)\tLoss 1.0609e+00 (2.4694e+00)\tAcc@1 100.00 ( 98.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][500/704]\tTime  0.075 ( 0.076)\tLoss 1.8041e+00 (2.4685e+00)\tAcc@1  98.44 ( 98.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][600/704]\tTime  0.076 ( 0.076)\tLoss 4.2480e+00 (2.4675e+00)\tAcc@1  96.88 ( 98.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][700/704]\tTime  0.071 ( 0.075)\tLoss 3.0127e+00 (2.4570e+00)\tAcc@1  96.88 ( 98.74)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 98.740 || Acc@5 100.000\n",
            "==> Valid Accuracy:  Acc@1 95.720 || Acc@5 99.980\n",
            "Best Top-1 Accuracy for fold5: 95.72\n",
            "\n",
            "FOLD 6\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.393 ( 0.393)\tLoss 3.7093e+00 (3.7093e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][100/704]\tTime  0.074 ( 0.078)\tLoss 3.1563e+00 (7.6434e+00)\tAcc@1  98.44 ( 96.12)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [0][200/704]\tTime  0.073 ( 0.077)\tLoss 1.2491e+01 (7.5836e+00)\tAcc@1  95.31 ( 96.06)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [0][300/704]\tTime  0.073 ( 0.076)\tLoss 4.8503e+00 (7.6087e+00)\tAcc@1  95.31 ( 96.02)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [0][400/704]\tTime  0.074 ( 0.076)\tLoss 1.0210e+01 (7.8000e+00)\tAcc@1  92.19 ( 95.87)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][500/704]\tTime  0.074 ( 0.075)\tLoss 9.2364e+00 (8.1246e+00)\tAcc@1  93.75 ( 95.65)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [0][600/704]\tTime  0.073 ( 0.075)\tLoss 1.1490e+01 (8.6759e+00)\tAcc@1  93.75 ( 95.40)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [0][700/704]\tTime  0.072 ( 0.075)\tLoss 8.5838e+00 (8.7700e+00)\tAcc@1  96.88 ( 95.31)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 95.296 || Acc@5 99.956\n",
            "==> Valid Accuracy:  Acc@1 95.180 || Acc@5 99.980\n",
            "Epoch: [1][  0/704]\tTime  0.458 ( 0.458)\tLoss 1.1102e+01 (1.1102e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.074 ( 0.079)\tLoss 3.1344e+01 (6.7621e+00)\tAcc@1  82.81 ( 96.41)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][200/704]\tTime  0.077 ( 0.077)\tLoss 2.0745e+01 (1.5806e+01)\tAcc@1  84.38 ( 92.82)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [1][300/704]\tTime  0.076 ( 0.077)\tLoss 1.2835e+01 (1.6854e+01)\tAcc@1  93.75 ( 92.03)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [1][400/704]\tTime  0.075 ( 0.076)\tLoss 1.5107e+01 (1.6057e+01)\tAcc@1  93.75 ( 92.21)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [1][500/704]\tTime  0.073 ( 0.076)\tLoss 3.4950e+00 (1.5128e+01)\tAcc@1  96.88 ( 92.51)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [1][600/704]\tTime  0.074 ( 0.076)\tLoss 5.5930e+00 (1.4132e+01)\tAcc@1  95.31 ( 92.92)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [1][700/704]\tTime  0.071 ( 0.076)\tLoss 5.5914e+00 (1.3308e+01)\tAcc@1  96.88 ( 93.28)\tAcc@5 100.00 ( 99.88)\n",
            "==> Train Accuracy: Acc@1 93.280 || Acc@5 99.884\n",
            "==> Valid Accuracy:  Acc@1 94.640 || Acc@5 100.000\n",
            "Epoch: [2][  0/704]\tTime  0.293 ( 0.293)\tLoss 4.9182e+00 (4.9182e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.074 ( 0.077)\tLoss 9.1096e+00 (6.9549e+00)\tAcc@1  93.75 ( 96.29)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [2][200/704]\tTime  0.075 ( 0.076)\tLoss 7.0180e+00 (6.5167e+00)\tAcc@1  96.88 ( 96.50)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [2][300/704]\tTime  0.075 ( 0.075)\tLoss 7.3572e+00 (6.6253e+00)\tAcc@1  92.19 ( 96.42)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [2][400/704]\tTime  0.078 ( 0.075)\tLoss 3.9474e+00 (6.6132e+00)\tAcc@1  95.31 ( 96.38)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [2][500/704]\tTime  0.073 ( 0.075)\tLoss 6.4091e+00 (6.7018e+00)\tAcc@1  96.88 ( 96.33)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [2][600/704]\tTime  0.075 ( 0.075)\tLoss 8.3656e+00 (6.8532e+00)\tAcc@1  95.31 ( 96.28)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [2][700/704]\tTime  0.069 ( 0.075)\tLoss 3.4155e+00 (6.7602e+00)\tAcc@1  96.88 ( 96.33)\tAcc@5 100.00 ( 99.97)\n",
            "==> Train Accuracy: Acc@1 96.327 || Acc@5 99.973\n",
            "==> Valid Accuracy:  Acc@1 95.220 || Acc@5 99.980\n",
            "Epoch: [3][  0/704]\tTime  0.417 ( 0.417)\tLoss 6.8192e+00 (6.8192e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.074 ( 0.078)\tLoss 6.8100e+00 (5.9333e+00)\tAcc@1  96.88 ( 96.81)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [3][200/704]\tTime  0.074 ( 0.077)\tLoss 5.1976e+00 (5.9695e+00)\tAcc@1  95.31 ( 96.75)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [3][300/704]\tTime  0.074 ( 0.076)\tLoss 5.5161e+00 (5.9020e+00)\tAcc@1  95.31 ( 96.77)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [3][400/704]\tTime  0.074 ( 0.076)\tLoss 5.3860e+00 (6.0936e+00)\tAcc@1  98.44 ( 96.72)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [3][500/704]\tTime  0.074 ( 0.076)\tLoss 4.0869e+00 (6.2883e+00)\tAcc@1  95.31 ( 96.56)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [3][600/704]\tTime  0.074 ( 0.076)\tLoss 1.7537e+01 (6.4192e+00)\tAcc@1  92.19 ( 96.51)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [3][700/704]\tTime  0.071 ( 0.076)\tLoss 7.5533e+00 (6.5778e+00)\tAcc@1  92.19 ( 96.45)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 96.447 || Acc@5 99.980\n",
            "==> Valid Accuracy:  Acc@1 94.740 || Acc@5 99.960\n",
            "Epoch: [4][  0/704]\tTime  0.319 ( 0.319)\tLoss 1.0147e+01 (1.0147e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.076 ( 0.078)\tLoss 6.0330e+00 (6.2848e+00)\tAcc@1  96.88 ( 96.69)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [4][200/704]\tTime  0.075 ( 0.078)\tLoss 5.7074e+00 (6.2349e+00)\tAcc@1  96.88 ( 96.77)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [4][300/704]\tTime  0.076 ( 0.078)\tLoss 8.5340e+00 (6.1430e+00)\tAcc@1  95.31 ( 96.77)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [4][400/704]\tTime  0.074 ( 0.077)\tLoss 1.4025e+01 (6.3165e+00)\tAcc@1  93.75 ( 96.70)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [4][500/704]\tTime  0.076 ( 0.077)\tLoss 7.5232e+00 (6.4233e+00)\tAcc@1  95.31 ( 96.65)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [4][600/704]\tTime  0.075 ( 0.076)\tLoss 1.9027e+01 (6.5067e+00)\tAcc@1  92.19 ( 96.58)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [4][700/704]\tTime  0.072 ( 0.076)\tLoss 1.2081e+01 (6.7542e+00)\tAcc@1  90.62 ( 96.42)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 96.422 || Acc@5 99.962\n",
            "==> Valid Accuracy:  Acc@1 93.820 || Acc@5 100.000\n",
            "Epoch: [5][  0/704]\tTime  0.400 ( 0.400)\tLoss 1.8328e+00 (1.8328e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.075 ( 0.078)\tLoss 1.7770e+00 (4.6400e+00)\tAcc@1 100.00 ( 97.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][200/704]\tTime  0.076 ( 0.077)\tLoss 2.2191e+00 (4.5021e+00)\tAcc@1  98.44 ( 97.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][300/704]\tTime  0.073 ( 0.076)\tLoss 1.2740e+00 (4.1941e+00)\tAcc@1 100.00 ( 97.88)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [5][400/704]\tTime  0.077 ( 0.076)\tLoss 2.3150e+00 (3.9485e+00)\tAcc@1 100.00 ( 98.02)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][500/704]\tTime  0.074 ( 0.076)\tLoss 1.6485e+00 (3.7309e+00)\tAcc@1  98.44 ( 98.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][600/704]\tTime  0.074 ( 0.075)\tLoss 1.4980e+00 (3.5834e+00)\tAcc@1 100.00 ( 98.22)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [5][700/704]\tTime  0.072 ( 0.075)\tLoss 7.1557e+00 (3.5101e+00)\tAcc@1  98.44 ( 98.23)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 98.231 || Acc@5 99.996\n",
            "==> Valid Accuracy:  Acc@1 96.340 || Acc@5 100.000\n",
            "Epoch: [6][  0/704]\tTime  0.415 ( 0.415)\tLoss 1.4758e+00 (1.4758e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.073 ( 0.078)\tLoss 1.1571e+00 (2.5574e+00)\tAcc@1  98.44 ( 98.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][200/704]\tTime  0.075 ( 0.078)\tLoss 7.4953e-01 (2.5068e+00)\tAcc@1 100.00 ( 98.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][300/704]\tTime  0.076 ( 0.077)\tLoss 3.0767e+00 (2.5730e+00)\tAcc@1  98.44 ( 98.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][400/704]\tTime  0.073 ( 0.076)\tLoss 1.2514e+00 (2.4278e+00)\tAcc@1 100.00 ( 98.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][500/704]\tTime  0.074 ( 0.076)\tLoss 2.0397e+00 (2.3816e+00)\tAcc@1  98.44 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][600/704]\tTime  0.076 ( 0.076)\tLoss 3.4222e+00 (2.3925e+00)\tAcc@1  98.44 ( 98.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][700/704]\tTime  0.070 ( 0.076)\tLoss 8.3860e-01 (2.3563e+00)\tAcc@1 100.00 ( 98.81)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 98.809 || Acc@5 100.000\n",
            "==> Valid Accuracy:  Acc@1 96.860 || Acc@5 100.000\n",
            "Epoch: [7][  0/704]\tTime  0.350 ( 0.350)\tLoss 2.8406e+00 (2.8406e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.077 ( 0.078)\tLoss 3.2710e+00 (1.9000e+00)\tAcc@1  98.44 ( 99.10)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [7][200/704]\tTime  0.074 ( 0.077)\tLoss 2.0745e+00 (2.0154e+00)\tAcc@1 100.00 ( 99.04)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [7][300/704]\tTime  0.077 ( 0.076)\tLoss 2.0384e+00 (1.8862e+00)\tAcc@1  98.44 ( 99.11)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [7][400/704]\tTime  0.076 ( 0.076)\tLoss 1.3110e+00 (1.8737e+00)\tAcc@1 100.00 ( 99.13)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][500/704]\tTime  0.075 ( 0.076)\tLoss 1.9540e+00 (1.8051e+00)\tAcc@1  98.44 ( 99.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][600/704]\tTime  0.076 ( 0.076)\tLoss 2.3340e-01 (1.7869e+00)\tAcc@1 100.00 ( 99.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][700/704]\tTime  0.071 ( 0.075)\tLoss 4.6484e+00 (1.7486e+00)\tAcc@1  96.88 ( 99.17)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.176 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 96.740 || Acc@5 100.000\n",
            "Best Top-1 Accuracy for fold6: 96.86\n",
            "\n",
            "FOLD 7\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.422 ( 0.422)\tLoss 1.6714e+00 (1.6714e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][100/704]\tTime  0.075 ( 0.078)\tLoss 6.4899e+00 (5.7790e+00)\tAcc@1  95.31 ( 96.78)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][200/704]\tTime  0.073 ( 0.076)\tLoss 2.6316e+00 (6.0628e+00)\tAcc@1  98.44 ( 96.64)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][300/704]\tTime  0.081 ( 0.076)\tLoss 3.1227e+00 (6.1056e+00)\tAcc@1  98.44 ( 96.71)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][400/704]\tTime  0.076 ( 0.076)\tLoss 1.8651e+01 (6.2779e+00)\tAcc@1  92.19 ( 96.64)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][500/704]\tTime  0.073 ( 0.076)\tLoss 3.4258e+00 (6.2534e+00)\tAcc@1  96.88 ( 96.65)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][600/704]\tTime  0.073 ( 0.075)\tLoss 7.9450e+00 (6.4507e+00)\tAcc@1  93.75 ( 96.54)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][700/704]\tTime  0.071 ( 0.075)\tLoss 9.6685e+00 (6.4645e+00)\tAcc@1  93.75 ( 96.54)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 96.547 || Acc@5 99.978\n",
            "==> Valid Accuracy:  Acc@1 97.040 || Acc@5 100.000\n",
            "Epoch: [1][  0/704]\tTime  0.352 ( 0.352)\tLoss 1.1115e+01 (1.1115e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.075 ( 0.078)\tLoss 8.8370e+00 (6.1775e+00)\tAcc@1  96.88 ( 96.78)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [1][200/704]\tTime  0.073 ( 0.077)\tLoss 2.9159e+00 (5.6920e+00)\tAcc@1  98.44 ( 97.02)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][300/704]\tTime  0.074 ( 0.076)\tLoss 9.8129e+00 (5.8901e+00)\tAcc@1  93.75 ( 96.80)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][400/704]\tTime  0.077 ( 0.076)\tLoss 4.1912e+00 (6.2290e+00)\tAcc@1  98.44 ( 96.61)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][500/704]\tTime  0.074 ( 0.076)\tLoss 5.0184e+00 (6.3359e+00)\tAcc@1  96.88 ( 96.53)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][600/704]\tTime  0.074 ( 0.075)\tLoss 3.0379e+00 (6.4912e+00)\tAcc@1  98.44 ( 96.49)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][700/704]\tTime  0.071 ( 0.075)\tLoss 5.2355e+00 (6.5266e+00)\tAcc@1  96.88 ( 96.47)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 96.469 || Acc@5 99.984\n",
            "==> Valid Accuracy:  Acc@1 95.920 || Acc@5 100.000\n",
            "Epoch: [2][  0/704]\tTime  0.410 ( 0.410)\tLoss 1.0556e+01 (1.0556e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.073 ( 0.078)\tLoss 6.7248e+00 (5.5109e+00)\tAcc@1  92.19 ( 97.22)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [2][200/704]\tTime  0.074 ( 0.076)\tLoss 7.5538e+00 (5.7011e+00)\tAcc@1  93.75 ( 97.01)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [2][300/704]\tTime  0.075 ( 0.076)\tLoss 5.6306e+00 (5.6580e+00)\tAcc@1  95.31 ( 97.03)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [2][400/704]\tTime  0.074 ( 0.075)\tLoss 8.0872e+00 (5.5730e+00)\tAcc@1  96.88 ( 97.04)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [2][500/704]\tTime  0.074 ( 0.075)\tLoss 3.1801e+00 (5.8587e+00)\tAcc@1  98.44 ( 96.87)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [2][600/704]\tTime  0.073 ( 0.075)\tLoss 4.2707e+00 (6.0263e+00)\tAcc@1  98.44 ( 96.78)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][700/704]\tTime  0.070 ( 0.075)\tLoss 6.6885e+00 (6.1474e+00)\tAcc@1  96.88 ( 96.71)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 96.707 || Acc@5 99.987\n",
            "==> Valid Accuracy:  Acc@1 95.640 || Acc@5 100.000\n",
            "Epoch: [3][  0/704]\tTime  0.321 ( 0.321)\tLoss 6.6093e+00 (6.6093e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.074 ( 0.077)\tLoss 2.1258e+01 (9.3641e+00)\tAcc@1  85.94 ( 95.45)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [3][200/704]\tTime  0.077 ( 0.076)\tLoss 5.7368e+00 (9.1457e+00)\tAcc@1  96.88 ( 95.37)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [3][300/704]\tTime  0.073 ( 0.075)\tLoss 1.5387e+01 (1.3794e+01)\tAcc@1  93.75 ( 93.53)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [3][400/704]\tTime  0.073 ( 0.075)\tLoss 6.3968e+00 (1.5442e+01)\tAcc@1  98.44 ( 92.70)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [3][500/704]\tTime  0.073 ( 0.075)\tLoss 8.7853e+00 (1.4573e+01)\tAcc@1  93.75 ( 92.94)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [3][600/704]\tTime  0.074 ( 0.075)\tLoss 8.2209e+00 (1.4251e+01)\tAcc@1  98.44 ( 93.05)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [3][700/704]\tTime  0.072 ( 0.075)\tLoss 5.5164e+00 (1.3611e+01)\tAcc@1  95.31 ( 93.32)\tAcc@5 100.00 ( 99.88)\n",
            "==> Train Accuracy: Acc@1 93.322 || Acc@5 99.880\n",
            "==> Valid Accuracy:  Acc@1 94.880 || Acc@5 99.960\n",
            "Epoch: [4][  0/704]\tTime  0.371 ( 0.371)\tLoss 7.5640e+00 (7.5640e+00)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.073 ( 0.078)\tLoss 1.2631e+01 (7.3149e+00)\tAcc@1  92.19 ( 96.18)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][200/704]\tTime  0.075 ( 0.076)\tLoss 5.8782e+00 (8.1622e+00)\tAcc@1  95.31 ( 96.00)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [4][300/704]\tTime  0.075 ( 0.076)\tLoss 5.3649e+00 (7.3693e+00)\tAcc@1  95.31 ( 96.31)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [4][400/704]\tTime  0.076 ( 0.076)\tLoss 1.6089e+00 (7.1006e+00)\tAcc@1 100.00 ( 96.37)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [4][500/704]\tTime  0.074 ( 0.075)\tLoss 5.5952e+00 (6.8737e+00)\tAcc@1  96.88 ( 96.46)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [4][600/704]\tTime  0.076 ( 0.075)\tLoss 4.7347e+00 (6.6818e+00)\tAcc@1  96.88 ( 96.52)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [4][700/704]\tTime  0.071 ( 0.075)\tLoss 5.7867e+00 (6.6522e+00)\tAcc@1  96.88 ( 96.53)\tAcc@5 100.00 ( 99.97)\n",
            "==> Train Accuracy: Acc@1 96.531 || Acc@5 99.973\n",
            "==> Valid Accuracy:  Acc@1 94.960 || Acc@5 99.960\n",
            "Epoch: [5][  0/704]\tTime  0.306 ( 0.306)\tLoss 5.2092e+00 (5.2092e+00)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.075 ( 0.077)\tLoss 1.9491e+00 (4.2783e+00)\tAcc@1 100.00 ( 97.63)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][200/704]\tTime  0.075 ( 0.076)\tLoss 3.7407e+00 (4.1788e+00)\tAcc@1  98.44 ( 97.85)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][300/704]\tTime  0.074 ( 0.075)\tLoss 1.7348e+00 (3.8810e+00)\tAcc@1 100.00 ( 98.02)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][400/704]\tTime  0.073 ( 0.075)\tLoss 6.3032e+00 (3.5748e+00)\tAcc@1  96.88 ( 98.20)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][500/704]\tTime  0.073 ( 0.075)\tLoss 7.8651e-01 (3.5271e+00)\tAcc@1 100.00 ( 98.25)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][600/704]\tTime  0.074 ( 0.075)\tLoss 4.2874e+00 (3.4595e+00)\tAcc@1  98.44 ( 98.27)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [5][700/704]\tTime  0.071 ( 0.075)\tLoss 9.4889e-01 (3.2814e+00)\tAcc@1 100.00 ( 98.35)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 98.356 || Acc@5 99.984\n",
            "==> Valid Accuracy:  Acc@1 96.860 || Acc@5 100.000\n",
            "Epoch: [6][  0/704]\tTime  0.419 ( 0.419)\tLoss 5.9292e-01 (5.9292e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.075 ( 0.079)\tLoss 1.0980e+00 (2.4328e+00)\tAcc@1 100.00 ( 98.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][200/704]\tTime  0.074 ( 0.077)\tLoss 3.3187e-01 (2.4686e+00)\tAcc@1 100.00 ( 98.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][300/704]\tTime  0.070 ( 0.076)\tLoss 2.0262e+00 (2.4331e+00)\tAcc@1  98.44 ( 98.74)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [6][400/704]\tTime  0.074 ( 0.076)\tLoss 5.2992e-01 (2.3371e+00)\tAcc@1 100.00 ( 98.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][500/704]\tTime  0.073 ( 0.076)\tLoss 3.0800e+00 (2.2430e+00)\tAcc@1  98.44 ( 98.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][600/704]\tTime  0.078 ( 0.075)\tLoss 1.1309e+00 (2.3051e+00)\tAcc@1 100.00 ( 98.85)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [6][700/704]\tTime  0.071 ( 0.075)\tLoss 8.1624e-01 (2.3550e+00)\tAcc@1 100.00 ( 98.84)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.840 || Acc@5 99.993\n",
            "==> Valid Accuracy:  Acc@1 97.120 || Acc@5 100.000\n",
            "Epoch: [7][  0/704]\tTime  0.331 ( 0.331)\tLoss 5.3216e-01 (5.3216e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.074 ( 0.077)\tLoss 6.4485e-01 (1.9998e+00)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][200/704]\tTime  0.077 ( 0.077)\tLoss 1.7130e+00 (2.1652e+00)\tAcc@1  98.44 ( 98.98)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [7][300/704]\tTime  0.074 ( 0.076)\tLoss 4.3984e+00 (2.0940e+00)\tAcc@1  95.31 ( 99.01)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [7][400/704]\tTime  0.073 ( 0.076)\tLoss 3.4350e+00 (2.0756e+00)\tAcc@1  96.88 ( 99.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][500/704]\tTime  0.074 ( 0.076)\tLoss 2.8702e+00 (1.9894e+00)\tAcc@1  98.44 ( 99.02)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][600/704]\tTime  0.076 ( 0.076)\tLoss 5.7653e-01 (1.9143e+00)\tAcc@1 100.00 ( 99.06)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][700/704]\tTime  0.071 ( 0.075)\tLoss 1.2271e+00 (1.8523e+00)\tAcc@1 100.00 ( 99.10)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.098 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 97.180 || Acc@5 100.000\n",
            "Best Top-1 Accuracy for fold7: 97.18\n",
            "\n",
            "FOLD 8\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.346 ( 0.346)\tLoss 8.7019e+00 (8.7019e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][100/704]\tTime  0.076 ( 0.078)\tLoss 9.0156e+00 (5.2342e+00)\tAcc@1  95.31 ( 97.37)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][200/704]\tTime  0.074 ( 0.077)\tLoss 1.2822e+00 (5.5441e+00)\tAcc@1 100.00 ( 97.12)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][300/704]\tTime  0.075 ( 0.076)\tLoss 1.1843e+01 (5.9340e+00)\tAcc@1  93.75 ( 96.85)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][400/704]\tTime  0.076 ( 0.076)\tLoss 3.7745e+00 (6.0507e+00)\tAcc@1  98.44 ( 96.78)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][500/704]\tTime  0.075 ( 0.076)\tLoss 1.4810e+01 (6.1159e+00)\tAcc@1  93.75 ( 96.73)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [0][600/704]\tTime  0.075 ( 0.076)\tLoss 1.3336e+01 (6.0673e+00)\tAcc@1  96.88 ( 96.74)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [0][700/704]\tTime  0.071 ( 0.076)\tLoss 6.6860e+00 (6.1166e+00)\tAcc@1  96.88 ( 96.71)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 96.704 || Acc@5 99.980\n",
            "==> Valid Accuracy:  Acc@1 96.220 || Acc@5 99.960\n",
            "Epoch: [1][  0/704]\tTime  0.464 ( 0.464)\tLoss 6.8775e+00 (6.8775e+00)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.074 ( 0.081)\tLoss 1.4986e+01 (1.0540e+01)\tAcc@1  89.06 ( 94.85)\tAcc@5  98.44 ( 99.92)\n",
            "Epoch: [1][200/704]\tTime  0.080 ( 0.081)\tLoss 4.2220e+00 (9.6390e+00)\tAcc@1  98.44 ( 95.17)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [1][300/704]\tTime  0.074 ( 0.080)\tLoss 1.7144e+01 (1.0914e+01)\tAcc@1  85.94 ( 94.61)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [1][400/704]\tTime  0.077 ( 0.079)\tLoss 8.2645e+00 (1.0709e+01)\tAcc@1  96.88 ( 94.61)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [1][500/704]\tTime  0.076 ( 0.079)\tLoss 3.6518e+00 (9.8312e+00)\tAcc@1  96.88 ( 95.04)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [1][600/704]\tTime  0.075 ( 0.079)\tLoss 1.5616e+00 (9.1469e+00)\tAcc@1 100.00 ( 95.36)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [1][700/704]\tTime  0.070 ( 0.078)\tLoss 1.7266e+00 (8.6618e+00)\tAcc@1  98.44 ( 95.59)\tAcc@5 100.00 ( 99.95)\n",
            "==> Train Accuracy: Acc@1 95.596 || Acc@5 99.947\n",
            "==> Valid Accuracy:  Acc@1 97.280 || Acc@5 100.000\n",
            "Epoch: [2][  0/704]\tTime  0.320 ( 0.320)\tLoss 4.8525e+00 (4.8525e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.075 ( 0.078)\tLoss 4.1649e+00 (3.9743e+00)\tAcc@1  98.44 ( 97.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][200/704]\tTime  0.074 ( 0.077)\tLoss 2.6374e+00 (3.9298e+00)\tAcc@1  98.44 ( 97.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][300/704]\tTime  0.074 ( 0.076)\tLoss 4.8659e+00 (4.0788e+00)\tAcc@1  98.44 ( 97.79)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][400/704]\tTime  0.075 ( 0.076)\tLoss 8.6966e+00 (4.1017e+00)\tAcc@1  93.75 ( 97.80)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][500/704]\tTime  0.074 ( 0.076)\tLoss 5.7404e+00 (4.1657e+00)\tAcc@1  96.88 ( 97.77)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][600/704]\tTime  0.073 ( 0.076)\tLoss 1.4368e+00 (4.1316e+00)\tAcc@1 100.00 ( 97.78)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][700/704]\tTime  0.072 ( 0.075)\tLoss 1.1431e+00 (4.2381e+00)\tAcc@1 100.00 ( 97.72)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 97.722 || Acc@5 99.989\n",
            "==> Valid Accuracy:  Acc@1 96.080 || Acc@5 100.000\n",
            "Epoch: [3][  0/704]\tTime  0.394 ( 0.394)\tLoss 1.4235e+01 (1.4235e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.075 ( 0.078)\tLoss 3.2961e+00 (4.0533e+00)\tAcc@1  98.44 ( 97.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][200/704]\tTime  0.075 ( 0.076)\tLoss 7.0645e+00 (4.1911e+00)\tAcc@1  95.31 ( 97.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][300/704]\tTime  0.075 ( 0.076)\tLoss 1.0666e+01 (4.4361e+00)\tAcc@1  92.19 ( 97.63)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][400/704]\tTime  0.074 ( 0.076)\tLoss 1.0525e+01 (4.5875e+00)\tAcc@1  96.88 ( 97.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][500/704]\tTime  0.075 ( 0.076)\tLoss 5.8523e+00 (4.7944e+00)\tAcc@1  96.88 ( 97.45)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][600/704]\tTime  0.075 ( 0.075)\tLoss 3.4046e+00 (4.9673e+00)\tAcc@1  96.88 ( 97.36)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][700/704]\tTime  0.071 ( 0.075)\tLoss 5.8231e+00 (5.0722e+00)\tAcc@1  96.88 ( 97.29)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 97.287 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 96.420 || Acc@5 99.960\n",
            "Epoch: [4][  0/704]\tTime  0.318 ( 0.318)\tLoss 1.0493e+00 (1.0493e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.075 ( 0.078)\tLoss 6.4451e+00 (4.1894e+00)\tAcc@1  96.88 ( 97.68)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][200/704]\tTime  0.075 ( 0.077)\tLoss 1.6551e+00 (4.5821e+00)\tAcc@1 100.00 ( 97.51)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][300/704]\tTime  0.073 ( 0.076)\tLoss 1.1686e+01 (4.3830e+00)\tAcc@1  95.31 ( 97.60)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][400/704]\tTime  0.074 ( 0.076)\tLoss 1.1340e+00 (4.3645e+00)\tAcc@1 100.00 ( 97.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][500/704]\tTime  0.073 ( 0.076)\tLoss 5.9979e-01 (4.3825e+00)\tAcc@1 100.00 ( 97.61)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][600/704]\tTime  0.075 ( 0.075)\tLoss 2.0265e+00 (4.3300e+00)\tAcc@1  98.44 ( 97.64)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][700/704]\tTime  0.073 ( 0.075)\tLoss 5.7697e+00 (4.5269e+00)\tAcc@1  98.44 ( 97.56)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 97.553 || Acc@5 99.996\n",
            "==> Valid Accuracy:  Acc@1 95.780 || Acc@5 100.000\n",
            "Epoch: [5][  0/704]\tTime  0.413 ( 0.413)\tLoss 8.6971e+00 (8.6971e+00)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.076 ( 0.079)\tLoss 1.7496e+00 (3.6245e+00)\tAcc@1  98.44 ( 98.05)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][200/704]\tTime  0.074 ( 0.077)\tLoss 8.1120e-01 (3.3181e+00)\tAcc@1 100.00 ( 98.27)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][300/704]\tTime  0.075 ( 0.076)\tLoss 1.2594e+00 (3.2136e+00)\tAcc@1  98.44 ( 98.33)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][400/704]\tTime  0.091 ( 0.076)\tLoss 4.3100e+00 (3.1316e+00)\tAcc@1  98.44 ( 98.41)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][500/704]\tTime  0.074 ( 0.076)\tLoss 3.7397e-01 (3.0022e+00)\tAcc@1 100.00 ( 98.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][600/704]\tTime  0.074 ( 0.075)\tLoss 3.0183e+00 (2.9055e+00)\tAcc@1  96.88 ( 98.52)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][700/704]\tTime  0.072 ( 0.075)\tLoss 5.3482e-01 (2.7811e+00)\tAcc@1 100.00 ( 98.56)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 98.567 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 97.900 || Acc@5 100.000\n",
            "Epoch: [6][  0/704]\tTime  0.347 ( 0.347)\tLoss 4.7305e-01 (4.7305e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.076 ( 0.078)\tLoss 1.5955e+00 (2.0358e+00)\tAcc@1 100.00 ( 98.99)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [6][200/704]\tTime  0.076 ( 0.077)\tLoss 1.9109e-01 (1.9734e+00)\tAcc@1 100.00 ( 99.08)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [6][300/704]\tTime  0.075 ( 0.076)\tLoss 2.8252e-01 (1.8216e+00)\tAcc@1 100.00 ( 99.13)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [6][400/704]\tTime  0.072 ( 0.076)\tLoss 3.4224e-01 (1.7778e+00)\tAcc@1 100.00 ( 99.14)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][500/704]\tTime  0.075 ( 0.076)\tLoss 1.6392e-01 (1.6681e+00)\tAcc@1 100.00 ( 99.21)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][600/704]\tTime  0.075 ( 0.076)\tLoss 5.8740e-01 (1.6637e+00)\tAcc@1 100.00 ( 99.18)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][700/704]\tTime  0.071 ( 0.075)\tLoss 1.0450e-01 (1.6188e+00)\tAcc@1 100.00 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.216 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 98.180 || Acc@5 100.000\n",
            "Epoch: [7][  0/704]\tTime  0.441 ( 0.441)\tLoss 4.2073e+00 (4.2073e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.074 ( 0.079)\tLoss 2.1992e-01 (1.1615e+00)\tAcc@1 100.00 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][200/704]\tTime  0.078 ( 0.078)\tLoss 8.2065e-01 (1.1357e+00)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][300/704]\tTime  0.074 ( 0.077)\tLoss 4.6992e-01 (1.2756e+00)\tAcc@1 100.00 ( 99.40)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][400/704]\tTime  0.075 ( 0.076)\tLoss 1.8245e+00 (1.3073e+00)\tAcc@1  98.44 ( 99.37)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][500/704]\tTime  0.075 ( 0.076)\tLoss 2.7073e+00 (1.3514e+00)\tAcc@1  96.88 ( 99.34)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][600/704]\tTime  0.073 ( 0.076)\tLoss 4.5494e-01 (1.3325e+00)\tAcc@1 100.00 ( 99.36)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][700/704]\tTime  0.072 ( 0.076)\tLoss 1.2245e+00 (1.3044e+00)\tAcc@1  98.44 ( 99.36)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.358 || Acc@5 100.000\n",
            "==> Valid Accuracy:  Acc@1 98.400 || Acc@5 100.000\n",
            "Best Top-1 Accuracy for fold8: 98.4\n",
            "\n",
            "FOLD 9\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.367 ( 0.367)\tLoss 6.2327e-01 (6.2327e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][100/704]\tTime  0.073 ( 0.079)\tLoss 1.2561e+01 (3.6568e+00)\tAcc@1  93.75 ( 98.17)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][200/704]\tTime  0.076 ( 0.077)\tLoss 6.1865e+00 (3.8965e+00)\tAcc@1  93.75 ( 97.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][300/704]\tTime  0.078 ( 0.077)\tLoss 3.1257e+00 (4.3468e+00)\tAcc@1  98.44 ( 97.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][400/704]\tTime  0.076 ( 0.076)\tLoss 7.3580e+00 (4.7102e+00)\tAcc@1  95.31 ( 97.58)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][500/704]\tTime  0.075 ( 0.076)\tLoss 3.3301e+00 (4.7082e+00)\tAcc@1  98.44 ( 97.57)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][600/704]\tTime  0.074 ( 0.076)\tLoss 3.7245e-01 (4.7635e+00)\tAcc@1 100.00 ( 97.51)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][700/704]\tTime  0.071 ( 0.075)\tLoss 2.4736e+00 (4.7441e+00)\tAcc@1  98.44 ( 97.52)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 97.520 || Acc@5 99.991\n",
            "==> Valid Accuracy:  Acc@1 97.600 || Acc@5 100.000\n",
            "Epoch: [1][  0/704]\tTime  0.377 ( 0.377)\tLoss 1.9884e+00 (1.9884e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.076 ( 0.079)\tLoss 7.1767e-01 (4.5427e+00)\tAcc@1 100.00 ( 97.66)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][200/704]\tTime  0.074 ( 0.078)\tLoss 6.9092e+00 (4.5089e+00)\tAcc@1  96.88 ( 97.54)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][300/704]\tTime  0.075 ( 0.077)\tLoss 3.9376e+00 (4.6444e+00)\tAcc@1  96.88 ( 97.44)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [1][400/704]\tTime  0.076 ( 0.076)\tLoss 6.5891e-01 (4.5583e+00)\tAcc@1 100.00 ( 97.53)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [1][500/704]\tTime  0.074 ( 0.076)\tLoss 1.0728e+01 (4.6121e+00)\tAcc@1  98.44 ( 97.47)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][600/704]\tTime  0.074 ( 0.076)\tLoss 2.6057e+00 (4.5379e+00)\tAcc@1  98.44 ( 97.52)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [1][700/704]\tTime  0.072 ( 0.076)\tLoss 1.7509e+00 (4.6641e+00)\tAcc@1 100.00 ( 97.47)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 97.467 || Acc@5 99.984\n",
            "==> Valid Accuracy:  Acc@1 96.840 || Acc@5 100.000\n",
            "Epoch: [2][  0/704]\tTime  0.398 ( 0.398)\tLoss 5.4301e-01 (5.4301e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.075 ( 0.079)\tLoss 3.1472e+00 (3.7332e+00)\tAcc@1  98.44 ( 97.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][200/704]\tTime  0.074 ( 0.077)\tLoss 6.7197e+00 (3.7128e+00)\tAcc@1  98.44 ( 98.02)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][300/704]\tTime  0.075 ( 0.076)\tLoss 1.0492e+01 (5.1270e+00)\tAcc@1  93.75 ( 97.59)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][400/704]\tTime  0.075 ( 0.076)\tLoss 4.5123e+00 (7.5116e+00)\tAcc@1  98.44 ( 96.58)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [2][500/704]\tTime  0.076 ( 0.076)\tLoss 4.4452e+00 (7.4527e+00)\tAcc@1  98.44 ( 96.46)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [2][600/704]\tTime  0.075 ( 0.076)\tLoss 3.9281e+00 (6.9754e+00)\tAcc@1  98.44 ( 96.66)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [2][700/704]\tTime  0.071 ( 0.075)\tLoss 9.6317e+00 (6.6276e+00)\tAcc@1  95.31 ( 96.75)\tAcc@5 100.00 ( 99.97)\n",
            "==> Train Accuracy: Acc@1 96.762 || Acc@5 99.973\n",
            "==> Valid Accuracy:  Acc@1 96.800 || Acc@5 99.980\n",
            "Epoch: [3][  0/704]\tTime  0.294 ( 0.294)\tLoss 1.8727e+00 (1.8727e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.076 ( 0.077)\tLoss 7.1372e+00 (4.1649e+00)\tAcc@1  96.88 ( 97.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][200/704]\tTime  0.073 ( 0.076)\tLoss 1.4089e+00 (4.9205e+00)\tAcc@1 100.00 ( 97.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][300/704]\tTime  0.076 ( 0.076)\tLoss 9.7157e-01 (4.8021e+00)\tAcc@1 100.00 ( 97.56)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][400/704]\tTime  0.076 ( 0.075)\tLoss 1.6121e+00 (4.6711e+00)\tAcc@1  98.44 ( 97.58)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][500/704]\tTime  0.074 ( 0.075)\tLoss 6.6795e+00 (4.4102e+00)\tAcc@1  96.88 ( 97.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][600/704]\tTime  0.075 ( 0.075)\tLoss 3.2989e+00 (4.2852e+00)\tAcc@1  98.44 ( 97.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][700/704]\tTime  0.072 ( 0.075)\tLoss 3.1663e+00 (4.2887e+00)\tAcc@1  98.44 ( 97.74)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 97.736 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 97.360 || Acc@5 100.000\n",
            "Epoch: [4][  0/704]\tTime  0.414 ( 0.414)\tLoss 3.3355e-01 (3.3355e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.087 ( 0.078)\tLoss 3.5709e-01 (3.3185e+00)\tAcc@1 100.00 ( 98.14)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][200/704]\tTime  0.073 ( 0.077)\tLoss 5.8552e+00 (3.2511e+00)\tAcc@1  98.44 ( 98.20)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][300/704]\tTime  0.075 ( 0.076)\tLoss 3.4309e+00 (3.2771e+00)\tAcc@1  98.44 ( 98.20)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][400/704]\tTime  0.077 ( 0.076)\tLoss 4.6229e+00 (3.4247e+00)\tAcc@1  96.88 ( 98.08)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][500/704]\tTime  0.075 ( 0.076)\tLoss 2.7626e+00 (3.6160e+00)\tAcc@1  98.44 ( 98.02)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][600/704]\tTime  0.073 ( 0.076)\tLoss 3.9498e+00 (3.7110e+00)\tAcc@1  96.88 ( 97.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][700/704]\tTime  0.072 ( 0.075)\tLoss 7.1029e+00 (3.8219e+00)\tAcc@1  93.75 ( 97.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 97.924 || Acc@5 99.996\n",
            "==> Valid Accuracy:  Acc@1 96.300 || Acc@5 100.000\n",
            "Epoch: [5][  0/704]\tTime  0.302 ( 0.302)\tLoss 2.2598e+00 (2.2598e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.074 ( 0.077)\tLoss 7.6407e+00 (3.2180e+00)\tAcc@1  98.44 ( 98.45)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][200/704]\tTime  0.075 ( 0.076)\tLoss 7.5944e+00 (2.9203e+00)\tAcc@1  95.31 ( 98.51)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][300/704]\tTime  0.075 ( 0.076)\tLoss 1.6678e+00 (2.6299e+00)\tAcc@1  98.44 ( 98.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][400/704]\tTime  0.074 ( 0.075)\tLoss 9.0631e-01 (2.3859e+00)\tAcc@1 100.00 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][500/704]\tTime  0.074 ( 0.075)\tLoss 3.7786e-01 (2.4406e+00)\tAcc@1 100.00 ( 98.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][600/704]\tTime  0.073 ( 0.075)\tLoss 1.5419e+00 (2.2980e+00)\tAcc@1  98.44 ( 98.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][700/704]\tTime  0.072 ( 0.075)\tLoss 1.1420e+00 (2.2494e+00)\tAcc@1 100.00 ( 98.87)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 98.873 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 98.580 || Acc@5 100.000\n",
            "Epoch: [6][  0/704]\tTime  0.446 ( 0.446)\tLoss 1.6299e+00 (1.6299e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.072 ( 0.080)\tLoss 9.5632e-01 (2.0388e+00)\tAcc@1 100.00 ( 99.18)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][200/704]\tTime  0.072 ( 0.077)\tLoss 8.0122e-01 (1.7590e+00)\tAcc@1 100.00 ( 99.20)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][300/704]\tTime  0.073 ( 0.076)\tLoss 3.2322e-01 (1.5819e+00)\tAcc@1 100.00 ( 99.24)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][400/704]\tTime  0.091 ( 0.076)\tLoss 1.9887e+00 (1.4902e+00)\tAcc@1  98.44 ( 99.28)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][500/704]\tTime  0.074 ( 0.076)\tLoss 5.0103e-01 (1.4355e+00)\tAcc@1 100.00 ( 99.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][600/704]\tTime  0.075 ( 0.075)\tLoss 1.2864e+00 (1.3737e+00)\tAcc@1 100.00 ( 99.36)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][700/704]\tTime  0.071 ( 0.075)\tLoss 2.9081e-01 (1.3849e+00)\tAcc@1 100.00 ( 99.34)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.342 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 98.520 || Acc@5 100.000\n",
            "Epoch: [7][  0/704]\tTime  0.301 ( 0.301)\tLoss 8.2056e-01 (8.2056e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.073 ( 0.077)\tLoss 2.7172e+00 (1.1089e+00)\tAcc@1  98.44 ( 99.43)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][200/704]\tTime  0.074 ( 0.076)\tLoss 3.2592e-01 (1.1390e+00)\tAcc@1 100.00 ( 99.39)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][300/704]\tTime  0.073 ( 0.075)\tLoss 1.1428e+00 (1.0922e+00)\tAcc@1  98.44 ( 99.45)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][400/704]\tTime  0.076 ( 0.075)\tLoss 4.0569e+00 (1.1118e+00)\tAcc@1  98.44 ( 99.45)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][500/704]\tTime  0.091 ( 0.075)\tLoss 4.4894e-01 (1.0567e+00)\tAcc@1 100.00 ( 99.48)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][600/704]\tTime  0.077 ( 0.075)\tLoss 7.2810e-01 (1.0450e+00)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][700/704]\tTime  0.073 ( 0.075)\tLoss 1.0689e-01 (1.0354e+00)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.493 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 98.580 || Acc@5 100.000\n",
            "Best Top-1 Accuracy for fold9: 98.58\n",
            "\n",
            "FOLD 10\n",
            "--------------------------------\n",
            "Epoch: [0][  0/704]\tTime  0.445 ( 0.445)\tLoss 9.6168e-01 (9.6168e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][100/704]\tTime  0.073 ( 0.078)\tLoss 8.1040e+00 (3.7955e+00)\tAcc@1  98.44 ( 98.41)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][200/704]\tTime  0.077 ( 0.076)\tLoss 7.5635e+00 (3.8195e+00)\tAcc@1  98.44 ( 98.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][300/704]\tTime  0.074 ( 0.076)\tLoss 3.6994e+00 (3.7693e+00)\tAcc@1  96.88 ( 98.06)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][400/704]\tTime  0.074 ( 0.076)\tLoss 8.6048e-01 (3.9313e+00)\tAcc@1 100.00 ( 97.95)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][500/704]\tTime  0.074 ( 0.076)\tLoss 8.8755e+00 (3.9331e+00)\tAcc@1  96.88 ( 97.93)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][600/704]\tTime  0.074 ( 0.076)\tLoss 2.4726e+00 (4.0103e+00)\tAcc@1  96.88 ( 97.86)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [0][700/704]\tTime  0.069 ( 0.076)\tLoss 5.3219e+00 (4.1059e+00)\tAcc@1  96.88 ( 97.80)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 97.804 || Acc@5 99.991\n",
            "==> Valid Accuracy:  Acc@1 98.260 || Acc@5 100.000\n",
            "Epoch: [1][  0/704]\tTime  0.336 ( 0.336)\tLoss 5.9114e-01 (5.9114e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][100/704]\tTime  0.073 ( 0.078)\tLoss 7.3368e+00 (3.5247e+00)\tAcc@1  96.88 ( 98.38)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][200/704]\tTime  0.074 ( 0.077)\tLoss 4.5635e+00 (3.5333e+00)\tAcc@1  96.88 ( 98.13)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][300/704]\tTime  0.074 ( 0.076)\tLoss 1.0032e+01 (3.4777e+00)\tAcc@1  96.88 ( 98.12)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][400/704]\tTime  0.076 ( 0.076)\tLoss 1.0879e+00 (3.6416e+00)\tAcc@1 100.00 ( 98.03)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][500/704]\tTime  0.074 ( 0.076)\tLoss 9.0220e+00 (3.8983e+00)\tAcc@1  96.88 ( 97.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][600/704]\tTime  0.074 ( 0.076)\tLoss 2.0389e+00 (3.8787e+00)\tAcc@1  98.44 ( 97.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [1][700/704]\tTime  0.072 ( 0.075)\tLoss 1.1388e+01 (4.0164e+00)\tAcc@1  93.75 ( 97.82)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 97.822 || Acc@5 99.998\n",
            "==> Valid Accuracy:  Acc@1 97.280 || Acc@5 100.000\n",
            "Epoch: [2][  0/704]\tTime  0.310 ( 0.310)\tLoss 4.4152e+00 (4.4152e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][100/704]\tTime  0.075 ( 0.077)\tLoss 1.0192e+00 (3.5905e+00)\tAcc@1 100.00 ( 98.07)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][200/704]\tTime  0.082 ( 0.076)\tLoss 9.3357e+00 (3.8296e+00)\tAcc@1  96.88 ( 98.05)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][300/704]\tTime  0.073 ( 0.076)\tLoss 6.5543e+00 (3.7187e+00)\tAcc@1  98.44 ( 98.11)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][400/704]\tTime  0.076 ( 0.075)\tLoss 3.6116e+00 (3.8872e+00)\tAcc@1  98.44 ( 97.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [2][500/704]\tTime  0.074 ( 0.075)\tLoss 5.8944e-01 (3.8416e+00)\tAcc@1 100.00 ( 98.03)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][600/704]\tTime  0.075 ( 0.075)\tLoss 4.2690e+00 (3.8859e+00)\tAcc@1  96.88 ( 97.95)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [2][700/704]\tTime  0.070 ( 0.075)\tLoss 3.4335e-01 (3.8991e+00)\tAcc@1 100.00 ( 97.95)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 97.944 || Acc@5 99.993\n",
            "==> Valid Accuracy:  Acc@1 97.780 || Acc@5 99.980\n",
            "Epoch: [3][  0/704]\tTime  0.433 ( 0.433)\tLoss 3.8295e+00 (3.8295e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][100/704]\tTime  0.088 ( 0.078)\tLoss 3.8933e+00 (3.5845e+00)\tAcc@1  98.44 ( 98.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][200/704]\tTime  0.074 ( 0.076)\tLoss 8.6442e-01 (3.2621e+00)\tAcc@1 100.00 ( 98.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][300/704]\tTime  0.079 ( 0.076)\tLoss 7.0314e+00 (3.4013e+00)\tAcc@1  95.31 ( 98.15)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][400/704]\tTime  0.076 ( 0.076)\tLoss 2.9679e+00 (3.4703e+00)\tAcc@1  98.44 ( 98.10)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [3][500/704]\tTime  0.075 ( 0.075)\tLoss 6.4952e+00 (4.2377e+00)\tAcc@1  95.31 ( 97.76)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [3][600/704]\tTime  0.074 ( 0.075)\tLoss 1.1532e+00 (4.4749e+00)\tAcc@1 100.00 ( 97.58)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [3][700/704]\tTime  0.072 ( 0.075)\tLoss 3.7819e+00 (4.4959e+00)\tAcc@1  96.88 ( 97.60)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 97.607 || Acc@5 99.993\n",
            "==> Valid Accuracy:  Acc@1 97.160 || Acc@5 100.000\n",
            "Epoch: [4][  0/704]\tTime  0.327 ( 0.327)\tLoss 1.2280e+00 (1.2280e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [4][100/704]\tTime  0.074 ( 0.078)\tLoss 1.5654e+00 (4.2879e+00)\tAcc@1 100.00 ( 98.00)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][200/704]\tTime  0.074 ( 0.076)\tLoss 9.1884e+00 (6.5742e+00)\tAcc@1  95.31 ( 96.88)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [4][300/704]\tTime  0.077 ( 0.076)\tLoss 1.6816e+00 (6.5814e+00)\tAcc@1  98.44 ( 96.88)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][400/704]\tTime  0.077 ( 0.076)\tLoss 7.9518e+00 (6.0787e+00)\tAcc@1  95.31 ( 97.00)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][500/704]\tTime  0.076 ( 0.076)\tLoss 2.7534e+00 (5.6723e+00)\tAcc@1  98.44 ( 97.20)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][600/704]\tTime  0.074 ( 0.076)\tLoss 9.4904e+00 (5.4536e+00)\tAcc@1  96.88 ( 97.28)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [4][700/704]\tTime  0.070 ( 0.076)\tLoss 5.7423e-01 (5.1253e+00)\tAcc@1 100.00 ( 97.42)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 97.422 || Acc@5 99.989\n",
            "==> Valid Accuracy:  Acc@1 97.860 || Acc@5 99.980\n",
            "Epoch: [5][  0/704]\tTime  0.413 ( 0.413)\tLoss 1.9615e+00 (1.9615e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][100/704]\tTime  0.075 ( 0.078)\tLoss 1.5621e+00 (2.5427e+00)\tAcc@1  98.44 ( 98.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][200/704]\tTime  0.072 ( 0.076)\tLoss 4.2984e-01 (2.1441e+00)\tAcc@1 100.00 ( 98.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [5][300/704]\tTime  0.076 ( 0.076)\tLoss 2.9260e+00 (2.0716e+00)\tAcc@1  98.44 ( 98.92)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [5][400/704]\tTime  0.074 ( 0.076)\tLoss 1.3878e+00 (1.9609e+00)\tAcc@1 100.00 ( 98.98)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [5][500/704]\tTime  0.078 ( 0.075)\tLoss 5.0967e-01 (1.9448e+00)\tAcc@1 100.00 ( 99.00)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [5][600/704]\tTime  0.074 ( 0.075)\tLoss 1.8772e-01 (1.9358e+00)\tAcc@1 100.00 ( 99.04)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [5][700/704]\tTime  0.072 ( 0.075)\tLoss 6.5054e+00 (1.9391e+00)\tAcc@1  98.44 ( 99.05)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.053 || Acc@5 99.991\n",
            "==> Valid Accuracy:  Acc@1 98.380 || Acc@5 100.000\n",
            "Epoch: [6][  0/704]\tTime  0.353 ( 0.353)\tLoss 5.1976e-01 (5.1976e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][100/704]\tTime  0.075 ( 0.078)\tLoss 2.2804e+00 (1.6789e+00)\tAcc@1  98.44 ( 99.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][200/704]\tTime  0.076 ( 0.078)\tLoss 1.7130e+00 (1.3951e+00)\tAcc@1 100.00 ( 99.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][300/704]\tTime  0.074 ( 0.077)\tLoss 2.6164e-01 (1.4557e+00)\tAcc@1 100.00 ( 99.27)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][400/704]\tTime  0.073 ( 0.076)\tLoss 6.4516e-01 (1.4805e+00)\tAcc@1 100.00 ( 99.25)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][500/704]\tTime  0.074 ( 0.076)\tLoss 4.4026e+00 (1.4734e+00)\tAcc@1  96.88 ( 99.25)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][600/704]\tTime  0.073 ( 0.076)\tLoss 3.7435e-01 (1.4680e+00)\tAcc@1 100.00 ( 99.25)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [6][700/704]\tTime  0.070 ( 0.076)\tLoss 1.2322e+00 (1.4479e+00)\tAcc@1  98.44 ( 99.26)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.260 || Acc@5 100.000\n",
            "==> Valid Accuracy:  Acc@1 98.940 || Acc@5 99.980\n",
            "Epoch: [7][  0/704]\tTime  0.471 ( 0.471)\tLoss 1.0270e+00 (1.0270e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][100/704]\tTime  0.075 ( 0.080)\tLoss 1.1909e+00 (1.0979e+00)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][200/704]\tTime  0.077 ( 0.078)\tLoss 1.6280e+00 (1.1361e+00)\tAcc@1  98.44 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][300/704]\tTime  0.074 ( 0.077)\tLoss 7.6665e-01 (1.0997e+00)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][400/704]\tTime  0.074 ( 0.076)\tLoss 2.1044e+00 (1.1507e+00)\tAcc@1  98.44 ( 99.47)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][500/704]\tTime  0.075 ( 0.076)\tLoss 1.9217e-01 (1.1125e+00)\tAcc@1 100.00 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][600/704]\tTime  0.076 ( 0.076)\tLoss 3.2680e+00 (1.1075e+00)\tAcc@1  98.44 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [7][700/704]\tTime  0.071 ( 0.075)\tLoss 1.1658e+00 (1.1002e+00)\tAcc@1 100.00 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.460 || Acc@5 100.000\n",
            "==> Valid Accuracy:  Acc@1 98.920 || Acc@5 100.000\n",
            "Best Top-1 Accuracy for fold10: 98.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test with ensemble**"
      ],
      "metadata": {
        "id": "ORvLl9gcmZjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          pin_memory=True,\n",
        "                                          num_workers=2)"
      ],
      "metadata": {
        "id": "qTKAvAeNmbwI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensemble\n",
        "with torch.no_grad():\n",
        "    output = None\n",
        "    predictions_list = []\n",
        "   \n",
        "    for fold in range(fold_num):\n",
        "        print(f'[Fold {fold+1}]')\n",
        "\n",
        "        if output is not None:\n",
        "            del output   # del output : memory free\n",
        "        else :\n",
        "            pass\n",
        "        path2weights_fold = f'{path2weights}_fold{fold+1}.pth'\n",
        "        if model == 'ResNet34':\n",
        "            model = resnet34().cuda()\n",
        "        elif model == \"ResNet50\":\n",
        "            model = resnet50().cuda()\n",
        "        elif model == \"ResNet101\":\n",
        "            model = resnet101().cuda()\n",
        "        model.load_state_dict(torch.load(path2weights_fold))\n",
        "\n",
        "        output = test(test_loader, model)\n",
        "        output = output.view(output.shape[0], output.shape[1], 1).cpu() # 각 fold별 output의 평균을 내기 위해 3번째 dimension 추가\n",
        "        predictions_list.append(output)\n",
        "\n",
        "    predictions_array = np.concatenate(predictions_list, axis=2)\n",
        "    predictions_mean = predictions_array.mean(axis = 2)\n",
        "    predictions_mean = torch.from_numpy(predictions_mean)\n",
        "    predictData = torch.argmax(predictions_mean, 1)\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat',\n",
        "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    lst = []\n",
        "    for Id, predict in enumerate(predictData, 1):\n",
        "        # tensor형태의 predict를 정수의 prediction으로 바꿈\n",
        "        x = predict.to(\"cpu\").numpy()\n",
        "        x = x.astype(int)\n",
        "        Category = classes[x]\n",
        "        lst.append([Id, Category])\n",
        "\n",
        "    df = DataFrame(lst, columns=['Id', 'Category'])\n",
        "    df.to_csv(path2submission, index=False, encoding='cp949')"
      ],
      "metadata": {
        "id": "KS3wl8-vdMkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6cf11b9-d263-4d02-e601-cf81035fc612"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 31.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:04<00:00, 33.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **결과가 가장좋았던 ResNet101_fold5를 혼자 사용해본다면?**"
      ],
      "metadata": {
        "id": "BhSBv8lh630y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def test_not_ensemble(test_loader, model):\n",
        "#     classes = ('plane', 'car', 'bird', 'cat',\n",
        "#                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "#     model.eval()\n",
        "#     for i, (input, target) in enumerate(tqdm(test_loader), 0):\n",
        "#         input = input.cuda()\n",
        "#         #target은 쓰지 않음.\n",
        "#         #target = target.cuda()\n",
        "\n",
        "#         output = torch.argmax(model(input), 1)\n",
        "        \n",
        "#         id = i * batch_size + 1     # id는 1부터 시작\n",
        "#         lst = []\n",
        "        \n",
        "#         for Id, Category in zip(range(id, id+batch_size), output):\n",
        "#             x = Category.to(\"cpu\").numpy()\n",
        "#             Category = x.astype(int)\n",
        "#             lst.append([Id, classes[Category]])\n",
        "\n",
        "#         df = DataFrame(lst, columns=['Id', 'Category'])\n",
        "#         if i == 0:\n",
        "#             df.to_csv(path2submission, index=False, encoding='cp949')\n",
        "#         else :\n",
        "#             df.to_csv(path2submission, mode='a', index=False, encoding='cp949', header=False)"
      ],
      "metadata": {
        "id": "ejUc3D4x7Hsq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path2submission = f'/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/submission/{model}_best.csv'\n",
        "# final_model = resnet101().cuda()\n",
        "# final_model.load_state_dict(torch.load('/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/models/ResNet101_fold5.pth'))\n",
        "# test_not_ensemble(test_loader, final_model)"
      ],
      "metadata": {
        "id": "0PeeMTm56_Hv"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}