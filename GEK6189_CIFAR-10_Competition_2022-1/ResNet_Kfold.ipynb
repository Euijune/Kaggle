{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet34_Kfold.ipynb","provenance":[],"collapsed_sections":["Yq2t0nduROER","zP5k6WvrgnTB","GjyF1Tveg0A1"],"authorship_tag":"ABX9TyOUFm/ymTwYT3N6vS6/9Ymw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ae46ab5dbd7046b79a45690f48f3ada9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9162fbc4b094449f89dd260ea4a94ec0","IPY_MODEL_ac30ec7cd35d4cf5a63e51c9e15bde09","IPY_MODEL_4f305797c3ad44f9ba46336ab5a1b5e3"],"layout":"IPY_MODEL_4184be4fd3024249a12f5689001f2171"}},"9162fbc4b094449f89dd260ea4a94ec0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43d5d49642784167b525a6441510b6f6","placeholder":"​","style":"IPY_MODEL_dacc4c4dbb714d78bfdbb3d1706c9faf","value":""}},"ac30ec7cd35d4cf5a63e51c9e15bde09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bda06a7fe1d14c2f9936a70e7a7c035a","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_609e865b16fd444aa0c6e229830ce151","value":170498071}},"4f305797c3ad44f9ba46336ab5a1b5e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_558b9c78df1c4261ae15d28dd229cee7","placeholder":"​","style":"IPY_MODEL_b97b8d66fa4549c6a85c9f631edca3e8","value":" 170499072/? [00:04&lt;00:00, 47116584.35it/s]"}},"4184be4fd3024249a12f5689001f2171":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43d5d49642784167b525a6441510b6f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dacc4c4dbb714d78bfdbb3d1706c9faf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bda06a7fe1d14c2f9936a70e7a7c035a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"609e865b16fd444aa0c6e229830ce151":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"558b9c78df1c4261ae15d28dd229cee7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b97b8d66fa4549c6a85c9f631edca3e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSVZKuMHOkNd","executionInfo":{"status":"ok","timestamp":1652158299299,"user_tz":-540,"elapsed":20999,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}},"outputId":"24dc890e-d9b9-475c-c8d1-b8c8fdfcf49c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# import package\n","\n","# model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","from torchsummary import summary\n","from torch import optim\n","\n","# dataset and transformation\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import os\n","\n","# Cross Validation\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","# Scheduler\n","from torch.optim.lr_scheduler import StepLR\n","\n","# display images\n","from torchvision import utils\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# utils\n","import numpy as np\n","from torchsummary import summary\n","import time\n","import copy\n","\n","# submission\n","from tqdm import tqdm\n","import pandas as pd\n","from pandas import DataFrame"],"metadata":{"id":"eFOjM_GoPIQi","executionInfo":{"status":"ok","timestamp":1652158302345,"user_tz":-540,"elapsed":3053,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## **Define ResNet model**"],"metadata":{"id":"Yq2t0nduROER"}},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","    expansion = 1   # output 채널을 늘리고싶다면 1보다 큰 값으로\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n","        )\n","\n","        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n","        self.shortcut = nn.Sequential()\n","\n","        self.relu = nn.ReLU()\n","\n","        # projection mapping using 1x1conv, input과 output의 feature map size가 다를 경우 사용\n","        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n","            )\n","\n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x\n","\n","\n","class BottleNeck(nn.Module):\n","    expansion = 4\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","        )\n","\n","        # identity mapping\n","        self.shortcut = nn.Sequential()\n","\n","        self.relu = nn.ReLU()\n","        \n","        # projection mapping\n","        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n","            )\n","            \n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x"],"metadata":{"id":"Qve0Qom9RSxo","executionInfo":{"status":"ok","timestamp":1652158302345,"user_tz":-540,"elapsed":13,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class ResNet(nn.Module):\n","    def __init__(self, block, num_block, num_classes=100, init_weights=True):\n","        super().__init__()\n","\n","        self.in_channels=64\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        )\n","\n","        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n","        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n","        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n","        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n","\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        # weights inittialization\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def _make_layer(self, block, out_channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride))\n","            self.in_channels = out_channels * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self,x):\n","        output = self.conv1(x)\n","        output = self.conv2_x(output)\n","        x = self.conv3_x(output)\n","        x = self.conv4_x(x)\n","        x = self.conv5_x(x)\n","        x = self.avg_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","    # define weight initialization function\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","def resnet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n","\n","# 34 = 1(7x7 conv) + 2 * (3 + 4 + 6 + 3) + 1(fc 1000)\n","def resnet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n","\n","# 50 = 1(7x7 conv) + 3 * (3 + 4 + 6 + 3) + 1(fc 1000)\n","def resnet50():\n","    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=num_classes)\n","\n","def resnet101():\n","    return ResNet(BottleNeck, [3, 4, 23, 3], num_classes=num_classes)\n","\n","def resnet152():\n","    return ResNet(BottleNeck, [3, 8, 36, 3], num_classes=num_classes)"],"metadata":{"id":"hvqBbM3DRTUE","executionInfo":{"status":"ok","timestamp":1652158302345,"user_tz":-540,"elapsed":10,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## **Utils**"],"metadata":{"id":"zP5k6WvrgnTB"}},{"cell_type":"code","source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"metadata":{"id":"1Xa4ViILgpKQ","executionInfo":{"status":"ok","timestamp":1652158302346,"user_tz":-540,"elapsed":8,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## **Cutout: Main Code for Applying Cutout data augmentation**"],"metadata":{"id":"GjyF1Tveg0A1"}},{"cell_type":"code","source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"metadata":{"id":"n8eGTZuwgzUF","executionInfo":{"status":"ok","timestamp":1652158302346,"user_tz":-540,"elapsed":6,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## **Parameter Setting**"],"metadata":{"id":"lXJGSMQSRWuC"}},{"cell_type":"code","source":["dataset = 'cifar10' # cifar10 or cifar100\n","model = 'ResNet50' # resnet18, resnet50, resnet101, GoogLeNetV1\n","batch_size = 64  # Input batch size for training (default: 128)\n","epochs = 8 # Number of epochs to train (default: 200)\n","learning_rate = 0.001 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","fold_num = 10 # k-fold validation\n","path2submission = f'/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/submission/{model}.csv'    # route for submission .csv file\n","path2weights = f'/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/models/{model}'\n","\n","cutout = False # Apply Cutout?\n","if cutout:\n","    n_holes = 1 # Number of holes to cut out from image\n","    length = 16 # Length of the holes\n","\n","seed = 0 # Random seed (default: 0)\n","print_freq = 100\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"metadata":{"id":"ma17ymk8QGUN","executionInfo":{"status":"ok","timestamp":1652158302931,"user_tz":-540,"elapsed":19,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","# train\n","train_transform = transforms.Compose([])\n","\n","train_transform.transforms.append(transforms.Resize((64, 64)))\n","if data_augmentation:\n","    #train_transform.transforms.append(transforms.RandomCrop(299, 299))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","# test\n","test_transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","    normalize])\n","\n","\n","# load dataset\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["ae46ab5dbd7046b79a45690f48f3ada9","9162fbc4b094449f89dd260ea4a94ec0","ac30ec7cd35d4cf5a63e51c9e15bde09","4f305797c3ad44f9ba46336ab5a1b5e3","4184be4fd3024249a12f5689001f2171","43d5d49642784167b525a6441510b6f6","dacc4c4dbb714d78bfdbb3d1706c9faf","bda06a7fe1d14c2f9936a70e7a7c035a","609e865b16fd444aa0c6e229830ce151","558b9c78df1c4261ae15d28dd229cee7","b97b8d66fa4549c6a85c9f631edca3e8"]},"id":"AVTMRhb5PcH0","executionInfo":{"status":"ok","timestamp":1652158310497,"user_tz":-540,"elapsed":7584,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}},"outputId":"4c2e4ced-a063-458c-a140-4b4a56be402e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae46ab5dbd7046b79a45690f48f3ada9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-10-python.tar.gz to data/\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["## **Main Training**"],"metadata":{"id":"fO4sCjR0i6f0"}},{"cell_type":"code","source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","        #input = input.to(torch.device(\"cpu\"))\n","        #target = target.to(torch.device(\"cpu\"))\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def valid(val_loader, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(val_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","        #input = input.to(torch.device(\"cpu\"))\n","        #target = target.to(torch.device(\"cpu\"))\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Valid Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader, model):  \n","    output = None\n","    \n","    model.eval()\n","    for i, (input, target) in enumerate(tqdm(test_loader), 0):\n","        input = input.cuda()\n","        #target은 쓰지 않음.\n","        #target = target.cuda()\n","\n","        if output is not None:\n","            output = torch.cat((output, model(input)), dim=0)\n","        else:\n","            output = model(input)\n","\n","    return output"],"metadata":{"id":"Ky64JtDki8dd","executionInfo":{"status":"ok","timestamp":1652158310498,"user_tz":-540,"elapsed":12,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Define the K-fold Cross Validator\n","kfold = KFold(n_splits=fold_num, shuffle=True)"],"metadata":{"id":"C-i8yJnaX60r","executionInfo":{"status":"ok","timestamp":1652158310499,"user_tz":-540,"elapsed":10,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Model evaluation using K-fold cross-validation\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_dataset)):\n","\n","    # Print\n","    print(f'\\nFOLD {fold+1}')\n","    print('--------------------------------')\n","\n","    # Ramdom sample elements from a given list of ids, not replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    valid_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","\n","    train_loader = DataLoader(dataset = train_dataset,\n","                         batch_size=batch_size,\n","                         sampler = train_subsampler,\n","                         pin_memory=True,\n","                         num_workers=2)\n","    \n","    valid_loader = DataLoader(dataset = train_dataset,\n","                         batch_size=batch_size,\n","                         sampler = valid_subsampler,\n","                         pin_memory=True,\n","                         num_workers=2)\n","    \n","    # Setting\n","    if model == 'ResNet34':\n","        model = resnet34().cuda()\n","    elif model == \"ResNet50\":\n","        model = resnet50().cuda()\n","    elif model == \"ResNet101\":\n","        model = resnet101().cuda()\n","\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n","    criterion = torch.nn.CrossEntropyLoss(reduction='sum').cuda()\n","\n","    # Training\n","    best_acc = 0\n","    for epoch in range(epochs):\n","        # Train for one epoch\n","        train(train_loader, epoch, model, optimizer, criterion)\n","\n","        # Validation\n","        with torch.no_grad():\n","            val_acc = valid(valid_loader, model)\n","\n","        # learning rate scheduling\n","        scheduler.step()\n","    \n","        # Save model for best accuracy\n","        if best_acc < val_acc:\n","            path2weights_fold = f'{path2weights}_fold{fold+1}.pth'  # route for model saving\n","            best_acc = val_acc\n","            torch.save(model.state_dict(), path2weights_fold)\n","\n","    print(f\"Best Top-1 Accuracy for fold{fold+1}: {best_acc}\")"],"metadata":{"id":"2ZIdY89oYH7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652162869178,"user_tz":-540,"elapsed":4558688,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}},"outputId":"264cbf53-587b-4bdf-e4fb-98e0e9958d26"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","FOLD 1\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  1.822 ( 1.822)\tLoss 1.4925e+02 (1.4925e+02)\tAcc@1  14.06 ( 14.06)\tAcc@5  59.38 ( 59.38)\n","Epoch: [0][100/704]\tTime  0.071 ( 0.089)\tLoss 1.1282e+02 (1.3473e+02)\tAcc@1  37.50 ( 27.35)\tAcc@5  85.94 ( 79.13)\n","Epoch: [0][200/704]\tTime  0.098 ( 0.080)\tLoss 1.0044e+02 (1.2231e+02)\tAcc@1  42.19 ( 32.88)\tAcc@5  89.06 ( 83.87)\n","Epoch: [0][300/704]\tTime  0.073 ( 0.079)\tLoss 8.8983e+01 (1.1609e+02)\tAcc@1  45.31 ( 35.98)\tAcc@5  90.62 ( 85.88)\n","Epoch: [0][400/704]\tTime  0.070 ( 0.078)\tLoss 9.9782e+01 (1.1181e+02)\tAcc@1  37.50 ( 38.08)\tAcc@5  92.19 ( 87.21)\n","Epoch: [0][500/704]\tTime  0.073 ( 0.077)\tLoss 9.8943e+01 (1.0824e+02)\tAcc@1  54.69 ( 39.84)\tAcc@5  89.06 ( 88.20)\n","Epoch: [0][600/704]\tTime  0.072 ( 0.076)\tLoss 9.4763e+01 (1.0514e+02)\tAcc@1  48.44 ( 41.43)\tAcc@5  92.19 ( 89.04)\n","Epoch: [0][700/704]\tTime  0.069 ( 0.076)\tLoss 7.1182e+01 (1.0212e+02)\tAcc@1  68.75 ( 43.03)\tAcc@5  93.75 ( 89.72)\n","==> Train Accuracy: Acc@1 43.060 || Acc@5 89.738\n","==> Valid Accuracy:  Acc@1 55.080 || Acc@5 94.260\n","Epoch: [1][  0/704]\tTime  0.466 ( 0.466)\tLoss 6.3984e+01 (6.3984e+01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.072 ( 0.077)\tLoss 9.5848e+01 (7.7236e+01)\tAcc@1  42.19 ( 56.95)\tAcc@5  87.50 ( 95.25)\n","Epoch: [1][200/704]\tTime  0.071 ( 0.076)\tLoss 7.6350e+01 (7.6392e+01)\tAcc@1  56.25 ( 57.56)\tAcc@5  98.44 ( 95.09)\n","Epoch: [1][300/704]\tTime  0.074 ( 0.075)\tLoss 6.4207e+01 (7.5279e+01)\tAcc@1  64.06 ( 58.07)\tAcc@5  95.31 ( 95.28)\n","Epoch: [1][400/704]\tTime  0.075 ( 0.075)\tLoss 6.1207e+01 (7.3761e+01)\tAcc@1  70.31 ( 58.80)\tAcc@5  95.31 ( 95.51)\n","Epoch: [1][500/704]\tTime  0.075 ( 0.075)\tLoss 5.9781e+01 (7.2797e+01)\tAcc@1  65.62 ( 59.33)\tAcc@5  98.44 ( 95.59)\n","Epoch: [1][600/704]\tTime  0.075 ( 0.075)\tLoss 6.4750e+01 (7.1929e+01)\tAcc@1  53.12 ( 59.94)\tAcc@5 100.00 ( 95.65)\n","Epoch: [1][700/704]\tTime  0.072 ( 0.075)\tLoss 6.1796e+01 (7.1114e+01)\tAcc@1  62.50 ( 60.51)\tAcc@5  93.75 ( 95.79)\n","==> Train Accuracy: Acc@1 60.527 || Acc@5 95.798\n","==> Valid Accuracy:  Acc@1 65.100 || Acc@5 96.700\n","Epoch: [2][  0/704]\tTime  0.302 ( 0.302)\tLoss 6.4332e+01 (6.4332e+01)\tAcc@1  67.19 ( 67.19)\tAcc@5  96.88 ( 96.88)\n","Epoch: [2][100/704]\tTime  0.075 ( 0.077)\tLoss 4.5573e+01 (5.9024e+01)\tAcc@1  73.44 ( 67.67)\tAcc@5  96.88 ( 97.20)\n","Epoch: [2][200/704]\tTime  0.074 ( 0.076)\tLoss 5.6710e+01 (5.8375e+01)\tAcc@1  67.19 ( 67.92)\tAcc@5  95.31 ( 97.21)\n","Epoch: [2][300/704]\tTime  0.073 ( 0.076)\tLoss 4.7607e+01 (5.8238e+01)\tAcc@1  78.12 ( 68.25)\tAcc@5  98.44 ( 97.17)\n","Epoch: [2][400/704]\tTime  0.073 ( 0.075)\tLoss 4.3672e+01 (5.7455e+01)\tAcc@1  78.12 ( 68.66)\tAcc@5  98.44 ( 97.23)\n","Epoch: [2][500/704]\tTime  0.076 ( 0.075)\tLoss 6.5781e+01 (5.9127e+01)\tAcc@1  68.75 ( 67.86)\tAcc@5  95.31 ( 97.06)\n","Epoch: [2][600/704]\tTime  0.073 ( 0.075)\tLoss 6.1663e+01 (5.8496e+01)\tAcc@1  68.75 ( 68.14)\tAcc@5 100.00 ( 97.16)\n","Epoch: [2][700/704]\tTime  0.073 ( 0.075)\tLoss 4.6371e+01 (5.7717e+01)\tAcc@1  76.56 ( 68.55)\tAcc@5  98.44 ( 97.27)\n","==> Train Accuracy: Acc@1 68.562 || Acc@5 97.271\n","==> Valid Accuracy:  Acc@1 69.160 || Acc@5 97.580\n","Epoch: [3][  0/704]\tTime  0.416 ( 0.416)\tLoss 5.8862e+01 (5.8862e+01)\tAcc@1  64.06 ( 64.06)\tAcc@5  98.44 ( 98.44)\n","Epoch: [3][100/704]\tTime  0.074 ( 0.079)\tLoss 4.6501e+01 (4.8753e+01)\tAcc@1  76.56 ( 73.38)\tAcc@5  96.88 ( 98.11)\n","Epoch: [3][200/704]\tTime  0.075 ( 0.078)\tLoss 5.2948e+01 (4.8947e+01)\tAcc@1  70.31 ( 73.44)\tAcc@5 100.00 ( 98.00)\n","Epoch: [3][300/704]\tTime  0.076 ( 0.078)\tLoss 5.0198e+01 (4.8409e+01)\tAcc@1  76.56 ( 73.54)\tAcc@5  98.44 ( 98.03)\n","Epoch: [3][400/704]\tTime  0.076 ( 0.077)\tLoss 4.7706e+01 (5.1611e+01)\tAcc@1  71.88 ( 71.99)\tAcc@5  96.88 ( 97.79)\n","Epoch: [3][500/704]\tTime  0.078 ( 0.077)\tLoss 5.2696e+01 (5.1553e+01)\tAcc@1  70.31 ( 72.00)\tAcc@5 100.00 ( 97.82)\n","Epoch: [3][600/704]\tTime  0.077 ( 0.077)\tLoss 4.3905e+01 (5.0755e+01)\tAcc@1  71.88 ( 72.33)\tAcc@5  98.44 ( 97.90)\n","Epoch: [3][700/704]\tTime  0.073 ( 0.077)\tLoss 3.7621e+01 (5.0062e+01)\tAcc@1  78.12 ( 72.75)\tAcc@5  96.88 ( 97.96)\n","==> Train Accuracy: Acc@1 72.767 || Acc@5 97.958\n","==> Valid Accuracy:  Acc@1 70.880 || Acc@5 97.940\n","Epoch: [4][  0/704]\tTime  0.300 ( 0.300)\tLoss 5.5494e+01 (5.5494e+01)\tAcc@1  75.00 ( 75.00)\tAcc@5  98.44 ( 98.44)\n","Epoch: [4][100/704]\tTime  0.075 ( 0.079)\tLoss 4.1901e+01 (4.1501e+01)\tAcc@1  75.00 ( 77.57)\tAcc@5  98.44 ( 98.61)\n","Epoch: [4][200/704]\tTime  0.076 ( 0.079)\tLoss 4.1684e+01 (4.1517e+01)\tAcc@1  79.69 ( 77.40)\tAcc@5  95.31 ( 98.69)\n","Epoch: [4][300/704]\tTime  0.078 ( 0.078)\tLoss 4.6352e+01 (4.1403e+01)\tAcc@1  73.44 ( 77.54)\tAcc@5  96.88 ( 98.66)\n","Epoch: [4][400/704]\tTime  0.077 ( 0.078)\tLoss 4.5357e+01 (4.1472e+01)\tAcc@1  71.88 ( 77.57)\tAcc@5  98.44 ( 98.62)\n","Epoch: [4][500/704]\tTime  0.077 ( 0.078)\tLoss 3.9066e+01 (4.1503e+01)\tAcc@1  79.69 ( 77.58)\tAcc@5 100.00 ( 98.65)\n","Epoch: [4][600/704]\tTime  0.078 ( 0.078)\tLoss 3.8066e+01 (4.1356e+01)\tAcc@1  78.12 ( 77.60)\tAcc@5 100.00 ( 98.65)\n","Epoch: [4][700/704]\tTime  0.075 ( 0.078)\tLoss 4.8747e+01 (4.1530e+01)\tAcc@1  71.88 ( 77.55)\tAcc@5 100.00 ( 98.61)\n","==> Train Accuracy: Acc@1 77.538 || Acc@5 98.609\n","==> Valid Accuracy:  Acc@1 75.240 || Acc@5 98.420\n","Epoch: [5][  0/704]\tTime  0.406 ( 0.406)\tLoss 2.9232e+01 (2.9232e+01)\tAcc@1  90.62 ( 90.62)\tAcc@5  98.44 ( 98.44)\n","Epoch: [5][100/704]\tTime  0.078 ( 0.081)\tLoss 1.9401e+01 (3.3602e+01)\tAcc@1  89.06 ( 81.76)\tAcc@5 100.00 ( 99.33)\n","Epoch: [5][200/704]\tTime  0.076 ( 0.080)\tLoss 1.8284e+01 (3.1581e+01)\tAcc@1  93.75 ( 82.98)\tAcc@5 100.00 ( 99.34)\n","Epoch: [5][300/704]\tTime  0.079 ( 0.079)\tLoss 2.0617e+01 (3.0455e+01)\tAcc@1  89.06 ( 83.66)\tAcc@5 100.00 ( 99.32)\n","Epoch: [5][400/704]\tTime  0.078 ( 0.079)\tLoss 3.2362e+01 (2.9766e+01)\tAcc@1  84.38 ( 84.09)\tAcc@5 100.00 ( 99.29)\n","Epoch: [5][500/704]\tTime  0.079 ( 0.078)\tLoss 1.4280e+01 (2.9119e+01)\tAcc@1  93.75 ( 84.39)\tAcc@5  98.44 ( 99.34)\n","Epoch: [5][600/704]\tTime  0.076 ( 0.078)\tLoss 2.4107e+01 (2.8585e+01)\tAcc@1  85.94 ( 84.68)\tAcc@5 100.00 ( 99.38)\n","Epoch: [5][700/704]\tTime  0.076 ( 0.078)\tLoss 1.2125e+01 (2.8135e+01)\tAcc@1  92.19 ( 84.94)\tAcc@5 100.00 ( 99.39)\n","==> Train Accuracy: Acc@1 84.947 || Acc@5 99.382\n","==> Valid Accuracy:  Acc@1 82.220 || Acc@5 99.340\n","Epoch: [6][  0/704]\tTime  0.305 ( 0.305)\tLoss 3.2673e+01 (3.2673e+01)\tAcc@1  84.38 ( 84.38)\tAcc@5  96.88 ( 96.88)\n","Epoch: [6][100/704]\tTime  0.076 ( 0.079)\tLoss 3.5723e+01 (2.3073e+01)\tAcc@1  81.25 ( 87.65)\tAcc@5  96.88 ( 99.44)\n","Epoch: [6][200/704]\tTime  0.078 ( 0.078)\tLoss 1.9171e+01 (2.2569e+01)\tAcc@1  89.06 ( 88.01)\tAcc@5  98.44 ( 99.53)\n","Epoch: [6][300/704]\tTime  0.078 ( 0.078)\tLoss 1.6833e+01 (2.2800e+01)\tAcc@1  90.62 ( 87.78)\tAcc@5 100.00 ( 99.57)\n","Epoch: [6][400/704]\tTime  0.077 ( 0.078)\tLoss 2.3214e+01 (2.2699e+01)\tAcc@1  85.94 ( 87.82)\tAcc@5 100.00 ( 99.57)\n","Epoch: [6][500/704]\tTime  0.076 ( 0.078)\tLoss 1.6181e+01 (2.2850e+01)\tAcc@1  90.62 ( 87.82)\tAcc@5 100.00 ( 99.54)\n","Epoch: [6][600/704]\tTime  0.077 ( 0.077)\tLoss 2.9206e+01 (2.2927e+01)\tAcc@1  87.50 ( 87.77)\tAcc@5  98.44 ( 99.53)\n","Epoch: [6][700/704]\tTime  0.075 ( 0.077)\tLoss 2.4383e+01 (2.2950e+01)\tAcc@1  89.06 ( 87.77)\tAcc@5  98.44 ( 99.54)\n","==> Train Accuracy: Acc@1 87.756 || Acc@5 99.540\n","==> Valid Accuracy:  Acc@1 83.140 || Acc@5 99.380\n","Epoch: [7][  0/704]\tTime  0.300 ( 0.300)\tLoss 1.6587e+01 (1.6587e+01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.077 ( 0.079)\tLoss 1.6582e+01 (1.9119e+01)\tAcc@1  92.19 ( 89.77)\tAcc@5 100.00 ( 99.75)\n","Epoch: [7][200/704]\tTime  0.077 ( 0.079)\tLoss 1.2677e+01 (1.9562e+01)\tAcc@1  89.06 ( 89.56)\tAcc@5 100.00 ( 99.74)\n","Epoch: [7][300/704]\tTime  0.077 ( 0.078)\tLoss 9.2578e+00 (1.9804e+01)\tAcc@1  95.31 ( 89.55)\tAcc@5 100.00 ( 99.70)\n","Epoch: [7][400/704]\tTime  0.075 ( 0.078)\tLoss 2.3662e+01 (1.9684e+01)\tAcc@1  84.38 ( 89.54)\tAcc@5 100.00 ( 99.69)\n","Epoch: [7][500/704]\tTime  0.077 ( 0.078)\tLoss 1.4209e+01 (1.9705e+01)\tAcc@1  90.62 ( 89.53)\tAcc@5 100.00 ( 99.67)\n","Epoch: [7][600/704]\tTime  0.076 ( 0.078)\tLoss 2.5176e+01 (1.9536e+01)\tAcc@1  87.50 ( 89.53)\tAcc@5  98.44 ( 99.67)\n","Epoch: [7][700/704]\tTime  0.075 ( 0.078)\tLoss 1.0734e+01 (1.9474e+01)\tAcc@1  95.31 ( 89.56)\tAcc@5 100.00 ( 99.68)\n","==> Train Accuracy: Acc@1 89.567 || Acc@5 99.678\n","==> Valid Accuracy:  Acc@1 83.700 || Acc@5 99.280\n","Best Top-1 Accuracy for fold1: 83.7\n","\n","FOLD 2\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.402 ( 0.402)\tLoss 1.5663e+01 (1.5663e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.078 ( 0.081)\tLoss 2.9363e+01 (3.4594e+01)\tAcc@1  85.94 ( 81.16)\tAcc@5 100.00 ( 99.18)\n","Epoch: [0][200/704]\tTime  0.078 ( 0.079)\tLoss 3.7944e+01 (3.5005e+01)\tAcc@1  79.69 ( 81.19)\tAcc@5 100.00 ( 99.20)\n","Epoch: [0][300/704]\tTime  0.076 ( 0.078)\tLoss 3.6913e+01 (3.5637e+01)\tAcc@1  82.81 ( 80.83)\tAcc@5 100.00 ( 99.14)\n","Epoch: [0][400/704]\tTime  0.077 ( 0.078)\tLoss 2.5979e+01 (3.5670e+01)\tAcc@1  87.50 ( 80.74)\tAcc@5 100.00 ( 99.12)\n","Epoch: [0][500/704]\tTime  0.077 ( 0.078)\tLoss 4.0309e+01 (3.6539e+01)\tAcc@1  82.81 ( 80.41)\tAcc@5  96.88 ( 98.99)\n","Epoch: [0][600/704]\tTime  0.076 ( 0.077)\tLoss 5.4698e+01 (3.8482e+01)\tAcc@1  67.19 ( 79.33)\tAcc@5  98.44 ( 98.84)\n","Epoch: [0][700/704]\tTime  0.075 ( 0.077)\tLoss 4.4638e+01 (3.8599e+01)\tAcc@1  78.12 ( 79.26)\tAcc@5  98.44 ( 98.83)\n","==> Train Accuracy: Acc@1 79.262 || Acc@5 98.822\n","==> Valid Accuracy:  Acc@1 76.240 || Acc@5 98.580\n","Epoch: [1][  0/704]\tTime  0.331 ( 0.331)\tLoss 4.6934e+01 (4.6934e+01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.077 ( 0.080)\tLoss 3.1407e+01 (3.2343e+01)\tAcc@1  82.81 ( 82.80)\tAcc@5 100.00 ( 99.27)\n","Epoch: [1][200/704]\tTime  0.077 ( 0.078)\tLoss 3.5946e+01 (3.2105e+01)\tAcc@1  76.56 ( 82.69)\tAcc@5 100.00 ( 99.22)\n","Epoch: [1][300/704]\tTime  0.075 ( 0.078)\tLoss 2.4927e+01 (3.1753e+01)\tAcc@1  84.38 ( 82.91)\tAcc@5 100.00 ( 99.24)\n","Epoch: [1][400/704]\tTime  0.076 ( 0.078)\tLoss 3.3092e+01 (3.1931e+01)\tAcc@1  82.81 ( 82.83)\tAcc@5 100.00 ( 99.23)\n","Epoch: [1][500/704]\tTime  0.075 ( 0.077)\tLoss 3.9308e+01 (3.2157e+01)\tAcc@1  75.00 ( 82.68)\tAcc@5  98.44 ( 99.24)\n","Epoch: [1][600/704]\tTime  0.077 ( 0.077)\tLoss 4.5326e+01 (3.2309e+01)\tAcc@1  79.69 ( 82.64)\tAcc@5  96.88 ( 99.22)\n","Epoch: [1][700/704]\tTime  0.074 ( 0.077)\tLoss 4.1842e+01 (3.3679e+01)\tAcc@1  75.00 ( 81.92)\tAcc@5  98.44 ( 99.17)\n","==> Train Accuracy: Acc@1 81.929 || Acc@5 99.171\n","==> Valid Accuracy:  Acc@1 78.900 || Acc@5 98.680\n","Epoch: [2][  0/704]\tTime  0.391 ( 0.391)\tLoss 2.8210e+01 (2.8210e+01)\tAcc@1  89.06 ( 89.06)\tAcc@5  98.44 ( 98.44)\n","Epoch: [2][100/704]\tTime  0.075 ( 0.080)\tLoss 2.4422e+01 (2.8731e+01)\tAcc@1  84.38 ( 85.16)\tAcc@5  98.44 ( 99.30)\n","Epoch: [2][200/704]\tTime  0.077 ( 0.079)\tLoss 3.2807e+01 (2.7735e+01)\tAcc@1  85.94 ( 85.24)\tAcc@5  98.44 ( 99.43)\n","Epoch: [2][300/704]\tTime  0.077 ( 0.078)\tLoss 3.3643e+01 (2.8408e+01)\tAcc@1  81.25 ( 84.85)\tAcc@5  98.44 ( 99.41)\n","Epoch: [2][400/704]\tTime  0.075 ( 0.077)\tLoss 2.4511e+01 (2.9804e+01)\tAcc@1  81.25 ( 84.04)\tAcc@5 100.00 ( 99.38)\n","Epoch: [2][500/704]\tTime  0.076 ( 0.077)\tLoss 2.9916e+01 (2.9802e+01)\tAcc@1  82.81 ( 84.04)\tAcc@5  98.44 ( 99.37)\n","Epoch: [2][600/704]\tTime  0.075 ( 0.077)\tLoss 2.6700e+01 (2.9734e+01)\tAcc@1  81.25 ( 84.00)\tAcc@5 100.00 ( 99.39)\n","Epoch: [2][700/704]\tTime  0.074 ( 0.077)\tLoss 3.7852e+01 (2.9562e+01)\tAcc@1  79.69 ( 84.07)\tAcc@5 100.00 ( 99.39)\n","==> Train Accuracy: Acc@1 84.069 || Acc@5 99.387\n","==> Valid Accuracy:  Acc@1 83.280 || Acc@5 99.140\n","Epoch: [3][  0/704]\tTime  0.308 ( 0.308)\tLoss 2.9752e+01 (2.9752e+01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.081 ( 0.080)\tLoss 3.3169e+01 (2.7530e+01)\tAcc@1  79.69 ( 85.01)\tAcc@5 100.00 ( 99.54)\n","Epoch: [3][200/704]\tTime  0.078 ( 0.078)\tLoss 2.4369e+01 (2.7291e+01)\tAcc@1  85.94 ( 85.32)\tAcc@5 100.00 ( 99.44)\n","Epoch: [3][300/704]\tTime  0.075 ( 0.077)\tLoss 1.2482e+01 (2.5969e+01)\tAcc@1  93.75 ( 85.98)\tAcc@5 100.00 ( 99.46)\n","Epoch: [3][400/704]\tTime  0.075 ( 0.077)\tLoss 2.8394e+01 (2.6144e+01)\tAcc@1  84.38 ( 85.89)\tAcc@5 100.00 ( 99.48)\n","Epoch: [3][500/704]\tTime  0.075 ( 0.077)\tLoss 3.0542e+01 (2.6097e+01)\tAcc@1  78.12 ( 85.86)\tAcc@5 100.00 ( 99.50)\n","Epoch: [3][600/704]\tTime  0.077 ( 0.077)\tLoss 2.8510e+01 (2.6057e+01)\tAcc@1  84.38 ( 85.87)\tAcc@5 100.00 ( 99.50)\n","Epoch: [3][700/704]\tTime  0.072 ( 0.077)\tLoss 2.8090e+01 (2.6020e+01)\tAcc@1  85.94 ( 85.94)\tAcc@5  98.44 ( 99.50)\n","==> Train Accuracy: Acc@1 85.944 || Acc@5 99.500\n","==> Valid Accuracy:  Acc@1 82.920 || Acc@5 98.820\n","Epoch: [4][  0/704]\tTime  0.347 ( 0.347)\tLoss 2.7135e+01 (2.7135e+01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.077 ( 0.079)\tLoss 2.1503e+01 (2.0585e+01)\tAcc@1  89.06 ( 89.11)\tAcc@5 100.00 ( 99.69)\n","Epoch: [4][200/704]\tTime  0.076 ( 0.078)\tLoss 2.9842e+01 (2.0253e+01)\tAcc@1  84.38 ( 89.24)\tAcc@5 100.00 ( 99.70)\n","Epoch: [4][300/704]\tTime  0.076 ( 0.077)\tLoss 1.7119e+01 (2.0434e+01)\tAcc@1  87.50 ( 89.02)\tAcc@5 100.00 ( 99.65)\n","Epoch: [4][400/704]\tTime  0.077 ( 0.077)\tLoss 1.9113e+01 (2.0969e+01)\tAcc@1  93.75 ( 88.83)\tAcc@5  98.44 ( 99.61)\n","Epoch: [4][500/704]\tTime  0.075 ( 0.077)\tLoss 1.5475e+01 (2.1615e+01)\tAcc@1  92.19 ( 88.47)\tAcc@5 100.00 ( 99.61)\n","Epoch: [4][600/704]\tTime  0.077 ( 0.077)\tLoss 2.2105e+01 (2.1776e+01)\tAcc@1  85.94 ( 88.32)\tAcc@5 100.00 ( 99.61)\n","Epoch: [4][700/704]\tTime  0.073 ( 0.077)\tLoss 1.8597e+01 (2.1867e+01)\tAcc@1  92.19 ( 88.22)\tAcc@5  98.44 ( 99.62)\n","==> Train Accuracy: Acc@1 88.224 || Acc@5 99.622\n","==> Valid Accuracy:  Acc@1 83.640 || Acc@5 99.060\n","Epoch: [5][  0/704]\tTime  0.331 ( 0.331)\tLoss 1.8835e+01 (1.8835e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.078 ( 0.079)\tLoss 1.1140e+01 (1.4643e+01)\tAcc@1  92.19 ( 92.13)\tAcc@5 100.00 ( 99.86)\n","Epoch: [5][200/704]\tTime  0.075 ( 0.078)\tLoss 8.8239e+00 (1.3353e+01)\tAcc@1  96.88 ( 92.99)\tAcc@5 100.00 ( 99.85)\n","Epoch: [5][300/704]\tTime  0.077 ( 0.077)\tLoss 1.4564e+01 (1.2907e+01)\tAcc@1  93.75 ( 93.22)\tAcc@5 100.00 ( 99.85)\n","Epoch: [5][400/704]\tTime  0.076 ( 0.077)\tLoss 1.4233e+01 (1.2532e+01)\tAcc@1  93.75 ( 93.47)\tAcc@5 100.00 ( 99.87)\n","Epoch: [5][500/704]\tTime  0.075 ( 0.077)\tLoss 6.9420e+00 (1.2272e+01)\tAcc@1  98.44 ( 93.57)\tAcc@5  98.44 ( 99.87)\n","Epoch: [5][600/704]\tTime  0.081 ( 0.077)\tLoss 1.1857e+01 (1.1979e+01)\tAcc@1  93.75 ( 93.72)\tAcc@5 100.00 ( 99.87)\n","Epoch: [5][700/704]\tTime  0.075 ( 0.077)\tLoss 7.0678e+00 (1.1664e+01)\tAcc@1  96.88 ( 93.89)\tAcc@5 100.00 ( 99.88)\n","==> Train Accuracy: Acc@1 93.891 || Acc@5 99.880\n","==> Valid Accuracy:  Acc@1 87.480 || Acc@5 99.420\n","Epoch: [6][  0/704]\tTime  0.409 ( 0.409)\tLoss 1.1657e+01 (1.1657e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.075 ( 0.080)\tLoss 1.8222e+01 (8.4739e+00)\tAcc@1  92.19 ( 95.53)\tAcc@5 100.00 ( 99.86)\n","Epoch: [6][200/704]\tTime  0.076 ( 0.078)\tLoss 6.6594e+00 (8.3380e+00)\tAcc@1  96.88 ( 95.43)\tAcc@5 100.00 ( 99.91)\n","Epoch: [6][300/704]\tTime  0.078 ( 0.078)\tLoss 4.6745e+00 (8.3051e+00)\tAcc@1  98.44 ( 95.45)\tAcc@5 100.00 ( 99.92)\n","Epoch: [6][400/704]\tTime  0.075 ( 0.077)\tLoss 3.9021e+00 (8.2543e+00)\tAcc@1 100.00 ( 95.49)\tAcc@5 100.00 ( 99.94)\n","Epoch: [6][500/704]\tTime  0.078 ( 0.077)\tLoss 1.2021e+01 (8.2970e+00)\tAcc@1  90.62 ( 95.46)\tAcc@5 100.00 ( 99.93)\n","Epoch: [6][600/704]\tTime  0.077 ( 0.077)\tLoss 1.5896e+01 (8.2488e+00)\tAcc@1  90.62 ( 95.53)\tAcc@5 100.00 ( 99.93)\n","Epoch: [6][700/704]\tTime  0.074 ( 0.077)\tLoss 1.1701e+01 (8.4545e+00)\tAcc@1  93.75 ( 95.48)\tAcc@5  98.44 ( 99.92)\n","==> Train Accuracy: Acc@1 95.480 || Acc@5 99.920\n","==> Valid Accuracy:  Acc@1 87.720 || Acc@5 99.180\n","Epoch: [7][  0/704]\tTime  0.397 ( 0.397)\tLoss 4.5551e+00 (4.5551e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.077 ( 0.080)\tLoss 9.0762e+00 (6.2945e+00)\tAcc@1  96.88 ( 96.84)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.075 ( 0.078)\tLoss 9.4322e+00 (6.3618e+00)\tAcc@1  95.31 ( 96.80)\tAcc@5 100.00 ( 99.95)\n","Epoch: [7][300/704]\tTime  0.076 ( 0.078)\tLoss 2.6979e+00 (6.4801e+00)\tAcc@1  98.44 ( 96.81)\tAcc@5 100.00 ( 99.95)\n","Epoch: [7][400/704]\tTime  0.077 ( 0.077)\tLoss 5.7828e+00 (6.6437e+00)\tAcc@1  96.88 ( 96.73)\tAcc@5 100.00 ( 99.95)\n","Epoch: [7][500/704]\tTime  0.076 ( 0.077)\tLoss 1.4018e+01 (6.7164e+00)\tAcc@1  90.62 ( 96.66)\tAcc@5 100.00 ( 99.95)\n","Epoch: [7][600/704]\tTime  0.076 ( 0.077)\tLoss 7.3844e+00 (6.7210e+00)\tAcc@1  98.44 ( 96.62)\tAcc@5  98.44 ( 99.95)\n","Epoch: [7][700/704]\tTime  0.074 ( 0.077)\tLoss 3.8191e+00 (6.6936e+00)\tAcc@1  98.44 ( 96.60)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 96.600 || Acc@5 99.956\n","==> Valid Accuracy:  Acc@1 86.900 || Acc@5 99.380\n","Best Top-1 Accuracy for fold2: 87.72\n","\n","FOLD 3\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.279 ( 0.279)\tLoss 3.4184e+00 (3.4184e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.076 ( 0.078)\tLoss 1.6800e+01 (1.7445e+01)\tAcc@1  92.19 ( 90.76)\tAcc@5 100.00 ( 99.75)\n","Epoch: [0][200/704]\tTime  0.078 ( 0.077)\tLoss 2.4842e+01 (1.7617e+01)\tAcc@1  81.25 ( 90.64)\tAcc@5 100.00 ( 99.73)\n","Epoch: [0][300/704]\tTime  0.077 ( 0.077)\tLoss 2.8133e+01 (1.8343e+01)\tAcc@1  87.50 ( 90.14)\tAcc@5 100.00 ( 99.76)\n","Epoch: [0][400/704]\tTime  0.075 ( 0.077)\tLoss 2.6624e+01 (1.8566e+01)\tAcc@1  85.94 ( 89.98)\tAcc@5 100.00 ( 99.72)\n","Epoch: [0][500/704]\tTime  0.076 ( 0.077)\tLoss 8.8063e+00 (1.8998e+01)\tAcc@1  96.88 ( 89.75)\tAcc@5 100.00 ( 99.71)\n","Epoch: [0][600/704]\tTime  0.076 ( 0.077)\tLoss 2.0449e+01 (1.9427e+01)\tAcc@1  90.62 ( 89.48)\tAcc@5 100.00 ( 99.71)\n","Epoch: [0][700/704]\tTime  0.076 ( 0.076)\tLoss 2.0679e+01 (2.0810e+01)\tAcc@1  89.06 ( 88.79)\tAcc@5 100.00 ( 99.64)\n","==> Train Accuracy: Acc@1 88.787 || Acc@5 99.640\n","==> Valid Accuracy:  Acc@1 85.460 || Acc@5 99.620\n","Epoch: [1][  0/704]\tTime  0.415 ( 0.415)\tLoss 1.3045e+01 (1.3045e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.075 ( 0.079)\tLoss 9.4903e+00 (3.9866e+01)\tAcc@1  95.31 ( 79.67)\tAcc@5 100.00 ( 98.75)\n","Epoch: [1][200/704]\tTime  0.077 ( 0.078)\tLoss 1.8433e+01 (3.0639e+01)\tAcc@1  89.06 ( 84.07)\tAcc@5 100.00 ( 99.25)\n","Epoch: [1][300/704]\tTime  0.077 ( 0.078)\tLoss 1.5008e+01 (2.6879e+01)\tAcc@1  90.62 ( 85.84)\tAcc@5 100.00 ( 99.42)\n","Epoch: [1][400/704]\tTime  0.075 ( 0.077)\tLoss 1.8143e+01 (2.4910e+01)\tAcc@1  90.62 ( 86.71)\tAcc@5 100.00 ( 99.51)\n","Epoch: [1][500/704]\tTime  0.076 ( 0.077)\tLoss 1.0264e+01 (2.3574e+01)\tAcc@1  96.88 ( 87.41)\tAcc@5 100.00 ( 99.56)\n","Epoch: [1][600/704]\tTime  0.075 ( 0.077)\tLoss 9.6515e+00 (2.2549e+01)\tAcc@1  95.31 ( 87.90)\tAcc@5 100.00 ( 99.60)\n","Epoch: [1][700/704]\tTime  0.074 ( 0.077)\tLoss 2.6311e+01 (2.1916e+01)\tAcc@1  89.06 ( 88.24)\tAcc@5 100.00 ( 99.63)\n","==> Train Accuracy: Acc@1 88.253 || Acc@5 99.629\n","==> Valid Accuracy:  Acc@1 89.620 || Acc@5 99.780\n","Epoch: [2][  0/704]\tTime  0.298 ( 0.298)\tLoss 1.8635e+01 (1.8635e+01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.074 ( 0.078)\tLoss 1.3786e+01 (1.1940e+01)\tAcc@1  89.06 ( 93.61)\tAcc@5 100.00 ( 99.92)\n","Epoch: [2][200/704]\tTime  0.076 ( 0.078)\tLoss 5.2976e+00 (1.2838e+01)\tAcc@1  96.88 ( 92.89)\tAcc@5 100.00 ( 99.91)\n","Epoch: [2][300/704]\tTime  0.074 ( 0.077)\tLoss 1.6957e+01 (1.3614e+01)\tAcc@1  90.62 ( 92.47)\tAcc@5 100.00 ( 99.87)\n","Epoch: [2][400/704]\tTime  0.075 ( 0.077)\tLoss 1.7911e+01 (1.3969e+01)\tAcc@1  93.75 ( 92.28)\tAcc@5 100.00 ( 99.88)\n","Epoch: [2][500/704]\tTime  0.085 ( 0.077)\tLoss 1.6424e+01 (1.4250e+01)\tAcc@1  92.19 ( 92.12)\tAcc@5 100.00 ( 99.87)\n","Epoch: [2][600/704]\tTime  0.076 ( 0.077)\tLoss 2.5095e+01 (1.4616e+01)\tAcc@1  92.19 ( 91.96)\tAcc@5 100.00 ( 99.87)\n","Epoch: [2][700/704]\tTime  0.074 ( 0.077)\tLoss 1.2558e+01 (1.5994e+01)\tAcc@1  95.31 ( 91.39)\tAcc@5 100.00 ( 99.83)\n","==> Train Accuracy: Acc@1 91.378 || Acc@5 99.829\n","==> Valid Accuracy:  Acc@1 88.980 || Acc@5 99.740\n","Epoch: [3][  0/704]\tTime  0.372 ( 0.372)\tLoss 9.6389e+00 (9.6389e+00)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.075 ( 0.079)\tLoss 1.1681e+01 (1.2179e+01)\tAcc@1  90.62 ( 93.29)\tAcc@5  98.44 ( 99.88)\n","Epoch: [3][200/704]\tTime  0.076 ( 0.078)\tLoss 4.5544e+00 (1.2068e+01)\tAcc@1  98.44 ( 93.36)\tAcc@5 100.00 ( 99.88)\n","Epoch: [3][300/704]\tTime  0.077 ( 0.077)\tLoss 1.1700e+01 (1.2045e+01)\tAcc@1  95.31 ( 93.28)\tAcc@5 100.00 ( 99.91)\n","Epoch: [3][400/704]\tTime  0.075 ( 0.077)\tLoss 2.3716e+01 (1.2069e+01)\tAcc@1  87.50 ( 93.22)\tAcc@5 100.00 ( 99.91)\n","Epoch: [3][500/704]\tTime  0.075 ( 0.077)\tLoss 1.5537e+01 (1.2329e+01)\tAcc@1  95.31 ( 93.15)\tAcc@5 100.00 ( 99.89)\n","Epoch: [3][600/704]\tTime  0.076 ( 0.077)\tLoss 2.6715e+01 (1.2687e+01)\tAcc@1  89.06 ( 92.97)\tAcc@5 100.00 ( 99.89)\n","Epoch: [3][700/704]\tTime  0.074 ( 0.077)\tLoss 6.4168e+00 (1.2908e+01)\tAcc@1  96.88 ( 92.87)\tAcc@5 100.00 ( 99.88)\n","==> Train Accuracy: Acc@1 92.858 || Acc@5 99.882\n","==> Valid Accuracy:  Acc@1 89.540 || Acc@5 99.760\n","Epoch: [4][  0/704]\tTime  0.269 ( 0.269)\tLoss 7.5071e+00 (7.5071e+00)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.075 ( 0.078)\tLoss 8.7911e+00 (9.6028e+00)\tAcc@1  95.31 ( 94.76)\tAcc@5 100.00 ( 99.95)\n","Epoch: [4][200/704]\tTime  0.075 ( 0.077)\tLoss 1.0392e+01 (1.2416e+01)\tAcc@1  95.31 ( 93.58)\tAcc@5 100.00 ( 99.91)\n","Epoch: [4][300/704]\tTime  0.075 ( 0.077)\tLoss 1.6880e+01 (1.2152e+01)\tAcc@1  92.19 ( 93.63)\tAcc@5 100.00 ( 99.92)\n","Epoch: [4][400/704]\tTime  0.075 ( 0.076)\tLoss 1.4978e+01 (1.2150e+01)\tAcc@1  87.50 ( 93.56)\tAcc@5 100.00 ( 99.92)\n","Epoch: [4][500/704]\tTime  0.075 ( 0.076)\tLoss 6.1889e+00 (1.2154e+01)\tAcc@1  96.88 ( 93.55)\tAcc@5 100.00 ( 99.93)\n","Epoch: [4][600/704]\tTime  0.077 ( 0.076)\tLoss 2.2001e+01 (1.2400e+01)\tAcc@1  85.94 ( 93.43)\tAcc@5 100.00 ( 99.92)\n","Epoch: [4][700/704]\tTime  0.073 ( 0.076)\tLoss 7.1870e+00 (1.2650e+01)\tAcc@1  96.88 ( 93.30)\tAcc@5 100.00 ( 99.91)\n","==> Train Accuracy: Acc@1 93.298 || Acc@5 99.913\n","==> Valid Accuracy:  Acc@1 87.740 || Acc@5 99.700\n","Epoch: [5][  0/704]\tTime  0.392 ( 0.392)\tLoss 1.0027e+01 (1.0027e+01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.076 ( 0.079)\tLoss 8.9552e+00 (8.7243e+00)\tAcc@1  93.75 ( 95.42)\tAcc@5 100.00 ( 99.97)\n","Epoch: [5][200/704]\tTime  0.076 ( 0.078)\tLoss 2.6568e+00 (7.6451e+00)\tAcc@1 100.00 ( 96.01)\tAcc@5 100.00 ( 99.98)\n","Epoch: [5][300/704]\tTime  0.077 ( 0.077)\tLoss 3.9272e+00 (7.0311e+00)\tAcc@1 100.00 ( 96.31)\tAcc@5 100.00 ( 99.98)\n","Epoch: [5][400/704]\tTime  0.075 ( 0.077)\tLoss 3.2360e+00 (6.8013e+00)\tAcc@1  98.44 ( 96.44)\tAcc@5 100.00 ( 99.98)\n","Epoch: [5][500/704]\tTime  0.076 ( 0.077)\tLoss 8.1409e+00 (6.3890e+00)\tAcc@1  93.75 ( 96.67)\tAcc@5 100.00 ( 99.99)\n","Epoch: [5][600/704]\tTime  0.078 ( 0.077)\tLoss 3.1866e+00 (6.1553e+00)\tAcc@1  98.44 ( 96.82)\tAcc@5 100.00 ( 99.99)\n","Epoch: [5][700/704]\tTime  0.074 ( 0.077)\tLoss 9.3183e+00 (5.9318e+00)\tAcc@1  93.75 ( 96.95)\tAcc@5 100.00 ( 99.98)\n","==> Train Accuracy: Acc@1 96.958 || Acc@5 99.982\n","==> Valid Accuracy:  Acc@1 91.760 || Acc@5 99.820\n","Epoch: [6][  0/704]\tTime  0.314 ( 0.314)\tLoss 6.6374e+00 (6.6374e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.076 ( 0.079)\tLoss 7.1380e+00 (3.7879e+00)\tAcc@1  98.44 ( 98.13)\tAcc@5 100.00 (100.00)\n","Epoch: [6][200/704]\tTime  0.077 ( 0.078)\tLoss 6.2255e+00 (3.7587e+00)\tAcc@1  95.31 ( 98.13)\tAcc@5 100.00 ( 99.98)\n","Epoch: [6][300/704]\tTime  0.075 ( 0.077)\tLoss 3.8738e+00 (3.6566e+00)\tAcc@1  96.88 ( 98.20)\tAcc@5 100.00 ( 99.98)\n","Epoch: [6][400/704]\tTime  0.077 ( 0.077)\tLoss 4.9471e+00 (3.6031e+00)\tAcc@1  98.44 ( 98.22)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][500/704]\tTime  0.075 ( 0.077)\tLoss 2.4250e+00 (3.4859e+00)\tAcc@1  98.44 ( 98.25)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][600/704]\tTime  0.076 ( 0.077)\tLoss 1.4032e+00 (3.4287e+00)\tAcc@1 100.00 ( 98.27)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][700/704]\tTime  0.074 ( 0.077)\tLoss 1.0162e+00 (3.3947e+00)\tAcc@1 100.00 ( 98.31)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.302 || Acc@5 99.989\n","==> Valid Accuracy:  Acc@1 92.560 || Acc@5 99.820\n","Epoch: [7][  0/704]\tTime  0.380 ( 0.380)\tLoss 3.4361e+00 (3.4361e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.077 ( 0.079)\tLoss 1.5378e+00 (2.3395e+00)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 ( 99.98)\n","Epoch: [7][200/704]\tTime  0.076 ( 0.078)\tLoss 2.5871e+00 (2.2593e+00)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 ( 99.99)\n","Epoch: [7][300/704]\tTime  0.075 ( 0.078)\tLoss 5.2007e-01 (2.1337e+00)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.99)\n","Epoch: [7][400/704]\tTime  0.077 ( 0.077)\tLoss 1.2316e+00 (2.1002e+00)\tAcc@1  98.44 ( 99.03)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.075 ( 0.077)\tLoss 8.3264e-01 (2.1838e+00)\tAcc@1 100.00 ( 99.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.077 ( 0.077)\tLoss 6.0433e-01 (2.1201e+00)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.99)\n","Epoch: [7][700/704]\tTime  0.074 ( 0.077)\tLoss 3.0125e+00 (2.1906e+00)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.947 || Acc@5 99.996\n","==> Valid Accuracy:  Acc@1 92.280 || Acc@5 99.720\n","Best Top-1 Accuracy for fold3: 92.56\n","\n","FOLD 4\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.275 ( 0.275)\tLoss 1.0021e+01 (1.0021e+01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.076 ( 0.078)\tLoss 5.7944e+00 (8.4171e+00)\tAcc@1  98.44 ( 95.64)\tAcc@5 100.00 ( 99.98)\n","Epoch: [0][200/704]\tTime  0.077 ( 0.078)\tLoss 1.5378e+01 (9.9926e+00)\tAcc@1  90.62 ( 94.81)\tAcc@5 100.00 ( 99.95)\n","Epoch: [0][300/704]\tTime  0.076 ( 0.077)\tLoss 2.0371e+01 (1.0702e+01)\tAcc@1  87.50 ( 94.32)\tAcc@5 100.00 ( 99.94)\n","Epoch: [0][400/704]\tTime  0.077 ( 0.077)\tLoss 1.8933e+01 (1.1154e+01)\tAcc@1  90.62 ( 94.17)\tAcc@5 100.00 ( 99.95)\n","Epoch: [0][500/704]\tTime  0.075 ( 0.077)\tLoss 1.3050e+01 (1.1196e+01)\tAcc@1  93.75 ( 94.11)\tAcc@5 100.00 ( 99.94)\n","Epoch: [0][600/704]\tTime  0.075 ( 0.077)\tLoss 1.6695e+01 (1.1263e+01)\tAcc@1  90.62 ( 94.05)\tAcc@5  98.44 ( 99.94)\n","Epoch: [0][700/704]\tTime  0.073 ( 0.077)\tLoss 1.0024e+01 (1.1396e+01)\tAcc@1  95.31 ( 93.98)\tAcc@5 100.00 ( 99.93)\n","==> Train Accuracy: Acc@1 93.973 || Acc@5 99.929\n","==> Valid Accuracy:  Acc@1 94.540 || Acc@5 99.940\n","Epoch: [1][  0/704]\tTime  0.308 ( 0.308)\tLoss 8.1020e+00 (8.1020e+00)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.076 ( 0.079)\tLoss 7.7404e+00 (8.9536e+00)\tAcc@1  93.75 ( 94.94)\tAcc@5 100.00 ( 99.95)\n","Epoch: [1][200/704]\tTime  0.075 ( 0.078)\tLoss 3.5427e+00 (8.8768e+00)\tAcc@1  98.44 ( 95.09)\tAcc@5 100.00 ( 99.97)\n","Epoch: [1][300/704]\tTime  0.076 ( 0.077)\tLoss 1.3085e+01 (9.2285e+00)\tAcc@1  93.75 ( 94.83)\tAcc@5 100.00 ( 99.96)\n","Epoch: [1][400/704]\tTime  0.076 ( 0.077)\tLoss 7.0197e+00 (9.8931e+00)\tAcc@1  96.88 ( 94.57)\tAcc@5 100.00 ( 99.96)\n","Epoch: [1][500/704]\tTime  0.074 ( 0.077)\tLoss 2.3156e+01 (1.0144e+01)\tAcc@1  85.94 ( 94.50)\tAcc@5 100.00 ( 99.96)\n","Epoch: [1][600/704]\tTime  0.078 ( 0.077)\tLoss 8.1279e+00 (1.0141e+01)\tAcc@1  96.88 ( 94.51)\tAcc@5 100.00 ( 99.96)\n","Epoch: [1][700/704]\tTime  0.076 ( 0.077)\tLoss 1.1155e+01 (1.0219e+01)\tAcc@1  93.75 ( 94.43)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 94.424 || Acc@5 99.953\n","==> Valid Accuracy:  Acc@1 91.300 || Acc@5 99.880\n","Epoch: [2][  0/704]\tTime  0.374 ( 0.374)\tLoss 1.0089e+01 (1.0089e+01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.075 ( 0.079)\tLoss 6.9995e+00 (7.7181e+00)\tAcc@1  96.88 ( 95.96)\tAcc@5 100.00 ( 99.97)\n","Epoch: [2][200/704]\tTime  0.076 ( 0.078)\tLoss 4.0677e+00 (7.8505e+00)\tAcc@1  96.88 ( 95.73)\tAcc@5 100.00 ( 99.95)\n","Epoch: [2][300/704]\tTime  0.076 ( 0.077)\tLoss 9.2345e+00 (7.9982e+00)\tAcc@1  95.31 ( 95.65)\tAcc@5 100.00 ( 99.96)\n","Epoch: [2][400/704]\tTime  0.075 ( 0.077)\tLoss 1.5189e+01 (8.2801e+00)\tAcc@1  92.19 ( 95.44)\tAcc@5 100.00 ( 99.96)\n","Epoch: [2][500/704]\tTime  0.077 ( 0.077)\tLoss 8.3218e+00 (8.6290e+00)\tAcc@1  96.88 ( 95.30)\tAcc@5 100.00 ( 99.97)\n","Epoch: [2][600/704]\tTime  0.077 ( 0.077)\tLoss 7.5328e+00 (8.6969e+00)\tAcc@1  93.75 ( 95.24)\tAcc@5 100.00 ( 99.96)\n","Epoch: [2][700/704]\tTime  0.075 ( 0.077)\tLoss 2.6070e+00 (8.8717e+00)\tAcc@1 100.00 ( 95.17)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 95.162 || Acc@5 99.964\n","==> Valid Accuracy:  Acc@1 93.600 || Acc@5 99.960\n","Epoch: [3][  0/704]\tTime  0.273 ( 0.273)\tLoss 8.1245e+00 (8.1245e+00)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.076 ( 0.078)\tLoss 4.2737e+00 (6.6010e+00)\tAcc@1  98.44 ( 96.47)\tAcc@5 100.00 (100.00)\n","Epoch: [3][200/704]\tTime  0.074 ( 0.077)\tLoss 6.5260e+00 (7.6738e+00)\tAcc@1  93.75 ( 95.84)\tAcc@5 100.00 (100.00)\n","Epoch: [3][300/704]\tTime  0.078 ( 0.077)\tLoss 2.5995e+01 (1.2234e+01)\tAcc@1  85.94 ( 93.71)\tAcc@5  98.44 ( 99.85)\n","Epoch: [3][400/704]\tTime  0.075 ( 0.077)\tLoss 1.9133e+01 (1.6235e+01)\tAcc@1  90.62 ( 91.94)\tAcc@5 100.00 ( 99.79)\n","Epoch: [3][500/704]\tTime  0.076 ( 0.077)\tLoss 1.9434e+01 (1.6408e+01)\tAcc@1  90.62 ( 91.73)\tAcc@5  98.44 ( 99.81)\n","Epoch: [3][600/704]\tTime  0.076 ( 0.076)\tLoss 1.2259e+01 (1.5518e+01)\tAcc@1  93.75 ( 92.05)\tAcc@5 100.00 ( 99.84)\n","Epoch: [3][700/704]\tTime  0.074 ( 0.076)\tLoss 1.1346e+01 (1.4768e+01)\tAcc@1  96.88 ( 92.37)\tAcc@5 100.00 ( 99.86)\n","==> Train Accuracy: Acc@1 92.378 || Acc@5 99.858\n","==> Valid Accuracy:  Acc@1 92.840 || Acc@5 99.940\n","Epoch: [4][  0/704]\tTime  0.356 ( 0.356)\tLoss 3.2956e+00 (3.2956e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.075 ( 0.079)\tLoss 1.0381e+01 (6.0944e+00)\tAcc@1  93.75 ( 96.74)\tAcc@5 100.00 (100.00)\n","Epoch: [4][200/704]\tTime  0.074 ( 0.077)\tLoss 3.3460e+00 (6.1696e+00)\tAcc@1  98.44 ( 96.81)\tAcc@5 100.00 ( 99.99)\n","Epoch: [4][300/704]\tTime  0.074 ( 0.077)\tLoss 7.9689e+00 (6.6020e+00)\tAcc@1  95.31 ( 96.57)\tAcc@5 100.00 ( 99.98)\n","Epoch: [4][400/704]\tTime  0.076 ( 0.077)\tLoss 1.0145e+01 (6.8234e+00)\tAcc@1  93.75 ( 96.47)\tAcc@5 100.00 ( 99.98)\n","Epoch: [4][500/704]\tTime  0.077 ( 0.077)\tLoss 6.6509e+00 (6.9633e+00)\tAcc@1  95.31 ( 96.37)\tAcc@5 100.00 ( 99.97)\n","Epoch: [4][600/704]\tTime  0.076 ( 0.077)\tLoss 8.0791e+00 (7.0202e+00)\tAcc@1  96.88 ( 96.32)\tAcc@5  98.44 ( 99.97)\n","Epoch: [4][700/704]\tTime  0.075 ( 0.077)\tLoss 5.5318e+00 (7.2927e+00)\tAcc@1  96.88 ( 96.15)\tAcc@5 100.00 ( 99.97)\n","==> Train Accuracy: Acc@1 96.138 || Acc@5 99.967\n","==> Valid Accuracy:  Acc@1 88.840 || Acc@5 99.800\n","Epoch: [5][  0/704]\tTime  0.280 ( 0.280)\tLoss 7.3968e+00 (7.3968e+00)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.076 ( 0.078)\tLoss 8.6616e+00 (8.1761e+00)\tAcc@1  96.88 ( 95.81)\tAcc@5 100.00 ( 99.97)\n","Epoch: [5][200/704]\tTime  0.076 ( 0.077)\tLoss 1.7091e+00 (7.2207e+00)\tAcc@1 100.00 ( 96.32)\tAcc@5 100.00 ( 99.98)\n","Epoch: [5][300/704]\tTime  0.075 ( 0.077)\tLoss 2.3216e+00 (6.3578e+00)\tAcc@1  98.44 ( 96.76)\tAcc@5 100.00 ( 99.97)\n","Epoch: [5][400/704]\tTime  0.076 ( 0.077)\tLoss 4.8958e+00 (5.8363e+00)\tAcc@1  95.31 ( 97.00)\tAcc@5 100.00 ( 99.98)\n","Epoch: [5][500/704]\tTime  0.075 ( 0.077)\tLoss 2.0537e+00 (5.3968e+00)\tAcc@1  98.44 ( 97.23)\tAcc@5 100.00 ( 99.98)\n","Epoch: [5][600/704]\tTime  0.075 ( 0.076)\tLoss 2.7880e+00 (5.0406e+00)\tAcc@1  96.88 ( 97.42)\tAcc@5 100.00 ( 99.99)\n","Epoch: [5][700/704]\tTime  0.072 ( 0.076)\tLoss 6.1429e-01 (4.7928e+00)\tAcc@1 100.00 ( 97.53)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 97.529 || Acc@5 99.989\n","==> Valid Accuracy:  Acc@1 94.340 || Acc@5 99.920\n","Epoch: [6][  0/704]\tTime  0.366 ( 0.366)\tLoss 6.3317e-01 (6.3317e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.077 ( 0.079)\tLoss 2.4542e+00 (2.4557e+00)\tAcc@1  98.44 ( 98.86)\tAcc@5 100.00 (100.00)\n","Epoch: [6][200/704]\tTime  0.077 ( 0.078)\tLoss 1.6509e+00 (2.3533e+00)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 (100.00)\n","Epoch: [6][300/704]\tTime  0.076 ( 0.077)\tLoss 1.1716e+00 (2.2222e+00)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 (100.00)\n","Epoch: [6][400/704]\tTime  0.075 ( 0.077)\tLoss 2.8081e+00 (2.1778e+00)\tAcc@1  98.44 ( 98.92)\tAcc@5 100.00 (100.00)\n","Epoch: [6][500/704]\tTime  0.075 ( 0.077)\tLoss 2.6932e+00 (2.1568e+00)\tAcc@1  96.88 ( 98.94)\tAcc@5 100.00 (100.00)\n","Epoch: [6][600/704]\tTime  0.075 ( 0.077)\tLoss 2.3919e-01 (2.1242e+00)\tAcc@1 100.00 ( 98.96)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][700/704]\tTime  0.074 ( 0.077)\tLoss 1.6645e+00 (2.0600e+00)\tAcc@1  98.44 ( 99.00)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 98.996 || Acc@5 99.991\n","==> Valid Accuracy:  Acc@1 95.180 || Acc@5 99.940\n","Epoch: [7][  0/704]\tTime  0.324 ( 0.324)\tLoss 6.3578e-01 (6.3578e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.077 ( 0.079)\tLoss 2.1851e+00 (1.2519e+00)\tAcc@1  98.44 ( 99.47)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.076 ( 0.078)\tLoss 5.4425e-01 (1.4745e+00)\tAcc@1 100.00 ( 99.35)\tAcc@5 100.00 (100.00)\n","Epoch: [7][300/704]\tTime  0.076 ( 0.078)\tLoss 5.4254e-01 (1.3588e+00)\tAcc@1 100.00 ( 99.41)\tAcc@5 100.00 (100.00)\n","Epoch: [7][400/704]\tTime  0.077 ( 0.078)\tLoss 3.1568e-01 (1.3098e+00)\tAcc@1 100.00 ( 99.43)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.077 ( 0.077)\tLoss 1.0028e+00 (1.3096e+00)\tAcc@1  98.44 ( 99.43)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.076 ( 0.077)\tLoss 8.0424e-01 (1.3312e+00)\tAcc@1 100.00 ( 99.40)\tAcc@5 100.00 (100.00)\n","Epoch: [7][700/704]\tTime  0.075 ( 0.077)\tLoss 4.2274e-01 (1.2928e+00)\tAcc@1 100.00 ( 99.41)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.404 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 95.220 || Acc@5 99.940\n","Best Top-1 Accuracy for fold4: 95.22\n","\n","FOLD 5\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.374 ( 0.374)\tLoss 6.1999e-01 (6.1999e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.076 ( 0.079)\tLoss 2.8539e+00 (6.5017e+00)\tAcc@1  98.44 ( 96.55)\tAcc@5 100.00 (100.00)\n","Epoch: [0][200/704]\tTime  0.075 ( 0.078)\tLoss 6.5840e+00 (6.9977e+00)\tAcc@1  96.88 ( 96.32)\tAcc@5 100.00 (100.00)\n","Epoch: [0][300/704]\tTime  0.076 ( 0.077)\tLoss 1.3559e+01 (7.2632e+00)\tAcc@1  90.62 ( 96.23)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][400/704]\tTime  0.076 ( 0.077)\tLoss 8.1263e+00 (7.7698e+00)\tAcc@1  95.31 ( 96.05)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][500/704]\tTime  0.076 ( 0.077)\tLoss 8.6241e+00 (7.8321e+00)\tAcc@1  95.31 ( 96.00)\tAcc@5 100.00 ( 99.98)\n","Epoch: [0][600/704]\tTime  0.076 ( 0.077)\tLoss 7.4213e+00 (7.8727e+00)\tAcc@1  95.31 ( 95.91)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][700/704]\tTime  0.073 ( 0.077)\tLoss 2.8736e+00 (7.9771e+00)\tAcc@1  98.44 ( 95.85)\tAcc@5 100.00 ( 99.98)\n","==> Train Accuracy: Acc@1 95.849 || Acc@5 99.982\n","==> Valid Accuracy:  Acc@1 95.700 || Acc@5 100.000\n","Epoch: [1][  0/704]\tTime  0.300 ( 0.300)\tLoss 2.0579e+00 (2.0579e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.077 ( 0.078)\tLoss 7.4291e+00 (5.4342e+00)\tAcc@1  95.31 ( 97.00)\tAcc@5 100.00 (100.00)\n","Epoch: [1][200/704]\tTime  0.077 ( 0.078)\tLoss 6.3944e+00 (5.9646e+00)\tAcc@1  95.31 ( 96.62)\tAcc@5 100.00 ( 99.98)\n","Epoch: [1][300/704]\tTime  0.076 ( 0.077)\tLoss 1.2083e+01 (6.2683e+00)\tAcc@1  95.31 ( 96.48)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][400/704]\tTime  0.078 ( 0.077)\tLoss 8.7424e+00 (6.4171e+00)\tAcc@1  95.31 ( 96.38)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][500/704]\tTime  0.075 ( 0.077)\tLoss 8.0428e+00 (6.5288e+00)\tAcc@1  95.31 ( 96.34)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][600/704]\tTime  0.075 ( 0.077)\tLoss 1.5213e+01 (6.6679e+00)\tAcc@1  89.06 ( 96.28)\tAcc@5 100.00 ( 99.98)\n","Epoch: [1][700/704]\tTime  0.073 ( 0.077)\tLoss 4.6566e+00 (6.7858e+00)\tAcc@1  96.88 ( 96.24)\tAcc@5 100.00 ( 99.98)\n","==> Train Accuracy: Acc@1 96.242 || Acc@5 99.984\n","==> Valid Accuracy:  Acc@1 96.320 || Acc@5 100.000\n","Epoch: [2][  0/704]\tTime  0.291 ( 0.291)\tLoss 8.2733e+00 (8.2733e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.075 ( 0.078)\tLoss 4.7545e+00 (4.5323e+00)\tAcc@1  95.31 ( 97.60)\tAcc@5 100.00 ( 99.98)\n","Epoch: [2][200/704]\tTime  0.077 ( 0.078)\tLoss 1.2230e+01 (5.1692e+00)\tAcc@1  96.88 ( 97.24)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][300/704]\tTime  0.075 ( 0.077)\tLoss 6.0091e+00 (5.3791e+00)\tAcc@1  95.31 ( 97.13)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][400/704]\tTime  0.075 ( 0.077)\tLoss 1.7330e+01 (5.9046e+00)\tAcc@1  92.19 ( 96.90)\tAcc@5 100.00 ( 99.98)\n","Epoch: [2][500/704]\tTime  0.075 ( 0.077)\tLoss 4.9035e+00 (6.1900e+00)\tAcc@1  96.88 ( 96.66)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][600/704]\tTime  0.076 ( 0.077)\tLoss 3.4951e+00 (6.5864e+00)\tAcc@1  98.44 ( 96.48)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][700/704]\tTime  0.074 ( 0.077)\tLoss 2.4215e+00 (6.8105e+00)\tAcc@1  98.44 ( 96.35)\tAcc@5 100.00 ( 99.98)\n","==> Train Accuracy: Acc@1 96.351 || Acc@5 99.980\n","==> Valid Accuracy:  Acc@1 95.600 || Acc@5 99.980\n","Epoch: [3][  0/704]\tTime  0.377 ( 0.377)\tLoss 2.6003e+00 (2.6003e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.075 ( 0.079)\tLoss 7.9398e+00 (5.2115e+00)\tAcc@1  96.88 ( 97.35)\tAcc@5 100.00 ( 99.98)\n","Epoch: [3][200/704]\tTime  0.075 ( 0.078)\tLoss 1.0780e+01 (9.0207e+00)\tAcc@1  93.75 ( 95.20)\tAcc@5 100.00 ( 99.96)\n","Epoch: [3][300/704]\tTime  0.074 ( 0.077)\tLoss 8.6229e+00 (8.8409e+00)\tAcc@1  92.19 ( 95.27)\tAcc@5 100.00 ( 99.97)\n","Epoch: [3][400/704]\tTime  0.077 ( 0.077)\tLoss 1.3266e+01 (8.9591e+00)\tAcc@1  92.19 ( 95.22)\tAcc@5 100.00 ( 99.97)\n","Epoch: [3][500/704]\tTime  0.076 ( 0.077)\tLoss 4.2377e+00 (8.7323e+00)\tAcc@1  96.88 ( 95.36)\tAcc@5 100.00 ( 99.97)\n","Epoch: [3][600/704]\tTime  0.076 ( 0.077)\tLoss 2.3019e+00 (8.3252e+00)\tAcc@1  98.44 ( 95.52)\tAcc@5 100.00 ( 99.98)\n","Epoch: [3][700/704]\tTime  0.072 ( 0.077)\tLoss 4.1027e+00 (8.6442e+00)\tAcc@1  98.44 ( 95.37)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 95.362 || Acc@5 99.964\n","==> Valid Accuracy:  Acc@1 91.940 || Acc@5 99.960\n","Epoch: [4][  0/704]\tTime  0.296 ( 0.296)\tLoss 1.2627e+01 (1.2627e+01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.075 ( 0.078)\tLoss 4.5022e+00 (6.5475e+00)\tAcc@1  96.88 ( 96.50)\tAcc@5 100.00 (100.00)\n","Epoch: [4][200/704]\tTime  0.076 ( 0.077)\tLoss 2.6025e+00 (5.9454e+00)\tAcc@1  98.44 ( 96.91)\tAcc@5 100.00 (100.00)\n","Epoch: [4][300/704]\tTime  0.073 ( 0.077)\tLoss 5.8764e+00 (5.4656e+00)\tAcc@1  95.31 ( 97.17)\tAcc@5 100.00 ( 99.99)\n","Epoch: [4][400/704]\tTime  0.076 ( 0.076)\tLoss 1.5187e+00 (5.5004e+00)\tAcc@1  98.44 ( 97.15)\tAcc@5 100.00 (100.00)\n","Epoch: [4][500/704]\tTime  0.076 ( 0.076)\tLoss 4.2642e-01 (5.3192e+00)\tAcc@1 100.00 ( 97.26)\tAcc@5 100.00 (100.00)\n","Epoch: [4][600/704]\tTime  0.076 ( 0.076)\tLoss 3.9580e+00 (5.2966e+00)\tAcc@1  96.88 ( 97.26)\tAcc@5 100.00 ( 99.99)\n","Epoch: [4][700/704]\tTime  0.073 ( 0.076)\tLoss 9.3757e+00 (5.3539e+00)\tAcc@1  95.31 ( 97.24)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 97.244 || Acc@5 99.989\n","==> Valid Accuracy:  Acc@1 93.980 || Acc@5 100.000\n","Epoch: [5][  0/704]\tTime  0.373 ( 0.373)\tLoss 4.2006e+00 (4.2006e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.075 ( 0.079)\tLoss 3.5821e+00 (3.6954e+00)\tAcc@1  98.44 ( 97.99)\tAcc@5 100.00 (100.00)\n","Epoch: [5][200/704]\tTime  0.077 ( 0.078)\tLoss 1.6676e+00 (3.0452e+00)\tAcc@1  98.44 ( 98.37)\tAcc@5 100.00 (100.00)\n","Epoch: [5][300/704]\tTime  0.074 ( 0.077)\tLoss 1.7141e+00 (2.7599e+00)\tAcc@1 100.00 ( 98.55)\tAcc@5 100.00 (100.00)\n","Epoch: [5][400/704]\tTime  0.079 ( 0.077)\tLoss 4.8682e+00 (2.5037e+00)\tAcc@1  96.88 ( 98.71)\tAcc@5 100.00 (100.00)\n","Epoch: [5][500/704]\tTime  0.076 ( 0.077)\tLoss 6.8663e-01 (2.3569e+00)\tAcc@1 100.00 ( 98.78)\tAcc@5 100.00 (100.00)\n","Epoch: [5][600/704]\tTime  0.077 ( 0.077)\tLoss 3.2791e-01 (2.2537e+00)\tAcc@1 100.00 ( 98.85)\tAcc@5 100.00 (100.00)\n","Epoch: [5][700/704]\tTime  0.071 ( 0.077)\tLoss 1.7584e+00 (2.1583e+00)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.898 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 97.520 || Acc@5 99.980\n","Epoch: [6][  0/704]\tTime  0.296 ( 0.296)\tLoss 1.4788e-01 (1.4788e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.075 ( 0.078)\tLoss 1.9968e-01 (1.2727e+00)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 ( 99.97)\n","Epoch: [6][200/704]\tTime  0.077 ( 0.078)\tLoss 4.0195e-01 (1.2675e+00)\tAcc@1 100.00 ( 99.51)\tAcc@5 100.00 ( 99.98)\n","Epoch: [6][300/704]\tTime  0.080 ( 0.077)\tLoss 5.4564e+00 (1.2091e+00)\tAcc@1  98.44 ( 99.52)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][400/704]\tTime  0.077 ( 0.077)\tLoss 4.1901e-01 (1.1550e+00)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][500/704]\tTime  0.076 ( 0.077)\tLoss 3.3931e+00 (1.1579e+00)\tAcc@1  98.44 ( 99.51)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][600/704]\tTime  0.076 ( 0.077)\tLoss 6.4221e-01 (1.1460e+00)\tAcc@1 100.00 ( 99.51)\tAcc@5 100.00 ( 99.99)\n","Epoch: [6][700/704]\tTime  0.073 ( 0.077)\tLoss 5.9135e-01 (1.0888e+00)\tAcc@1 100.00 ( 99.53)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.529 || Acc@5 99.996\n","==> Valid Accuracy:  Acc@1 97.520 || Acc@5 99.980\n","Epoch: [7][  0/704]\tTime  0.381 ( 0.381)\tLoss 1.4206e-01 (1.4206e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.074 ( 0.079)\tLoss 1.4716e-01 (5.0455e-01)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.076 ( 0.078)\tLoss 2.6729e+00 (5.6718e-01)\tAcc@1  98.44 ( 99.77)\tAcc@5 100.00 (100.00)\n","Epoch: [7][300/704]\tTime  0.076 ( 0.077)\tLoss 5.3178e-01 (5.6252e-01)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [7][400/704]\tTime  0.075 ( 0.077)\tLoss 2.2791e-01 (5.9888e-01)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.076 ( 0.077)\tLoss 1.3190e+00 (6.1171e-01)\tAcc@1  98.44 ( 99.75)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.076 ( 0.077)\tLoss 1.9335e-02 (5.9486e-01)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","Epoch: [7][700/704]\tTime  0.075 ( 0.077)\tLoss 6.1266e-01 (5.7665e-01)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.753 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 97.760 || Acc@5 100.000\n","Best Top-1 Accuracy for fold5: 97.76\n","\n","FOLD 6\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.309 ( 0.309)\tLoss 8.6706e-01 (8.6706e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.074 ( 0.079)\tLoss 1.2276e+01 (4.5316e+00)\tAcc@1  95.31 ( 97.56)\tAcc@5 100.00 (100.00)\n","Epoch: [0][200/704]\tTime  0.075 ( 0.078)\tLoss 3.1049e+00 (4.7591e+00)\tAcc@1  96.88 ( 97.46)\tAcc@5 100.00 (100.00)\n","Epoch: [0][300/704]\tTime  0.077 ( 0.077)\tLoss 8.9385e-01 (4.9076e+00)\tAcc@1 100.00 ( 97.39)\tAcc@5 100.00 (100.00)\n","Epoch: [0][400/704]\tTime  0.077 ( 0.077)\tLoss 6.4118e+00 (5.0755e+00)\tAcc@1  98.44 ( 97.31)\tAcc@5 100.00 (100.00)\n","Epoch: [0][500/704]\tTime  0.077 ( 0.077)\tLoss 6.8687e+00 (5.2427e+00)\tAcc@1  96.88 ( 97.20)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][600/704]\tTime  0.076 ( 0.077)\tLoss 4.9708e+00 (5.4823e+00)\tAcc@1  96.88 ( 97.12)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][700/704]\tTime  0.074 ( 0.077)\tLoss 2.1409e+00 (5.4983e+00)\tAcc@1 100.00 ( 97.09)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 97.098 || Acc@5 99.989\n","==> Valid Accuracy:  Acc@1 97.360 || Acc@5 100.000\n","Epoch: [1][  0/704]\tTime  0.358 ( 0.358)\tLoss 1.3837e+00 (1.3837e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.076 ( 0.079)\tLoss 7.8445e-01 (4.3565e+00)\tAcc@1 100.00 ( 97.83)\tAcc@5 100.00 ( 99.98)\n","Epoch: [1][200/704]\tTime  0.078 ( 0.078)\tLoss 8.7219e-01 (4.2737e+00)\tAcc@1 100.00 ( 97.88)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][300/704]\tTime  0.075 ( 0.078)\tLoss 7.6955e+00 (4.3157e+00)\tAcc@1  95.31 ( 97.79)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][400/704]\tTime  0.078 ( 0.077)\tLoss 2.4039e+00 (4.4552e+00)\tAcc@1  98.44 ( 97.76)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][500/704]\tTime  0.076 ( 0.077)\tLoss 8.4777e+00 (4.5556e+00)\tAcc@1  93.75 ( 97.63)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][600/704]\tTime  0.076 ( 0.077)\tLoss 9.7122e+00 (4.8981e+00)\tAcc@1  92.19 ( 97.43)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][700/704]\tTime  0.072 ( 0.077)\tLoss 3.7957e+00 (4.8682e+00)\tAcc@1  96.88 ( 97.44)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 97.436 || Acc@5 99.989\n","==> Valid Accuracy:  Acc@1 96.360 || Acc@5 99.980\n","Epoch: [2][  0/704]\tTime  0.271 ( 0.271)\tLoss 2.2678e+00 (2.2678e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.077 ( 0.079)\tLoss 3.0339e+00 (4.9703e+00)\tAcc@1  96.88 ( 97.34)\tAcc@5 100.00 (100.00)\n","Epoch: [2][200/704]\tTime  0.076 ( 0.077)\tLoss 8.7328e+00 (4.7197e+00)\tAcc@1  98.44 ( 97.42)\tAcc@5 100.00 (100.00)\n","Epoch: [2][300/704]\tTime  0.077 ( 0.077)\tLoss 8.5316e+00 (4.5221e+00)\tAcc@1  96.88 ( 97.54)\tAcc@5 100.00 (100.00)\n","Epoch: [2][400/704]\tTime  0.077 ( 0.077)\tLoss 5.6216e+00 (4.6528e+00)\tAcc@1  95.31 ( 97.40)\tAcc@5 100.00 (100.00)\n","Epoch: [2][500/704]\tTime  0.077 ( 0.077)\tLoss 8.4560e+00 (4.5794e+00)\tAcc@1  96.88 ( 97.46)\tAcc@5 100.00 (100.00)\n","Epoch: [2][600/704]\tTime  0.074 ( 0.077)\tLoss 1.2147e+01 (4.5050e+00)\tAcc@1  93.75 ( 97.54)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][700/704]\tTime  0.074 ( 0.076)\tLoss 5.0312e+00 (4.7243e+00)\tAcc@1  95.31 ( 97.45)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 97.456 || Acc@5 99.993\n","==> Valid Accuracy:  Acc@1 95.360 || Acc@5 99.980\n","Epoch: [3][  0/704]\tTime  0.367 ( 0.367)\tLoss 1.1082e+00 (1.1082e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.076 ( 0.079)\tLoss 4.3833e+00 (3.9817e+00)\tAcc@1  98.44 ( 97.85)\tAcc@5 100.00 (100.00)\n","Epoch: [3][200/704]\tTime  0.074 ( 0.078)\tLoss 4.0730e+00 (3.8264e+00)\tAcc@1  96.88 ( 97.86)\tAcc@5 100.00 (100.00)\n","Epoch: [3][300/704]\tTime  0.076 ( 0.077)\tLoss 8.4357e+00 (3.9070e+00)\tAcc@1  95.31 ( 97.84)\tAcc@5 100.00 (100.00)\n","Epoch: [3][400/704]\tTime  0.076 ( 0.077)\tLoss 6.3963e+00 (4.2063e+00)\tAcc@1  96.88 ( 97.72)\tAcc@5 100.00 (100.00)\n","Epoch: [3][500/704]\tTime  0.074 ( 0.077)\tLoss 4.3499e+00 (4.1950e+00)\tAcc@1  98.44 ( 97.69)\tAcc@5 100.00 (100.00)\n","Epoch: [3][600/704]\tTime  0.075 ( 0.077)\tLoss 8.2270e+00 (4.3725e+00)\tAcc@1  95.31 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [3][700/704]\tTime  0.073 ( 0.077)\tLoss 2.5208e+00 (4.4335e+00)\tAcc@1  98.44 ( 97.63)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 97.633 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 95.880 || Acc@5 100.000\n","Epoch: [4][  0/704]\tTime  0.285 ( 0.285)\tLoss 7.6967e+00 (7.6967e+00)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.078 ( 0.079)\tLoss 4.5677e+00 (3.0791e+00)\tAcc@1  96.88 ( 98.33)\tAcc@5 100.00 (100.00)\n","Epoch: [4][200/704]\tTime  0.077 ( 0.078)\tLoss 3.4905e+00 (3.4476e+00)\tAcc@1  96.88 ( 98.17)\tAcc@5 100.00 (100.00)\n","Epoch: [4][300/704]\tTime  0.075 ( 0.077)\tLoss 1.8276e+00 (3.4154e+00)\tAcc@1  98.44 ( 98.20)\tAcc@5 100.00 ( 99.99)\n","Epoch: [4][400/704]\tTime  0.075 ( 0.077)\tLoss 4.4092e-01 (3.4820e+00)\tAcc@1 100.00 ( 98.17)\tAcc@5 100.00 (100.00)\n","Epoch: [4][500/704]\tTime  0.078 ( 0.077)\tLoss 5.0957e+00 (3.5875e+00)\tAcc@1  96.88 ( 98.12)\tAcc@5 100.00 (100.00)\n","Epoch: [4][600/704]\tTime  0.078 ( 0.077)\tLoss 8.4343e+00 (3.6278e+00)\tAcc@1  93.75 ( 98.07)\tAcc@5 100.00 (100.00)\n","Epoch: [4][700/704]\tTime  0.075 ( 0.077)\tLoss 7.8546e-01 (3.8655e+00)\tAcc@1 100.00 ( 97.95)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 97.940 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 95.400 || Acc@5 99.980\n","Epoch: [5][  0/704]\tTime  0.278 ( 0.278)\tLoss 9.8668e-01 (9.8668e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.076 ( 0.079)\tLoss 2.8948e-01 (2.8887e+00)\tAcc@1 100.00 ( 98.53)\tAcc@5 100.00 (100.00)\n","Epoch: [5][200/704]\tTime  0.076 ( 0.077)\tLoss 1.2907e+00 (2.4087e+00)\tAcc@1 100.00 ( 98.80)\tAcc@5 100.00 (100.00)\n","Epoch: [5][300/704]\tTime  0.078 ( 0.077)\tLoss 6.2794e-01 (2.2856e+00)\tAcc@1 100.00 ( 98.81)\tAcc@5 100.00 (100.00)\n","Epoch: [5][400/704]\tTime  0.076 ( 0.077)\tLoss 3.0527e-01 (2.1263e+00)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 (100.00)\n","Epoch: [5][500/704]\tTime  0.078 ( 0.077)\tLoss 2.8297e-01 (1.9943e+00)\tAcc@1 100.00 ( 98.99)\tAcc@5 100.00 (100.00)\n","Epoch: [5][600/704]\tTime  0.077 ( 0.077)\tLoss 3.1096e-01 (1.8408e+00)\tAcc@1 100.00 ( 99.08)\tAcc@5 100.00 (100.00)\n","Epoch: [5][700/704]\tTime  0.073 ( 0.077)\tLoss 2.0306e-01 (1.7482e+00)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.116 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.320 || Acc@5 100.000\n","Epoch: [6][  0/704]\tTime  0.421 ( 0.421)\tLoss 4.5567e-01 (4.5567e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.078 ( 0.080)\tLoss 1.9832e-01 (8.1707e-01)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [6][200/704]\tTime  0.074 ( 0.079)\tLoss 4.2242e-01 (7.7651e-01)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [6][300/704]\tTime  0.078 ( 0.078)\tLoss 1.6789e+00 (7.8897e-01)\tAcc@1  98.44 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [6][400/704]\tTime  0.078 ( 0.077)\tLoss 1.6636e-01 (7.5284e-01)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [6][500/704]\tTime  0.076 ( 0.077)\tLoss 4.3283e-01 (7.4926e-01)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n","Epoch: [6][600/704]\tTime  0.075 ( 0.077)\tLoss 4.3198e-02 (7.0440e-01)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n","Epoch: [6][700/704]\tTime  0.074 ( 0.077)\tLoss 2.3367e-01 (6.8558e-01)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.693 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.600 || Acc@5 100.000\n","Epoch: [7][  0/704]\tTime  0.315 ( 0.315)\tLoss 1.5228e+00 (1.5228e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.079 ( 0.079)\tLoss 6.4131e-01 (4.8059e-01)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.077 ( 0.078)\tLoss 1.0710e-01 (4.7749e-01)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [7][300/704]\tTime  0.077 ( 0.077)\tLoss 5.6748e-01 (4.5206e-01)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n","Epoch: [7][400/704]\tTime  0.078 ( 0.077)\tLoss 6.6608e-02 (4.5225e-01)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.076 ( 0.077)\tLoss 1.0017e-01 (4.2556e-01)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.077 ( 0.077)\tLoss 5.3681e-02 (4.1291e-01)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n","Epoch: [7][700/704]\tTime  0.074 ( 0.077)\tLoss 1.5232e-01 (4.1961e-01)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.818 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.800 || Acc@5 100.000\n","Best Top-1 Accuracy for fold6: 98.8\n","\n","FOLD 7\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.403 ( 0.403)\tLoss 2.3147e-01 (2.3147e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.077 ( 0.080)\tLoss 6.2624e-01 (3.2455e+00)\tAcc@1 100.00 ( 98.24)\tAcc@5 100.00 ( 99.98)\n","Epoch: [0][200/704]\tTime  0.074 ( 0.078)\tLoss 1.0663e+00 (3.7355e+00)\tAcc@1 100.00 ( 97.97)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][300/704]\tTime  0.075 ( 0.077)\tLoss 4.4732e+00 (3.6523e+00)\tAcc@1  98.44 ( 98.07)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][400/704]\tTime  0.079 ( 0.077)\tLoss 6.0654e-01 (3.8676e+00)\tAcc@1 100.00 ( 98.00)\tAcc@5 100.00 (100.00)\n","Epoch: [0][500/704]\tTime  0.078 ( 0.077)\tLoss 2.5300e+00 (3.9398e+00)\tAcc@1 100.00 ( 97.92)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][600/704]\tTime  0.075 ( 0.077)\tLoss 1.0252e+01 (3.9429e+00)\tAcc@1  95.31 ( 97.91)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][700/704]\tTime  0.075 ( 0.077)\tLoss 1.3178e+00 (3.8960e+00)\tAcc@1 100.00 ( 97.92)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 97.913 || Acc@5 99.996\n","==> Valid Accuracy:  Acc@1 98.360 || Acc@5 99.980\n","Epoch: [1][  0/704]\tTime  0.267 ( 0.267)\tLoss 7.8430e+00 (7.8430e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.074 ( 0.078)\tLoss 1.0573e+00 (7.0441e+00)\tAcc@1 100.00 ( 96.70)\tAcc@5 100.00 ( 99.98)\n","Epoch: [1][200/704]\tTime  0.077 ( 0.078)\tLoss 6.4809e+00 (5.6941e+00)\tAcc@1  98.44 ( 97.20)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][300/704]\tTime  0.075 ( 0.077)\tLoss 9.0321e+00 (5.0467e+00)\tAcc@1  95.31 ( 97.50)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][400/704]\tTime  0.076 ( 0.077)\tLoss 2.3401e+00 (5.5347e+00)\tAcc@1 100.00 ( 97.21)\tAcc@5 100.00 ( 99.98)\n","Epoch: [1][500/704]\tTime  0.074 ( 0.077)\tLoss 4.7476e+00 (5.2103e+00)\tAcc@1  98.44 ( 97.34)\tAcc@5 100.00 ( 99.98)\n","Epoch: [1][600/704]\tTime  0.076 ( 0.077)\tLoss 9.4983e+00 (5.2330e+00)\tAcc@1  95.31 ( 97.37)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][700/704]\tTime  0.073 ( 0.077)\tLoss 9.8129e+00 (5.1284e+00)\tAcc@1  93.75 ( 97.43)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 97.431 || Acc@5 99.987\n","==> Valid Accuracy:  Acc@1 98.540 || Acc@5 100.000\n","Epoch: [2][  0/704]\tTime  0.396 ( 0.396)\tLoss 7.2938e-01 (7.2938e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.071 ( 0.080)\tLoss 3.0915e+00 (2.1286e+00)\tAcc@1  98.44 ( 98.86)\tAcc@5 100.00 (100.00)\n","Epoch: [2][200/704]\tTime  0.075 ( 0.078)\tLoss 2.8455e+00 (2.3491e+00)\tAcc@1  98.44 ( 98.76)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][300/704]\tTime  0.078 ( 0.078)\tLoss 3.3868e-01 (2.5936e+00)\tAcc@1 100.00 ( 98.61)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][400/704]\tTime  0.076 ( 0.077)\tLoss 2.0874e+00 (2.8067e+00)\tAcc@1 100.00 ( 98.50)\tAcc@5 100.00 (100.00)\n","Epoch: [2][500/704]\tTime  0.076 ( 0.077)\tLoss 8.1960e-01 (2.8186e+00)\tAcc@1 100.00 ( 98.50)\tAcc@5 100.00 (100.00)\n","Epoch: [2][600/704]\tTime  0.081 ( 0.077)\tLoss 2.8761e+00 (2.8940e+00)\tAcc@1  95.31 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [2][700/704]\tTime  0.075 ( 0.077)\tLoss 3.9359e+00 (2.9739e+00)\tAcc@1  96.88 ( 98.38)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.371 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 97.760 || Acc@5 99.980\n","Epoch: [3][  0/704]\tTime  0.263 ( 0.263)\tLoss 4.5347e+00 (4.5347e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.077 ( 0.078)\tLoss 1.9666e+00 (3.0298e+00)\tAcc@1 100.00 ( 98.22)\tAcc@5 100.00 (100.00)\n","Epoch: [3][200/704]\tTime  0.076 ( 0.077)\tLoss 5.2359e-01 (2.8922e+00)\tAcc@1 100.00 ( 98.31)\tAcc@5 100.00 (100.00)\n","Epoch: [3][300/704]\tTime  0.075 ( 0.077)\tLoss 3.8044e-01 (2.7323e+00)\tAcc@1 100.00 ( 98.40)\tAcc@5 100.00 (100.00)\n","Epoch: [3][400/704]\tTime  0.075 ( 0.077)\tLoss 9.3261e-01 (3.1409e+00)\tAcc@1 100.00 ( 98.20)\tAcc@5 100.00 (100.00)\n","Epoch: [3][500/704]\tTime  0.075 ( 0.076)\tLoss 7.2170e+00 (3.4115e+00)\tAcc@1  96.88 ( 98.15)\tAcc@5 100.00 (100.00)\n","Epoch: [3][600/704]\tTime  0.076 ( 0.076)\tLoss 1.6916e+00 (3.7170e+00)\tAcc@1  98.44 ( 97.99)\tAcc@5 100.00 (100.00)\n","Epoch: [3][700/704]\tTime  0.073 ( 0.076)\tLoss 5.1565e+00 (3.6623e+00)\tAcc@1  96.88 ( 98.00)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.000 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 97.500 || Acc@5 100.000\n","Epoch: [4][  0/704]\tTime  0.362 ( 0.362)\tLoss 2.2259e+00 (2.2259e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.077 ( 0.079)\tLoss 3.1608e+00 (3.5143e+00)\tAcc@1  98.44 ( 98.22)\tAcc@5 100.00 ( 99.98)\n","Epoch: [4][200/704]\tTime  0.076 ( 0.077)\tLoss 5.8698e+01 (7.1184e+00)\tAcc@1  95.31 ( 96.49)\tAcc@5 100.00 ( 99.98)\n","Epoch: [4][300/704]\tTime  0.076 ( 0.077)\tLoss 8.8496e+00 (1.1581e+01)\tAcc@1  95.31 ( 94.63)\tAcc@5 100.00 ( 99.92)\n","Epoch: [4][400/704]\tTime  0.075 ( 0.077)\tLoss 4.3361e+00 (1.0769e+01)\tAcc@1  96.88 ( 94.81)\tAcc@5 100.00 ( 99.94)\n","Epoch: [4][500/704]\tTime  0.076 ( 0.077)\tLoss 2.6690e+00 (9.7619e+00)\tAcc@1  98.44 ( 95.26)\tAcc@5 100.00 ( 99.95)\n","Epoch: [4][600/704]\tTime  0.076 ( 0.077)\tLoss 4.0225e+00 (8.9777e+00)\tAcc@1  96.88 ( 95.61)\tAcc@5 100.00 ( 99.96)\n","Epoch: [4][700/704]\tTime  0.074 ( 0.077)\tLoss 5.8931e+00 (8.2643e+00)\tAcc@1  96.88 ( 95.97)\tAcc@5 100.00 ( 99.96)\n","==> Train Accuracy: Acc@1 95.976 || Acc@5 99.962\n","==> Valid Accuracy:  Acc@1 97.340 || Acc@5 100.000\n","Epoch: [5][  0/704]\tTime  0.282 ( 0.282)\tLoss 4.6792e-01 (4.6792e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.075 ( 0.078)\tLoss 2.3952e+00 (1.9502e+00)\tAcc@1  98.44 ( 98.93)\tAcc@5 100.00 (100.00)\n","Epoch: [5][200/704]\tTime  0.075 ( 0.077)\tLoss 2.5093e-01 (1.9617e+00)\tAcc@1 100.00 ( 98.86)\tAcc@5 100.00 (100.00)\n","Epoch: [5][300/704]\tTime  0.073 ( 0.077)\tLoss 1.4638e+00 (1.8972e+00)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 (100.00)\n","Epoch: [5][400/704]\tTime  0.078 ( 0.077)\tLoss 6.6417e-01 (1.8838e+00)\tAcc@1 100.00 ( 98.97)\tAcc@5 100.00 (100.00)\n","Epoch: [5][500/704]\tTime  0.077 ( 0.077)\tLoss 4.4278e+00 (1.7585e+00)\tAcc@1  96.88 ( 99.05)\tAcc@5 100.00 (100.00)\n","Epoch: [5][600/704]\tTime  0.078 ( 0.077)\tLoss 1.6225e-01 (1.7132e+00)\tAcc@1 100.00 ( 99.08)\tAcc@5 100.00 (100.00)\n","Epoch: [5][700/704]\tTime  0.075 ( 0.076)\tLoss 1.9461e-01 (1.7052e+00)\tAcc@1 100.00 ( 99.10)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.100 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.160 || Acc@5 100.000\n","Epoch: [6][  0/704]\tTime  0.280 ( 0.280)\tLoss 1.3011e+00 (1.3011e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.074 ( 0.078)\tLoss 3.5957e-01 (8.8301e-01)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n","Epoch: [6][200/704]\tTime  0.077 ( 0.077)\tLoss 1.6540e-01 (8.5310e-01)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [6][300/704]\tTime  0.077 ( 0.077)\tLoss 1.6640e+00 (8.5778e-01)\tAcc@1  98.44 ( 99.61)\tAcc@5 100.00 (100.00)\n","Epoch: [6][400/704]\tTime  0.077 ( 0.077)\tLoss 7.2448e-02 (8.1269e-01)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n","Epoch: [6][500/704]\tTime  0.075 ( 0.077)\tLoss 2.4198e-01 (8.0486e-01)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","Epoch: [6][600/704]\tTime  0.076 ( 0.077)\tLoss 2.9399e-01 (7.9713e-01)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n","Epoch: [6][700/704]\tTime  0.074 ( 0.077)\tLoss 6.2486e-01 (7.7480e-01)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.651 || Acc@5 99.996\n","==> Valid Accuracy:  Acc@1 98.320 || Acc@5 100.000\n","Epoch: [7][  0/704]\tTime  0.381 ( 0.381)\tLoss 8.0435e-01 (8.0435e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.076 ( 0.079)\tLoss 1.5934e-01 (5.1725e-01)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.075 ( 0.078)\tLoss 3.4526e-01 (5.6472e-01)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n","Epoch: [7][300/704]\tTime  0.075 ( 0.077)\tLoss 1.5362e+00 (5.4871e-01)\tAcc@1  98.44 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [7][400/704]\tTime  0.076 ( 0.077)\tLoss 1.8872e-01 (5.0437e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.077 ( 0.077)\tLoss 9.4355e-02 (5.3801e-01)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.075 ( 0.077)\tLoss 2.4540e-01 (5.0763e-01)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n","Epoch: [7][700/704]\tTime  0.074 ( 0.077)\tLoss 3.2602e+00 (5.1458e-01)\tAcc@1  98.44 ( 99.80)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.802 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.720 || Acc@5 100.000\n","Best Top-1 Accuracy for fold7: 98.72\n","\n","FOLD 8\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.294 ( 0.294)\tLoss 2.1895e+00 (2.1895e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.077 ( 0.078)\tLoss 5.3444e+00 (3.2604e+00)\tAcc@1  98.44 ( 98.24)\tAcc@5 100.00 (100.00)\n","Epoch: [0][200/704]\tTime  0.077 ( 0.078)\tLoss 1.2203e+00 (3.4914e+00)\tAcc@1 100.00 ( 98.31)\tAcc@5 100.00 (100.00)\n","Epoch: [0][300/704]\tTime  0.075 ( 0.077)\tLoss 7.0692e-01 (3.5485e+00)\tAcc@1 100.00 ( 98.24)\tAcc@5 100.00 (100.00)\n","Epoch: [0][400/704]\tTime  0.075 ( 0.077)\tLoss 5.1505e-01 (3.5466e+00)\tAcc@1 100.00 ( 98.22)\tAcc@5 100.00 (100.00)\n","Epoch: [0][500/704]\tTime  0.075 ( 0.077)\tLoss 2.7484e+00 (3.5799e+00)\tAcc@1  98.44 ( 98.18)\tAcc@5 100.00 (100.00)\n","Epoch: [0][600/704]\tTime  0.075 ( 0.077)\tLoss 4.9262e+00 (3.5997e+00)\tAcc@1  98.44 ( 98.14)\tAcc@5 100.00 (100.00)\n","Epoch: [0][700/704]\tTime  0.074 ( 0.077)\tLoss 1.4748e+00 (3.6247e+00)\tAcc@1  98.44 ( 98.11)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.098 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 97.000 || Acc@5 100.000\n","Epoch: [1][  0/704]\tTime  0.360 ( 0.360)\tLoss 4.2275e+00 (4.2275e+00)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.075 ( 0.080)\tLoss 4.9710e+00 (3.3537e+00)\tAcc@1  96.88 ( 98.27)\tAcc@5 100.00 (100.00)\n","Epoch: [1][200/704]\tTime  0.076 ( 0.078)\tLoss 9.3508e-01 (3.4768e+00)\tAcc@1 100.00 ( 98.15)\tAcc@5 100.00 (100.00)\n","Epoch: [1][300/704]\tTime  0.076 ( 0.078)\tLoss 2.3622e+00 (3.4711e+00)\tAcc@1  98.44 ( 98.23)\tAcc@5 100.00 (100.00)\n","Epoch: [1][400/704]\tTime  0.075 ( 0.077)\tLoss 3.7461e+00 (4.6238e+00)\tAcc@1  96.88 ( 97.68)\tAcc@5 100.00 (100.00)\n","Epoch: [1][500/704]\tTime  0.075 ( 0.077)\tLoss 2.4727e+00 (4.5715e+00)\tAcc@1  98.44 ( 97.66)\tAcc@5 100.00 (100.00)\n","Epoch: [1][600/704]\tTime  0.075 ( 0.077)\tLoss 1.8305e+00 (4.7195e+00)\tAcc@1 100.00 ( 97.60)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][700/704]\tTime  0.073 ( 0.077)\tLoss 1.2429e+00 (4.5693e+00)\tAcc@1 100.00 ( 97.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 97.673 || Acc@5 99.996\n","==> Valid Accuracy:  Acc@1 98.420 || Acc@5 100.000\n","Epoch: [2][  0/704]\tTime  0.304 ( 0.304)\tLoss 2.8173e+00 (2.8173e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.075 ( 0.079)\tLoss 9.3029e-02 (2.0024e+00)\tAcc@1 100.00 ( 98.79)\tAcc@5 100.00 (100.00)\n","Epoch: [2][200/704]\tTime  0.078 ( 0.089)\tLoss 6.0044e-01 (2.3323e+00)\tAcc@1 100.00 ( 98.62)\tAcc@5 100.00 (100.00)\n","Epoch: [2][300/704]\tTime  0.080 ( 0.085)\tLoss 3.4083e-01 (2.3095e+00)\tAcc@1 100.00 ( 98.69)\tAcc@5 100.00 (100.00)\n","Epoch: [2][400/704]\tTime  0.077 ( 0.083)\tLoss 2.0592e+00 (2.4580e+00)\tAcc@1  98.44 ( 98.63)\tAcc@5 100.00 (100.00)\n","Epoch: [2][500/704]\tTime  0.078 ( 0.082)\tLoss 2.3597e+00 (2.5000e+00)\tAcc@1  98.44 ( 98.61)\tAcc@5 100.00 (100.00)\n","Epoch: [2][600/704]\tTime  0.076 ( 0.081)\tLoss 1.1567e+00 (2.5454e+00)\tAcc@1 100.00 ( 98.58)\tAcc@5 100.00 (100.00)\n","Epoch: [2][700/704]\tTime  0.074 ( 0.080)\tLoss 7.1643e-01 (2.6100e+00)\tAcc@1 100.00 ( 98.54)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.542 || Acc@5 99.996\n","==> Valid Accuracy:  Acc@1 97.960 || Acc@5 100.000\n","Epoch: [3][  0/704]\tTime  0.361 ( 0.361)\tLoss 1.3363e+00 (1.3363e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.075 ( 0.083)\tLoss 4.9198e+00 (2.1020e+00)\tAcc@1  96.88 ( 98.81)\tAcc@5 100.00 (100.00)\n","Epoch: [3][200/704]\tTime  0.079 ( 0.080)\tLoss 8.3415e-01 (2.0759e+00)\tAcc@1 100.00 ( 98.83)\tAcc@5 100.00 (100.00)\n","Epoch: [3][300/704]\tTime  0.080 ( 0.078)\tLoss 1.7492e+00 (2.4488e+00)\tAcc@1  98.44 ( 98.69)\tAcc@5 100.00 (100.00)\n","Epoch: [3][400/704]\tTime  0.078 ( 0.078)\tLoss 4.2668e-01 (2.7161e+00)\tAcc@1 100.00 ( 98.51)\tAcc@5 100.00 (100.00)\n","Epoch: [3][500/704]\tTime  0.075 ( 0.078)\tLoss 1.7676e+00 (2.7712e+00)\tAcc@1 100.00 ( 98.45)\tAcc@5 100.00 (100.00)\n","Epoch: [3][600/704]\tTime  0.076 ( 0.077)\tLoss 8.3466e+00 (2.8563e+00)\tAcc@1  96.88 ( 98.41)\tAcc@5 100.00 (100.00)\n","Epoch: [3][700/704]\tTime  0.075 ( 0.077)\tLoss 4.4126e+00 (2.8352e+00)\tAcc@1  96.88 ( 98.44)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.429 || Acc@5 99.996\n","==> Valid Accuracy:  Acc@1 95.420 || Acc@5 99.940\n","Epoch: [4][  0/704]\tTime  0.262 ( 0.262)\tLoss 5.8348e-01 (5.8348e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.078 ( 0.078)\tLoss 5.9607e+00 (3.1513e+00)\tAcc@1  95.31 ( 98.17)\tAcc@5 100.00 (100.00)\n","Epoch: [4][200/704]\tTime  0.075 ( 0.077)\tLoss 1.4903e+00 (2.8621e+00)\tAcc@1  98.44 ( 98.39)\tAcc@5 100.00 (100.00)\n","Epoch: [4][300/704]\tTime  0.076 ( 0.077)\tLoss 6.3502e-01 (2.8881e+00)\tAcc@1 100.00 ( 98.42)\tAcc@5 100.00 (100.00)\n","Epoch: [4][400/704]\tTime  0.076 ( 0.077)\tLoss 1.5767e-01 (2.7969e+00)\tAcc@1 100.00 ( 98.47)\tAcc@5 100.00 (100.00)\n","Epoch: [4][500/704]\tTime  0.077 ( 0.077)\tLoss 6.0264e+00 (3.2709e+00)\tAcc@1  96.88 ( 98.33)\tAcc@5 100.00 (100.00)\n","Epoch: [4][600/704]\tTime  0.076 ( 0.077)\tLoss 1.1115e+00 (3.3492e+00)\tAcc@1 100.00 ( 98.26)\tAcc@5 100.00 (100.00)\n","Epoch: [4][700/704]\tTime  0.074 ( 0.077)\tLoss 1.0787e+00 (3.2562e+00)\tAcc@1 100.00 ( 98.31)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.316 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.160 || Acc@5 100.000\n","Epoch: [5][  0/704]\tTime  0.391 ( 0.391)\tLoss 3.4607e-01 (3.4607e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.078 ( 0.080)\tLoss 3.5691e-01 (1.7523e+00)\tAcc@1 100.00 ( 99.13)\tAcc@5 100.00 (100.00)\n","Epoch: [5][200/704]\tTime  0.076 ( 0.078)\tLoss 3.3726e-01 (1.4220e+00)\tAcc@1 100.00 ( 99.32)\tAcc@5 100.00 (100.00)\n","Epoch: [5][300/704]\tTime  0.075 ( 0.078)\tLoss 3.8434e-01 (1.2980e+00)\tAcc@1 100.00 ( 99.37)\tAcc@5 100.00 (100.00)\n","Epoch: [5][400/704]\tTime  0.075 ( 0.077)\tLoss 1.0450e+00 (1.1844e+00)\tAcc@1  98.44 ( 99.41)\tAcc@5 100.00 (100.00)\n","Epoch: [5][500/704]\tTime  0.080 ( 0.077)\tLoss 3.7890e-01 (1.1183e+00)\tAcc@1 100.00 ( 99.44)\tAcc@5 100.00 (100.00)\n","Epoch: [5][600/704]\tTime  0.075 ( 0.077)\tLoss 1.2049e-01 (1.1150e+00)\tAcc@1 100.00 ( 99.47)\tAcc@5 100.00 (100.00)\n","Epoch: [5][700/704]\tTime  0.074 ( 0.077)\tLoss 8.7755e-01 (1.0580e+00)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.496 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.060 || Acc@5 100.000\n","Epoch: [6][  0/704]\tTime  0.293 ( 0.293)\tLoss 5.1926e-01 (5.1926e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.075 ( 0.078)\tLoss 6.1317e-01 (4.4613e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [6][200/704]\tTime  0.078 ( 0.078)\tLoss 1.7889e-01 (4.7961e-01)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n","Epoch: [6][300/704]\tTime  0.077 ( 0.077)\tLoss 3.6590e-01 (4.7552e-01)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n","Epoch: [6][400/704]\tTime  0.080 ( 0.077)\tLoss 1.0872e-01 (4.5826e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [6][500/704]\tTime  0.076 ( 0.077)\tLoss 1.2072e-01 (4.4307e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [6][600/704]\tTime  0.075 ( 0.077)\tLoss 9.7471e-02 (4.2934e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [6][700/704]\tTime  0.076 ( 0.077)\tLoss 1.2074e-01 (4.2541e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.827 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.280 || Acc@5 100.000\n","Epoch: [7][  0/704]\tTime  0.301 ( 0.301)\tLoss 3.5824e-02 (3.5824e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.075 ( 0.079)\tLoss 5.8217e-02 (3.0888e-01)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.076 ( 0.078)\tLoss 3.4378e-01 (2.9021e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][300/704]\tTime  0.078 ( 0.077)\tLoss 9.4356e-02 (2.9144e-01)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n","Epoch: [7][400/704]\tTime  0.079 ( 0.077)\tLoss 2.5021e-02 (2.9031e-01)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.076 ( 0.077)\tLoss 1.8579e-02 (2.9242e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.077 ( 0.077)\tLoss 5.3775e-02 (2.8035e-01)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n","Epoch: [7][700/704]\tTime  0.074 ( 0.077)\tLoss 1.5620e-01 (2.6915e-01)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.904 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.240 || Acc@5 100.000\n","Best Top-1 Accuracy for fold8: 99.28\n","\n","FOLD 9\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.380 ( 0.380)\tLoss 5.1940e-02 (5.1940e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.077 ( 0.079)\tLoss 1.2088e+00 (2.1288e+00)\tAcc@1 100.00 ( 98.82)\tAcc@5 100.00 (100.00)\n","Epoch: [0][200/704]\tTime  0.075 ( 0.078)\tLoss 3.2190e+01 (2.4106e+00)\tAcc@1  92.19 ( 98.80)\tAcc@5 100.00 (100.00)\n","Epoch: [0][300/704]\tTime  0.076 ( 0.077)\tLoss 8.9630e-01 (2.6898e+00)\tAcc@1 100.00 ( 98.61)\tAcc@5 100.00 ( 99.99)\n","Epoch: [0][400/704]\tTime  0.076 ( 0.077)\tLoss 3.2366e-01 (2.7228e+00)\tAcc@1 100.00 ( 98.59)\tAcc@5 100.00 (100.00)\n","Epoch: [0][500/704]\tTime  0.083 ( 0.077)\tLoss 1.5977e+00 (2.7640e+00)\tAcc@1 100.00 ( 98.57)\tAcc@5 100.00 (100.00)\n","Epoch: [0][600/704]\tTime  0.076 ( 0.077)\tLoss 4.9956e+00 (2.7131e+00)\tAcc@1  96.88 ( 98.58)\tAcc@5 100.00 (100.00)\n","Epoch: [0][700/704]\tTime  0.073 ( 0.077)\tLoss 2.0404e+00 (2.7809e+00)\tAcc@1  98.44 ( 98.52)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.524 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 98.760 || Acc@5 100.000\n","Epoch: [1][  0/704]\tTime  0.254 ( 0.254)\tLoss 4.2047e-01 (4.2047e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.076 ( 0.078)\tLoss 4.7218e+00 (2.3251e+00)\tAcc@1  98.44 ( 98.82)\tAcc@5 100.00 (100.00)\n","Epoch: [1][200/704]\tTime  0.076 ( 0.078)\tLoss 1.2689e+00 (3.5230e+00)\tAcc@1 100.00 ( 98.17)\tAcc@5 100.00 (100.00)\n","Epoch: [1][300/704]\tTime  0.075 ( 0.077)\tLoss 5.8944e-01 (3.2762e+00)\tAcc@1 100.00 ( 98.31)\tAcc@5 100.00 (100.00)\n","Epoch: [1][400/704]\tTime  0.075 ( 0.077)\tLoss 4.1631e-01 (3.2739e+00)\tAcc@1 100.00 ( 98.34)\tAcc@5 100.00 (100.00)\n","Epoch: [1][500/704]\tTime  0.076 ( 0.077)\tLoss 1.0750e+01 (3.3991e+00)\tAcc@1  93.75 ( 98.33)\tAcc@5 100.00 (100.00)\n","Epoch: [1][600/704]\tTime  0.078 ( 0.077)\tLoss 1.2260e+00 (3.7045e+00)\tAcc@1 100.00 ( 98.17)\tAcc@5 100.00 (100.00)\n","Epoch: [1][700/704]\tTime  0.074 ( 0.077)\tLoss 7.5698e+00 (3.7042e+00)\tAcc@1  98.44 ( 98.15)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.151 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 98.440 || Acc@5 100.000\n","Epoch: [2][  0/704]\tTime  0.387 ( 0.387)\tLoss 1.0153e+00 (1.0153e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.078 ( 0.080)\tLoss 5.9766e+00 (2.2361e+00)\tAcc@1  96.88 ( 98.86)\tAcc@5 100.00 ( 99.98)\n","Epoch: [2][200/704]\tTime  0.075 ( 0.078)\tLoss 1.5391e+00 (2.0940e+00)\tAcc@1  98.44 ( 98.87)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][300/704]\tTime  0.079 ( 0.078)\tLoss 2.9579e+00 (2.0408e+00)\tAcc@1  98.44 ( 98.87)\tAcc@5 100.00 ( 99.99)\n","Epoch: [2][400/704]\tTime  0.077 ( 0.078)\tLoss 2.8918e+00 (2.0826e+00)\tAcc@1  98.44 ( 98.89)\tAcc@5 100.00 (100.00)\n","Epoch: [2][500/704]\tTime  0.076 ( 0.078)\tLoss 1.0430e+01 (2.2391e+00)\tAcc@1  98.44 ( 98.80)\tAcc@5 100.00 (100.00)\n","Epoch: [2][600/704]\tTime  0.076 ( 0.077)\tLoss 4.5967e-01 (2.1569e+00)\tAcc@1 100.00 ( 98.84)\tAcc@5 100.00 (100.00)\n","Epoch: [2][700/704]\tTime  0.074 ( 0.077)\tLoss 1.4045e+00 (2.4818e+00)\tAcc@1  98.44 ( 98.67)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.669 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 95.940 || Acc@5 100.000\n","Epoch: [3][  0/704]\tTime  0.291 ( 0.291)\tLoss 1.3552e+00 (1.3552e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.079 ( 0.079)\tLoss 1.2234e+00 (2.5441e+00)\tAcc@1 100.00 ( 98.56)\tAcc@5 100.00 (100.00)\n","Epoch: [3][200/704]\tTime  0.076 ( 0.078)\tLoss 3.4526e+00 (2.4057e+00)\tAcc@1  98.44 ( 98.69)\tAcc@5 100.00 (100.00)\n","Epoch: [3][300/704]\tTime  0.078 ( 0.077)\tLoss 3.2524e+00 (2.5310e+00)\tAcc@1  96.88 ( 98.62)\tAcc@5 100.00 (100.00)\n","Epoch: [3][400/704]\tTime  0.076 ( 0.077)\tLoss 1.3264e+00 (2.3950e+00)\tAcc@1  98.44 ( 98.73)\tAcc@5 100.00 (100.00)\n","Epoch: [3][500/704]\tTime  0.077 ( 0.077)\tLoss 8.8509e+00 (2.4328e+00)\tAcc@1  95.31 ( 98.73)\tAcc@5 100.00 (100.00)\n","Epoch: [3][600/704]\tTime  0.078 ( 0.077)\tLoss 1.1245e+00 (2.4847e+00)\tAcc@1  98.44 ( 98.68)\tAcc@5 100.00 (100.00)\n","Epoch: [3][700/704]\tTime  0.074 ( 0.077)\tLoss 4.3520e-01 (2.4949e+00)\tAcc@1 100.00 ( 98.68)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.680 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.620 || Acc@5 100.000\n","Epoch: [4][  0/704]\tTime  0.384 ( 0.384)\tLoss 5.1203e-01 (5.1203e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.075 ( 0.080)\tLoss 1.1965e+00 (1.6207e+00)\tAcc@1  98.44 ( 99.04)\tAcc@5 100.00 (100.00)\n","Epoch: [4][200/704]\tTime  0.076 ( 0.078)\tLoss 1.4896e+00 (1.7938e+00)\tAcc@1  98.44 ( 98.99)\tAcc@5 100.00 (100.00)\n","Epoch: [4][300/704]\tTime  0.077 ( 0.078)\tLoss 3.3365e+00 (1.8107e+00)\tAcc@1  96.88 ( 99.00)\tAcc@5 100.00 (100.00)\n","Epoch: [4][400/704]\tTime  0.079 ( 0.077)\tLoss 9.1750e-01 (2.0551e+00)\tAcc@1  98.44 ( 98.90)\tAcc@5 100.00 (100.00)\n","Epoch: [4][500/704]\tTime  0.078 ( 0.077)\tLoss 4.5356e+00 (2.0340e+00)\tAcc@1  93.75 ( 98.89)\tAcc@5 100.00 (100.00)\n","Epoch: [4][600/704]\tTime  0.077 ( 0.077)\tLoss 2.5770e-01 (2.0654e+00)\tAcc@1 100.00 ( 98.87)\tAcc@5 100.00 (100.00)\n","Epoch: [4][700/704]\tTime  0.072 ( 0.077)\tLoss 6.7010e+00 (2.1831e+00)\tAcc@1  96.88 ( 98.80)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.800 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 97.360 || Acc@5 100.000\n","Epoch: [5][  0/704]\tTime  0.266 ( 0.266)\tLoss 1.4471e+00 (1.4471e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.076 ( 0.078)\tLoss 1.3815e+00 (1.6723e+00)\tAcc@1  98.44 ( 99.07)\tAcc@5 100.00 (100.00)\n","Epoch: [5][200/704]\tTime  0.076 ( 0.077)\tLoss 1.8518e-01 (1.5237e+00)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 (100.00)\n","Epoch: [5][300/704]\tTime  0.075 ( 0.077)\tLoss 9.8608e-01 (1.3438e+00)\tAcc@1  98.44 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [5][400/704]\tTime  0.075 ( 0.077)\tLoss 5.9271e-01 (1.3124e+00)\tAcc@1 100.00 ( 99.28)\tAcc@5 100.00 (100.00)\n","Epoch: [5][500/704]\tTime  0.076 ( 0.077)\tLoss 3.0517e-01 (1.2374e+00)\tAcc@1 100.00 ( 99.35)\tAcc@5 100.00 (100.00)\n","Epoch: [5][600/704]\tTime  0.079 ( 0.077)\tLoss 1.7211e-01 (1.1451e+00)\tAcc@1 100.00 ( 99.39)\tAcc@5 100.00 (100.00)\n","Epoch: [5][700/704]\tTime  0.073 ( 0.077)\tLoss 2.8098e+00 (1.0947e+00)\tAcc@1  98.44 ( 99.43)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.431 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 99.160 || Acc@5 100.000\n","Epoch: [6][  0/704]\tTime  0.386 ( 0.386)\tLoss 3.9754e-01 (3.9754e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.077 ( 0.079)\tLoss 1.8545e-01 (4.2432e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [6][200/704]\tTime  0.077 ( 0.078)\tLoss 7.7439e-01 (3.7066e-01)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n","Epoch: [6][300/704]\tTime  0.076 ( 0.077)\tLoss 1.7920e-01 (3.6503e-01)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n","Epoch: [6][400/704]\tTime  0.076 ( 0.077)\tLoss 3.5152e-01 (3.7540e-01)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n","Epoch: [6][500/704]\tTime  0.075 ( 0.077)\tLoss 1.3937e-02 (3.9218e-01)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n","Epoch: [6][600/704]\tTime  0.075 ( 0.077)\tLoss 2.6512e-01 (3.9265e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [6][700/704]\tTime  0.074 ( 0.077)\tLoss 1.3718e-02 (3.8423e-01)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.836 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.340 || Acc@5 100.000\n","Epoch: [7][  0/704]\tTime  0.308 ( 0.308)\tLoss 2.4108e-01 (2.4108e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.076 ( 0.079)\tLoss 6.0254e-02 (1.9567e-01)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.077 ( 0.078)\tLoss 1.2074e-01 (2.1691e-01)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n","Epoch: [7][300/704]\tTime  0.075 ( 0.077)\tLoss 2.9511e-01 (2.6118e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][400/704]\tTime  0.076 ( 0.077)\tLoss 3.0321e-02 (2.5661e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.075 ( 0.077)\tLoss 3.1680e-02 (2.5494e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.079 ( 0.077)\tLoss 5.3911e-01 (2.4807e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][700/704]\tTime  0.074 ( 0.077)\tLoss 4.0981e-01 (2.3930e-01)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.898 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.300 || Acc@5 100.000\n","Best Top-1 Accuracy for fold9: 99.34\n","\n","FOLD 10\n","--------------------------------\n","Epoch: [0][  0/704]\tTime  0.371 ( 0.371)\tLoss 3.6885e-02 (3.6885e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [0][100/704]\tTime  0.077 ( 0.079)\tLoss 6.7326e-01 (1.7042e+00)\tAcc@1 100.00 ( 99.06)\tAcc@5 100.00 (100.00)\n","Epoch: [0][200/704]\tTime  0.075 ( 0.078)\tLoss 3.6280e-01 (2.1944e+00)\tAcc@1 100.00 ( 98.81)\tAcc@5 100.00 (100.00)\n","Epoch: [0][300/704]\tTime  0.079 ( 0.077)\tLoss 4.5247e-01 (2.1234e+00)\tAcc@1 100.00 ( 98.83)\tAcc@5 100.00 (100.00)\n","Epoch: [0][400/704]\tTime  0.076 ( 0.077)\tLoss 2.5279e+00 (2.1559e+00)\tAcc@1  96.88 ( 98.83)\tAcc@5 100.00 (100.00)\n","Epoch: [0][500/704]\tTime  0.076 ( 0.077)\tLoss 3.5850e+00 (2.1813e+00)\tAcc@1  98.44 ( 98.84)\tAcc@5 100.00 (100.00)\n","Epoch: [0][600/704]\tTime  0.076 ( 0.077)\tLoss 2.4847e+00 (2.2182e+00)\tAcc@1  98.44 ( 98.79)\tAcc@5 100.00 (100.00)\n","Epoch: [0][700/704]\tTime  0.074 ( 0.077)\tLoss 1.0860e+00 (2.3382e+00)\tAcc@1 100.00 ( 98.71)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.700 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.920 || Acc@5 100.000\n","Epoch: [1][  0/704]\tTime  0.369 ( 0.369)\tLoss 9.6282e+00 (9.6282e+00)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [1][100/704]\tTime  0.077 ( 0.079)\tLoss 2.1646e+00 (3.7192e+00)\tAcc@1  98.44 ( 98.22)\tAcc@5 100.00 (100.00)\n","Epoch: [1][200/704]\tTime  0.077 ( 0.078)\tLoss 5.6454e-01 (3.0746e+00)\tAcc@1 100.00 ( 98.41)\tAcc@5 100.00 (100.00)\n","Epoch: [1][300/704]\tTime  0.077 ( 0.077)\tLoss 5.7419e-02 (2.8167e+00)\tAcc@1 100.00 ( 98.52)\tAcc@5 100.00 (100.00)\n","Epoch: [1][400/704]\tTime  0.075 ( 0.077)\tLoss 2.5862e+01 (4.1824e+00)\tAcc@1  93.75 ( 98.11)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][500/704]\tTime  0.078 ( 0.077)\tLoss 4.9638e+00 (4.7851e+00)\tAcc@1  98.44 ( 97.74)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][600/704]\tTime  0.077 ( 0.077)\tLoss 7.3392e-01 (4.4243e+00)\tAcc@1 100.00 ( 97.88)\tAcc@5 100.00 ( 99.99)\n","Epoch: [1][700/704]\tTime  0.076 ( 0.077)\tLoss 3.2598e+00 (4.1745e+00)\tAcc@1  98.44 ( 97.97)\tAcc@5 100.00 ( 99.99)\n","==> Train Accuracy: Acc@1 97.973 || Acc@5 99.989\n","==> Valid Accuracy:  Acc@1 99.180 || Acc@5 100.000\n","Epoch: [2][  0/704]\tTime  0.311 ( 0.311)\tLoss 5.7184e-01 (5.7184e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [2][100/704]\tTime  0.076 ( 0.079)\tLoss 1.2347e-01 (1.9622e+00)\tAcc@1 100.00 ( 98.86)\tAcc@5 100.00 (100.00)\n","Epoch: [2][200/704]\tTime  0.078 ( 0.078)\tLoss 2.4568e+00 (1.6866e+00)\tAcc@1  98.44 ( 99.05)\tAcc@5 100.00 (100.00)\n","Epoch: [2][300/704]\tTime  0.075 ( 0.077)\tLoss 4.3915e+00 (1.5502e+00)\tAcc@1  98.44 ( 99.16)\tAcc@5 100.00 (100.00)\n","Epoch: [2][400/704]\tTime  0.076 ( 0.077)\tLoss 4.8667e-01 (1.6193e+00)\tAcc@1 100.00 ( 99.16)\tAcc@5 100.00 (100.00)\n","Epoch: [2][500/704]\tTime  0.076 ( 0.077)\tLoss 1.2327e-01 (1.5995e+00)\tAcc@1 100.00 ( 99.17)\tAcc@5 100.00 (100.00)\n","Epoch: [2][600/704]\tTime  0.076 ( 0.077)\tLoss 6.2984e+00 (1.6040e+00)\tAcc@1  96.88 ( 99.16)\tAcc@5 100.00 (100.00)\n","Epoch: [2][700/704]\tTime  0.074 ( 0.077)\tLoss 6.1833e-02 (1.6725e+00)\tAcc@1 100.00 ( 99.14)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.144 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.940 || Acc@5 100.000\n","Epoch: [3][  0/704]\tTime  0.379 ( 0.379)\tLoss 5.3031e-01 (5.3031e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [3][100/704]\tTime  0.075 ( 0.079)\tLoss 4.8342e-01 (1.2014e+00)\tAcc@1 100.00 ( 99.29)\tAcc@5 100.00 (100.00)\n","Epoch: [3][200/704]\tTime  0.076 ( 0.078)\tLoss 1.2418e+00 (1.3116e+00)\tAcc@1  98.44 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [3][300/704]\tTime  0.078 ( 0.077)\tLoss 1.8620e+00 (1.5132e+00)\tAcc@1  98.44 ( 99.12)\tAcc@5 100.00 (100.00)\n","Epoch: [3][400/704]\tTime  0.077 ( 0.077)\tLoss 2.5398e+00 (1.6504e+00)\tAcc@1  98.44 ( 99.07)\tAcc@5 100.00 (100.00)\n","Epoch: [3][500/704]\tTime  0.078 ( 0.077)\tLoss 6.0345e-01 (1.7253e+00)\tAcc@1 100.00 ( 99.06)\tAcc@5 100.00 (100.00)\n","Epoch: [3][600/704]\tTime  0.076 ( 0.077)\tLoss 1.6995e-01 (1.8620e+00)\tAcc@1 100.00 ( 98.99)\tAcc@5 100.00 (100.00)\n","Epoch: [3][700/704]\tTime  0.074 ( 0.077)\tLoss 1.4832e+00 (1.9863e+00)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.942 || Acc@5 99.998\n","==> Valid Accuracy:  Acc@1 98.440 || Acc@5 100.000\n","Epoch: [4][  0/704]\tTime  0.269 ( 0.269)\tLoss 8.9133e-01 (8.9133e-01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [4][100/704]\tTime  0.078 ( 0.078)\tLoss 2.4750e-01 (1.5007e+00)\tAcc@1 100.00 ( 99.16)\tAcc@5 100.00 (100.00)\n","Epoch: [4][200/704]\tTime  0.077 ( 0.077)\tLoss 2.4855e-01 (1.3475e+00)\tAcc@1 100.00 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [4][300/704]\tTime  0.075 ( 0.077)\tLoss 5.2675e+00 (1.3605e+00)\tAcc@1  98.44 ( 99.23)\tAcc@5 100.00 (100.00)\n","Epoch: [4][400/704]\tTime  0.077 ( 0.077)\tLoss 6.9976e-01 (1.5077e+00)\tAcc@1 100.00 ( 99.19)\tAcc@5 100.00 (100.00)\n","Epoch: [4][500/704]\tTime  0.077 ( 0.077)\tLoss 1.2172e+00 (2.0432e+00)\tAcc@1 100.00 ( 98.89)\tAcc@5 100.00 (100.00)\n","Epoch: [4][600/704]\tTime  0.075 ( 0.077)\tLoss 5.5694e+00 (2.2337e+00)\tAcc@1  96.88 ( 98.79)\tAcc@5 100.00 (100.00)\n","Epoch: [4][700/704]\tTime  0.074 ( 0.076)\tLoss 4.5457e-01 (2.3447e+00)\tAcc@1 100.00 ( 98.73)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 98.736 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 98.060 || Acc@5 100.000\n","Epoch: [5][  0/704]\tTime  0.386 ( 0.386)\tLoss 1.6604e-01 (1.6604e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [5][100/704]\tTime  0.077 ( 0.079)\tLoss 1.2023e+00 (1.9695e+00)\tAcc@1 100.00 ( 98.92)\tAcc@5 100.00 (100.00)\n","Epoch: [5][200/704]\tTime  0.076 ( 0.078)\tLoss 4.4096e-01 (1.5685e+00)\tAcc@1 100.00 ( 99.15)\tAcc@5 100.00 (100.00)\n","Epoch: [5][300/704]\tTime  0.076 ( 0.077)\tLoss 4.3272e-02 (1.3737e+00)\tAcc@1 100.00 ( 99.29)\tAcc@5 100.00 (100.00)\n","Epoch: [5][400/704]\tTime  0.075 ( 0.077)\tLoss 4.2410e-01 (1.2933e+00)\tAcc@1 100.00 ( 99.35)\tAcc@5 100.00 (100.00)\n","Epoch: [5][500/704]\tTime  0.076 ( 0.077)\tLoss 1.8446e-01 (1.2036e+00)\tAcc@1 100.00 ( 99.39)\tAcc@5 100.00 (100.00)\n","Epoch: [5][600/704]\tTime  0.077 ( 0.077)\tLoss 1.1528e-01 (1.1315e+00)\tAcc@1 100.00 ( 99.43)\tAcc@5 100.00 (100.00)\n","Epoch: [5][700/704]\tTime  0.076 ( 0.077)\tLoss 6.4522e-01 (1.0474e+00)\tAcc@1 100.00 ( 99.48)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.478 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.220 || Acc@5 100.000\n","Epoch: [6][  0/704]\tTime  0.314 ( 0.314)\tLoss 1.1017e-01 (1.1017e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [6][100/704]\tTime  0.075 ( 0.079)\tLoss 6.4994e-02 (5.8688e-01)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n","Epoch: [6][200/704]\tTime  0.075 ( 0.078)\tLoss 3.2098e-01 (5.5826e-01)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n","Epoch: [6][300/704]\tTime  0.076 ( 0.077)\tLoss 2.2468e-01 (4.7696e-01)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [6][400/704]\tTime  0.076 ( 0.077)\tLoss 9.6766e-01 (4.5784e-01)\tAcc@1  98.44 ( 99.78)\tAcc@5 100.00 (100.00)\n","Epoch: [6][500/704]\tTime  0.076 ( 0.077)\tLoss 5.8866e-02 (4.4844e-01)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n","Epoch: [6][600/704]\tTime  0.077 ( 0.077)\tLoss 5.8631e-02 (4.2067e-01)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n","Epoch: [6][700/704]\tTime  0.074 ( 0.077)\tLoss 6.9059e-01 (4.0672e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.829 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.320 || Acc@5 100.000\n","Epoch: [7][  0/704]\tTime  0.397 ( 0.397)\tLoss 2.7093e-02 (2.7093e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [7][100/704]\tTime  0.075 ( 0.079)\tLoss 1.4966e-01 (3.1641e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [7][200/704]\tTime  0.075 ( 0.078)\tLoss 2.3518e-01 (3.2980e-01)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n","Epoch: [7][300/704]\tTime  0.075 ( 0.078)\tLoss 6.9870e-02 (3.0732e-01)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n","Epoch: [7][400/704]\tTime  0.076 ( 0.077)\tLoss 2.7506e-02 (2.9024e-01)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n","Epoch: [7][500/704]\tTime  0.075 ( 0.077)\tLoss 6.3552e-01 (2.8862e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][600/704]\tTime  0.075 ( 0.077)\tLoss 1.8287e-02 (2.7093e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","Epoch: [7][700/704]\tTime  0.074 ( 0.077)\tLoss 1.0983e-01 (2.6864e-01)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n","==> Train Accuracy: Acc@1 99.884 || Acc@5 100.000\n","==> Valid Accuracy:  Acc@1 99.380 || Acc@5 100.000\n","Best Top-1 Accuracy for fold10: 99.38\n"]}]},{"cell_type":"markdown","source":["## **Test with ensemble**"],"metadata":{"id":"ORvLl9gcmZjv"}},{"cell_type":"code","source":["test_loader = DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"metadata":{"id":"qTKAvAeNmbwI","executionInfo":{"status":"ok","timestamp":1652162869179,"user_tz":-540,"elapsed":22,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ensemble\n","with torch.no_grad():\n","    output = None\n","    predictions_list = []\n","   \n","    for fold in range(fold_num):\n","        print(f'[Fold {fold+1}]')\n","\n","        if output is not None:\n","            del output   # del output : memory free\n","        else :\n","            pass\n","        path2weights_fold = f'{path2weights}_fold{fold+1}.pth'\n","        if model == 'ResNet34':\n","            model = resnet34().cuda()\n","        elif model == \"ResNet50\":\n","            model = resnet50().cuda()\n","        elif model == \"ResNet101\":\n","            model = resnet101().cuda()\n","        model.load_state_dict(torch.load(path2weights_fold))\n","\n","        output = test(test_loader, model)\n","        output = output.view(output.shape[0], output.shape[1], 1).cpu() # 각 fold별 output의 평균을 내기 위해 3번째 dimension 추가\n","        predictions_list.append(output)\n","\n","    predictions_array = np.concatenate(predictions_list, axis=2)\n","    predictions_mean = predictions_array.mean(axis = 2)\n","    predictions_mean = torch.from_numpy(predictions_mean)\n","    predictData = torch.argmax(predictions_mean, 1)\n","\n","    classes = ('plane', 'car', 'bird', 'cat',\n","               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","    lst = []\n","    for Id, predict in enumerate(predictData, 1):\n","        # tensor형태의 predict를 정수의 prediction으로 바꿈\n","        x = predict.to(\"cpu\").numpy()\n","        x = x.astype(int)\n","        Category = classes[x]\n","        lst.append([Id, Category])\n","\n","    df = DataFrame(lst, columns=['Id', 'Category'])\n","    df.to_csv(path2submission, index=False, encoding='cp949')"],"metadata":{"id":"KS3wl8-vdMkb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652162918961,"user_tz":-540,"elapsed":49803,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}},"outputId":"796db7ba-2819-4164-9e6d-102191f58123"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[Fold 1]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 32.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 2]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 33.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 3]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 33.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 4]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 33.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 5]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 32.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 6]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 33.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 7]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 33.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 8]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 32.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 9]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 33.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[Fold 10]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:04<00:00, 33.54it/s]\n"]}]},{"cell_type":"markdown","source":["### **결과가 가장좋았던 ResNet101_fold5를 혼자 사용해본다면?**"],"metadata":{"id":"BhSBv8lh630y"}},{"cell_type":"code","source":["# def test_not_ensemble(test_loader, model):\n","#     classes = ('plane', 'car', 'bird', 'cat',\n","#                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","    \n","#     model.eval()\n","#     for i, (input, target) in enumerate(tqdm(test_loader), 0):\n","#         input = input.cuda()\n","#         #target은 쓰지 않음.\n","#         #target = target.cuda()\n","\n","#         output = torch.argmax(model(input), 1)\n","        \n","#         id = i * batch_size + 1     # id는 1부터 시작\n","#         lst = []\n","        \n","#         for Id, Category in zip(range(id, id+batch_size), output):\n","#             x = Category.to(\"cpu\").numpy()\n","#             Category = x.astype(int)\n","#             lst.append([Id, classes[Category]])\n","\n","#         df = DataFrame(lst, columns=['Id', 'Category'])\n","#         if i == 0:\n","#             df.to_csv(path2submission, index=False, encoding='cp949')\n","#         else :\n","#             df.to_csv(path2submission, mode='a', index=False, encoding='cp949', header=False)"],"metadata":{"id":"ejUc3D4x7Hsq","executionInfo":{"status":"ok","timestamp":1652162918961,"user_tz":-540,"elapsed":12,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# path2submission = f'/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/submission/{model}_best.csv'\n","# final_model = resnet101().cuda()\n","# final_model.load_state_dict(torch.load('/content/drive/Shareddrives/Data/Kaggle/GEK6189_CIFAR-10_Competition_2022-1/models/ResNet101_fold5.pth'))\n","# test_not_ensemble(test_loader, final_model)"],"metadata":{"id":"0PeeMTm56_Hv","executionInfo":{"status":"ok","timestamp":1652162919672,"user_tz":-540,"elapsed":714,"user":{"displayName":"‍이의준[학생](소프트웨어융합대학 컴퓨터공학부)","userId":"06208559590960942181"}}},"execution_count":15,"outputs":[]}]}